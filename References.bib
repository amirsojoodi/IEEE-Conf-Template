@misc{ucxweb2023,
  key             = {UCX},
  keywords        = {UCX,Web},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {UCX,Web},
  title           = {{The Unified Communication X Library}},
  url             = {https://openucx.org/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{openmpweb2023,
  key             = {OpenMP},
  keywords        = {Web},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{OpenMP}},
  url             = {https://www.openmp.org/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{nvidiaweb2023,
  key             = {NVIDIA},
  keywords        = {Web},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{NVIDIA}},
  url             = {https://www.nvidia.com/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{nsightsystemsweb2023,
  key           = {Nsight Systems},
  keywords      = {Web},
  mendeley-tags = {Web},
  title         = {{Nsight Systems}},
  url           = {https://developer.nvidia.com/nsight-systems},
  urldate       = {2023-06-06},
  year          = {2023}
}
@misc{uccweb2023,
  key             = {UCC},
  keywords        = {UCC,Web},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {UCC,Web},
  title           = {{Unified Collective Communication (UCC)}},
  url             = {https://github.com/openucx/ucc},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{migweb2023,
  key             = {MIG},
  keywords        = {Web},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{Multi Instance GPU (MIG)}},
  url             = {https://www.nvidia.com/en-us/technologies/multi-instance-gpu/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{mpichweb2023,
  key             = {MPICH},
  keywords        = {Web},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{MPICH}},
  url             = {https://www.mpich.org/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{mpsweb2023,
  key             = {MPS},
  keywords        = {Web},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{Multi-Process Service}},
  url             = {https://docs.nvidia.com/deploy/mps/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{top500web2023,
  key             = {Top500},
  keywords        = {Web},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{Top500}},
  url             = {https://top500.org/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{dynamiccudagraphsweb2023,
  key             = {Dynamic CUDA Graphs},
  keywords        = {CUDA{\_}Graphs,Web},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {CUDA{\_}Graphs,Web},
  title           = {{CUDA Graphs in Dynamic Environments}},
  url             = {https://developer.nvidia.com/blog/employing-cuda-graphs-in-a-dynamic-environment/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{cudaweb2023,
  key             = {CUDA},
  keywords        = {Web},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{CUDA}},
  url             = {https://docs.nvidia.com/cuda/index.html},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{cooperativegroupsweb2023,
  key             = {Cooperative Groups},
  keywords        = {Web},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{Cooperative Groups}},
  url             = {https://developer.nvidia.com/blog/cooperative-groups/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{horovodweb2023,
  key             = {Horovod},
  keywords        = {Web},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{Horovod}},
  url             = {https://horovod.ai/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{infinibandweb2023,
  key             = {InfiniBand},
  keywords        = {Web},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{InfiniBand Trade Association}},
  url             = {https://www.infinibandta.org/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{jacobi2023,
  key           = {Multi-GPU Jacobi Solver},
  keywords      = {Benchmark,GPU,MPI},
  mendeley-tags = {Benchmark,GPU,MPI},
  title         = {{Multi-GPU Jacobi Solver}},
  url           = {https://github.com/NVIDIA/multi-gpu-programming-models},
  urldate       = {2023-10-01},
  year          = {2023}
}
@misc{ncclweb2023,
  key             = {NCCL},
  keywords        = {Web},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{NVIDIA Collective Communications Library}},
  url             = {https://github.com/NVIDIA/nccl},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{nvshmemweb2023,
  key           = {NVSHMEM},
  keywords      = {Web},
  mendeley-tags = {Web},
  title         = {{NVSHMEM}},
  url           = {https://developer.nvidia.com/nvshmem},
  urldate       = {2023-06-06},
  year          = {2023}
}
@misc{llvmweb2023,
  key           = {LLVM},
  keywords      = {Compiler,LLVM,Web},
  mendeley-tags = {Compiler,LLVM,Web},
  title         = {{LLVM}},
  url           = {https://llvm.org/},
  urldate       = {2023-06-06},
  year          = {2023}
}
@misc{mvapichweb2023,
  key             = {MVAPICH},
  keywords        = {Web},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{MVAPICH}},
  url             = {https://mvapich.cse.ohio-state.edu/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{openshmemweb2023,
  key             = {OpenSHMEM},
  keywords        = {Web},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{OpenSHMEM}},
  url             = {http://openshmem.org/},
  urldate         = {2022-01-30},
  year            = {2023}
}
@misc{ucfweb2023,
  key             = {UCF},
  keywords        = {UCX,Web},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {UCX,Web},
  title           = {{Unified Communication Framework (UCF)}},
  url             = {https://ucfconsortium.org/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{mpiforumweb2023,
  key             = {MPI Forum},
  keywords        = {Web},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{MPI Forum}},
  url             = {https://www.mpi-forum.org/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{cudagraphsweb2023,
  key             = {CUDA Graphs},
  keywords        = {Web},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{CUDA Graphs}},
  url             = {https://developer.nvidia.com/blog/cuda-graphs/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{openmpiweb2023,
  key             = {OpenMPI},
  keywords        = {Web},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Web},
  month           = {March},
  title           = {{Open MPI}},
  url             = {https://www.open-mpi.org/},
  urldate         = {2023-06-06},
  year            = {2023}
}
@misc{openclweb2022,
  key             = {OpenCL},
  keywords        = {Web},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{OpenCL}},
  url             = {https://www.khronos.org/opencl/},
  urldate         = {2022-01-30},
  year            = {2022}
}
@misc{clangweb2021,
  key           = {Clang},
  keywords      = {Compiler,Web},
  mendeley-tags = {Compiler,Web},
  title         = {{Clang}},
  url           = {https://clang.llvm.org/},
  urldate       = {2021-04-23},
  year          = {2021}
}
@misc{mellanoxweb2021,
  key             = {Mellanox},
  keywords        = {Web},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Web},
  title           = {{Mellanox Technologies}},
  url             = {https://www.mellanox.com/},
  urldate         = {2021-12-10},
  year            = {2021}
}
@techreport{Abbott2018,
  author          = {Abbott, Steve and Larkin, Jeff},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Unknown/Programming Multi-GPU Nodes - Abbott, Larkin - Unknown.pdf:pdf},
  keywords        = {GPU,Multi{\_}GPU},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {GPU,Multi{\_}GPU},
  number          = {November},
  title           = {{Programming Multi-GPU Nodes}},
  year            = {2018}
}
@techreport{Afsahi2019a,
  author          = {Afsahi, A.},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Unknown/ELEC-873 Cluster Computing - Suggested Projects - Afsahi - Unknown.pdf:pdf},
  mendeley-groups = {ELEC-873},
  pages           = {25--26},
  title           = {{ELEC-873 Cluster Computing - Suggested Projects}},
  year            = {2019}
}
@techreport{Afsahi2019,
  author          = {Afsahi, A.},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Unknown/ELEC-873 Cluster Computing - Research Topics - Afsahi - Unknown.pdf:pdf},
  mendeley-groups = {ELEC-873},
  pages           = {19--20},
  title           = {{ELEC-873 Cluster Computing - Research Topics}},
  year            = {2019}
}
@article{Agostini2018,
  abstract        = {NVIDIA GPUDirect is a family of technologies aimed at optimizing data movement among GPUs (P2P) or among GPUs and third-party devices (RDMA). GPUDirect Async, introduced in CUDA 8.0, is a new addition which allows direct synchronization between GPU and third party devices. For example, Async allows an NVIDIA GPU to directly trigger and poll for completion of communication operations queued to an InfiniBand Connect-IB network adapter, with no involvement of CPU in the critical communication path of GPU applications. In this paper we describe the motivations and the building blocks of GPUDirect Async. After an initial analysis with a micro-benchmark, by means of a performance model, we show the potential benefits of using two different asynchronous communication models supported by this new technology in two MPI multi-GPU applications: HPGMG-FV, a proxy for real-world geometric multi-grid applications and CoMD-CUDA, a proxy for Classical Molecular Dynamics codes. We also report a test case in which the use of GPUDirect Async does not provide any advantage, that is an implementation of the Breadth First Search algorithm for large scale graphs.},
  author          = {Agostini, Elena and Rossetti, D. and Potluri, S.},
  doi             = {10.1016/j.jpdc.2017.12.007},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Journal of Parallel and Distributed Computing/GPUDirect Async Exploring GPU synchronous communication techniques for InfiniBand clusters - Agostini, Rossetti, Potluri - Journal of Pa.pdf:pdf},
  issn            = {07437315},
  journal         = {Journal of Parallel and Distributed Computing},
  keywords        = {Asynchronous communication models,CUDA,CUDA 8.0,GPU,GPUDirect Async,GPUDirect{\_}Async,InfiniBand},
  mendeley-groups = {MustKnow,UsedInComp1,UsedInComp2},
  mendeley-tags   = {CUDA,GPU,GPUDirect{\_}Async,InfiniBand},
  pages           = {28--45},
  title           = {{GPUDirect Async: Exploring GPU synchronous communication techniques for InfiniBand clusters}},
  volume          = {114},
  year            = {2018}
}
@inproceedings{Agostini2017,
  abstract        = {NVIDIA GPUDirect is a family of technologiesaimed at optimizing data movement among GPUs (P2P) orbetween GPUs and third-party devices (RDMA). GPUDirectAsync, introduced in CUDA 8.0, is a new addition whichallows direct synchronization between GPU and third partydevices. For example, Async allows an NVIDIA GPU to directlytrigger and poll for completion of communication operationsqueued to an InfiniBand Connect-IB network adapter, removingCPU involvement from the critical path in GPU acceleratedapplications. In this paper, we present the building blocks ofGPUDirect Async and explain the supported usage models ofthis new technology. We also present a performance evaluationusing a micro-benchmark and a synthetic stencil benchmark. Finally, we demonstrate the use of Async in a few multi-GPUMPI applications: HPGMG-FV (geometric multi-grid), achievingup to 25{\%} improvement in total execution time, CoMD-CUDA(classical molecular dynamics), reducing communications timesup to 30{\%}, LULESH2-CUDA, achieving an average performanceimprovement of 13{\%} in the total execution time.},
  author          = {Agostini, Elena and Rossetti, Davide and Potluri, Sreeram},
  booktitle       = {Proceedings of the IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)},
  doi             = {10.1109/CCGRID.2017.29},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the IEEEACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)/Offloading communication control logic in GPU accelerated applications - Agostini, Rossetti, Potluri - Pr.pdf:pdf},
  isbn            = {9781509066100},
  keywords        = {Asynchronous communications,CUDA 8.0,GPU,GPUDirect Async,GPUDirect{\_}RDMA,InfiniBand},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,GPUDirect{\_}RDMA},
  pages           = {248--257},
  title           = {{Offloading communication control logic in GPU accelerated applications}},
  year            = {2017}
}
@article{Ahmed2022,
  author        = {Ahmed, H and Kumar, Pradeep and Meneghin, Massimiliano and Mahmoud, Ahmed H and Jayaraman, Pradeep Kumar and Morris, Nigel J W},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/UC Davis College of Engineering/Neon A Multi-GPU Programming Model for Grid-based Computations - Ahmed et al. - UC Davis College of Engineering.pdf:pdf},
  journal       = {UC Davis: College of Engineering},
  keywords      = {GPU,Multi{\_}GPU,Scheduling},
  mendeley-tags = {GPU,Multi{\_}GPU,Scheduling},
  pages         = {1--11},
  title         = {{Neon : A Multi-GPU Programming Model for Grid-based Computations}},
  year          = {2022}
}
@inproceedings{Aji2013,
  abstract        = {Despite the vast interest in accelerator-based systems, programming large multinode GPUs is still a complex task, particularly with respect to optimal data movement across the host-GPU PCIe connection and then across the network. In order to address such issues, GPU-integrated MPI solutions have been developed that integrate GPU data movement into existing MPI implementations. Currently available GPU-integrated frameworks differ in aspects related to the buffer synchronization and ordering semantics they provide to users. The noteworthy models are (1) unified virtual addressing (UVA)-based approach and (2) MPI attributes-based approach. In this paper, we compare these approaches, for both programmability and performance, and demonstrate that the UVA-based design is useful for isolated communication with no data dependencies or ordering requirements, while the attributes-based design might be more appropriate when multiple interdependent MPI and GPU operations are interleaved. {\textcopyright} 2013 IEEE.},
  author          = {Aji, Ashwin M. and Balaji, Pavan and Dinan, James and Feng, Wu Chun and Thakur, Rajeev},
  booktitle       = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
  doi             = {10.1109/IPDPSW.2013.256},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2013/Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)/Synchronization and ordering semantics in hybrid MPIGPU programming - Aji et al. - Proceedings of th.pdf:pdf},
  isbn            = {9780769549798},
  keywords        = {CUDA,GPGPU,GPU,MPI,MPI-ACC,OpenCL,Unified Virtual Addressing},
  mendeley-groups = {MustKnow,UsedInComp1,UsedInComp2},
  mendeley-tags   = {CUDA,GPU,MPI},
  pages           = {1020--1029},
  title           = {{Synchronization and ordering semantics in hybrid MPI+GPU programming}},
  year            = {2013}
}
@article{Aji2016,
  abstract      = {Data movement in high-performance computing systems accelerated by graphics processing units (GPUs) remains a challenging problem. Data communication in popular parallel programming models, such as the Message Passing Interface (MPI), is currently limited to the data stored in the CPU memory space. Auxiliary memory systems, such as GPU memory, are not integrated into such data movement standards, thus providing applications with no direct mechanism to perform end-to-end data movement. We introduce MPI-ACC, an integrated and extensible framework that allows end-to-end data movement in accelerator-based systems. MPI-ACC provides productivity and performance benefits by integrating support for auxiliary memory spaces into MPI. MPI-ACC supports data transfer among CUDA, OpenCL and CPU memory spaces and is extensible to other offload models as well. MPI-ACC's runtime system enables several key optimizations, including pipelining of data transfers, scalable memory management techniques, and balancing of communication based on accelerator and node architecture. MPI-ACC is designed to work concurrently with other GPU workloads with minimum contention. We describe how MPI-ACC can be used to design new communication-computation patterns in scientific applications from domains such as epidemiology simulation and seismology modeling, and we discuss the lessons learned. We present experimental results on a state-of-the-art cluster with hundreds of GPUs; and we compare the performance and productivity of MPI-ACC with MVAPICH, a popular CUDA-aware MPI solution. MPI-ACC encourages programmers to explore novel application-specific optimizations for improved overall cluster utilization.},
  author        = {Aji, Ashwin M. and Panwar, Lokendra S. and Ji, Feng and Murthy, Karthik and Chabbi, Milind and Balaji, Pavan and Bisset, Keith R. and Dinan, James and Feng, Wu Chun and Mellor-Crummey, John and Ma, Xiaosong and Thakur, Rajeev},
  doi           = {10.1109/TPDS.2015.2446479},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/IEEE Transactions on Parallel and Distributed Systems/MPI-ACC Accelerator-Aware MPI for Scientific Applications - Aji et al. - IEEE Transactions on Parallel and Distributed Systems.pdf:pdf},
  issn          = {10459219},
  journal       = {IEEE Transactions on Parallel and Distributed Systems},
  keywords      = {GPU,Heterogeneous (hybrid) systems,MPI,concurrent programming,distributed architectures,parallel systems},
  mendeley-tags = {GPU,MPI},
  pages         = {1401--1414},
  title         = {{MPI-ACC: Accelerator-Aware MPI for Scientific Applications}},
  year          = {2016}
}
@inproceedings{Akhmetova2017,
  abstract      = {With a large variety and complexity of existing HPC machines and uncertainty regarding exact future Exascale hardware, it is not clear whether existing parallel scientific codes will perform well on future Exascale systems: they can be largely modified or even completely rewritten from scratch. Therefore, now it is important to ensure that software is ready for Exascale computing and will utilize all Exascale resources well. Many parallel programming models try to take into account all possible hardware features and nuances. However, the HPC community does not yet have a precise answer whether, for Exascale computing, there should be a natural evolution of existing models interoperable with each other or it should be a disruptive approach. Here, we focus on the first option, particularly on a practical assessment of how some parallel programming models can coexist with each other. This work describes two API combination scenarios on the example of iPIC3D [26], an implicit Particle-in-Cell code for space weather applications written in C++ and MPI plus OpenMP. The first scenario is to enable multiple OpenMP threads call MPI functions simultaneously, with no restrictions, using an MPI THREAD MULTIPLE thread safety level. The second scenario is to utilize the OpenMP tasking model on top of the first scenario. The paper reports a step-by-step methodology and experience with these API combinations in iPIC3D; provides the scaling tests for these implementations with up to 2048 physical cores; discusses occurred interoperability issues; and provides suggestions to programmers and scientists who may adopt these API combinations in their own codes.},
  author        = {Akhmetova, Dana and Iakymchuk, Roman and Ekeberg, Orjan and Laure, Erwin},
  booktitle     = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
  doi           = {10.1109/IPDPSW.2017.128},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)/Performance study of multithreaded MPI and Openmp tasking in a large scientific code - Akhmetova et.pdf:pdf},
  isbn          = {9781538634080},
  keywords      = {API interoperability,Exascale,MPI-THREAD-MULTIPLE thread safety,Multithreaded{\_}MPI,OpenMP,OpenMP tasks,multithreaded MPI,performance,programming models},
  mendeley-tags = {Exascale,Multithreaded{\_}MPI,OpenMP},
  pages         = {756--765},
  title         = {{Performance study of multithreaded MPI and Openmp tasking in a large scientific code}},
  year          = {2017}
}
@phdthesis{Alizadeh2021,
  author          = {Alizadeh, Pedram},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Unknown/Efficient Process Arrival Pattern Aware Collective Communication For HPC and Deep Learning - Alizadeh - Unknown.pdf:pdf},
  keywords        = {MPI,PAP,Thesis},
  mendeley-groups = {MustKnow,ByPPRL,Theses},
  mendeley-tags   = {MPI,PAP,Thesis},
  number          = {November},
  pages           = {1--140},
  title           = {{Efficient Process Arrival Pattern Aware Collective Communication For HPC and Deep Learning}},
  year            = {2021}
}
@inproceedings{Alizadeh2022,
  abstract        = {MPI collective communication operations are used extensively in parallel applications. As such, researchers have been investigating how to improve their performance and scalability to directly impact application performance. Unfortunately, most of these studies are based on the premise that all processes arrive at the collective call simultaneously. A few studies though have shown that imbalanced Process Arrival Pattern (PAP) is ubiquitous in real environments, significantly affecting the collective performance. Therefore, devising PAP-aware collective algorithms that could improve performance, while challenging, is highly desirable. This paper is along those lines but in the context of Deep Learning (DL) workloads that have become maintstream. This paper presents a brief characterization of collective communications, in particular MPI-Allreduce, in the Horovod distributed Deep Learning framework and shows that the arrival pattern of MPI processes is indeed imbalanced. It then proposes an intra-node shared-memory PAP-aware MPI-Allreduce algorithm for small to medium messages, where the leader process is dynamically chosen based on the arrival time of the processes at each invocation of the collective call. We then propose an intra-node PAP-aware algorithm for large messages that dynamically constructs the reduction schedule at each MPI-Allreduce invocation. Finally, we propose a PAP-aware cluster-wide hierarchical algorithm, which is extended by utilizing our intra-node PAP-aware designs, that imposes less data dependency among processes given its hierarchical nature compared to flat algorithms. The proposed algorithms deliver up to 58{\%} and 17{\%} improvement at the micro-benchmark and Horovod with TensorFlow application over the native algorithms, respectively.},
  author          = {Alizadeh, Pedram and Sojoodi, Amirhossein and {Hassan Temucin}, Yiltan and Afsahi, Ahmad},
  booktitle       = {Proceedings of the European MPI Users' Group Meeting (EuroMPI)},
  doi             = {10.1145/3555819.3555857},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the European MPI Users' Group Meeting (EuroMPI)/Efficient Process Arrival Pattern Aware Collective Communication for Deep Learning - Alizadeh et al. - Proceedings of the European MPI U.pdf:pdf},
  isbn            = {9781450397995},
  keywords        = {Collective Communication,Deep{\_}Learning,Distributed Deep Learning,MPI,MPI-Allreduce,PAP,Process Arrival Pattern},
  mendeley-groups = {MustKnow,ByPPRL},
  mendeley-tags   = {Deep{\_}Learning,MPI,PAP},
  pages           = {68--78},
  title           = {{Efficient Process Arrival Pattern Aware Collective Communication for Deep Learning}},
  year            = {2022}
}
@inproceedings{Almasi2005,
  abstract      = {BlueGene/L is currently the world's fastest supercomputer. It consists of a large number of low power dual-processor compute nodes interconnected by high speed torus and collective networks. Because compute nodes do not have shared memory, MPI is the the natural programming model for this machine. The BlueGene/L MPI library is a port of MPICH2. In this paper we discuss the implementation of MPI collectives on BlueGene/L. The MPICH2 implementation of MPI collectives is based on point-to-point communication primitives. This turns out to be suboptimal for a number of reasons. Machine-optimized MPI collectives are necessary to harness the performance of BlueGene/L. We discuss these optimized MPI collectives, describing the algorithms and presenting performance results measured with targeted micro-benchmarks on real BlueGene/L hardware with up to 4096 compute nodes. Copyright 2005 ACM.},
  author        = {Alm{\'{a}}si, George and Heidelberger, Philip and Archer, Charles and Martorell, Xavier and Erway, C. Chris and Moreira, Jos{\'{e}} E. and Steinmacher-Burow, B. and Zheng, Yili},
  booktitle     = {Proceedings of the International Conference on Supercomputing (ICS)},
  doi           = {10.1145/1088149.1088183},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2005/Proceedings of the International Conference on Supercomputing (ICS)/Optimization of MPI collective communication on BlueGeneL systems - Alm{\'{a}}si et al. - Proceedings of the International Conference on Supe.pdf:pdf},
  isbn          = {1595931678},
  keywords      = {BlueGene,Collective Communication,Collectives,MPI,Optimization,Performance},
  mendeley-tags = {BlueGene,Collectives,MPI},
  pages         = {253--262},
  title         = {{Optimization of MPI collective communication on BlueGene/L systems}},
  year          = {2005}
}
@phdthesis{Amanzholov2022,
  author          = {Amanzholov, Muzakhir},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Unknown/FUNCTIONAL IMPLEMENTATION OF PARTITIONED COLLECTIVE COMMUNICATION PRIMITIVES - Amanzholov - Unknown.pdf:pdf},
  keywords        = {Collectives,MPI,Partitioned,Thesis},
  mendeley-groups = {Theses},
  mendeley-tags   = {Collectives,MPI,Partitioned,Thesis},
  pages           = {1--138},
  school          = {Tenessee Technological University},
  title           = {{FUNCTIONAL IMPLEMENTATION OF PARTITIONED COLLECTIVE COMMUNICATION PRIMITIVES}},
  year            = {2022}
}
@inproceedings{Amer2019,
  abstract        = {Efforts to mitigate lock contention from concurrent threaded accesses to MPI have reduced contention through fine-grained locking, avoided locking altogether by offloading communication to dedicated threads, or alleviated negative side effects from contention by using better lock management protocols. The blocking nature of lock-based methods, however, wastes the asynchrony benefits of nonblocking MPI operations, and the offloading model sacrifices CPU resources and incurs unnecessary software offloading overheads under low contention. We propose new thread safety models, CSync and LockQ, based on software combining, a form of software offloading without the requirement for dedicated threads; a thread holding the lock combines work of threads that failed their lock acquisitions. We demonstrate that CSync, a direct application of software combining, improves scalability but suffers from lack of asynchrony and incurs unnecessary offloading. LockQ alleviates these shortcomings by leveraging MPI semantics to relax synchronization and reduce offloading requirements. We present the implementation, analysis, and evaluation of these models on a modern network fabric and show that LockQ outperforms most existing thread safety models in low- and high-contention regimes.},
  author          = {Amer, Abdelhalim and Archer, Charles and Blocksome, Michael and Cao, Chongxiao and Chuvelev, Michael and Fujita, Hajime and Garzaran, Maria and Guo, Yanfei and Hammond, Jeff R. and Iwasaki, Shintaro and Raffenetti, Kenneth J. and Shiryaev, Mikhail and Si, Min and Taura, Kenjiro and Thapaliya, Sagar and Balaji, Pavan},
  booktitle       = {Proceedings of the International Conference on Supercomputing (ICS)},
  doi             = {10.1145/3330345.3330378},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Conference on Supercomputing (ICS)/Software combining to mitigate multithreaded MPI contention - Amer et al. - Proceedings of the International Conference on Supercomputi.pdf:pdf},
  isbn            = {9781450360791},
  keywords        = {MPI,Multithreaded{\_}MPI},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Multithreaded{\_}MPI},
  pages           = {367--379},
  title           = {{Software combining to mitigate multithreaded MPI contention}},
  year            = {2019}
}
@article{Amer2019a,
  abstract        = {In this article, we investigate contention management in lock-based thread-safe MPI libraries. Specifically, we make two assumptions: (1) locks are the only form of synchronization when protecting communication paths; and (2) contention occurs, and thus serialization is unavoidable. Our work distinguishes between lock acquisitions with respect to work being performed inside a critical section; productive vs. unproductive. Waiting for message reception without doing anything else inside a critical section is an example of unproductive lock acquisition. We show that the high-throughput nature of modern scalable locking protocols translates into better communication progress for throughput-intensive MPI communication but negatively impacts latency-sensitive communication because of overzealous unproductive lock acquisition. To reduce unproductive lock acquisitions, we devised a method that promotes threads with productive work using a generic two-level priority locking protocol. Our results show that using a high-throughput protocol for productive work and a fair protocol for less productive code paths ensures the best tradeoff for fine-grained communication, whereas a fair protocol is sufficient for more coarse-grained communication. Although these efforts have been rewarding, scalability degradation remains significant. We discuss techniques that diverge from the pure locking model and offer the potential to further improve scalability.},
  author          = {Amer, Abdelhalim and Lu, Huiwei and Balaji, Pavan and Chabbi, Milind and Wei, Yanjie and Hammond, Jeff and Matsuoka, Satoshi},
  doi             = {10.1145/3275443},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/ACM Transactions on Parallel Computing/Lock contention management in multithreaded MPI - Amer et al. - ACM Transactions on Parallel Computing.pdf:pdf},
  issn            = {23294957},
  journal         = {ACM Transactions on Parallel Computing},
  keywords        = {Critical section,MPI,Multithreaded{\_}MPI,Runtime contention,Threads},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Multithreaded{\_}MPI},
  number          = {3},
  pages           = {1--21},
  title           = {{Lock contention management in multithreaded MPI}},
  volume          = {5},
  year            = {2019}
}
@inproceedings{Amer2015,
  abstract        = {Hybrid MPI+Threads programming has emerged as an alternative model to the "MPI everywhere" model to better handle the increasing core density in cluster nodes. While the MPI standard allows multithreaded concurrent communication, such flexibility comes with the cost of maintaining thread safety within the MPI implementation, typically implemented using critical sections. In contrast to previous works that studied the importance of critical-section granularity in MPI implementations, in this paper we investigate the implication of critical-section arbitration on communication performance. We first analyze the MPI runtime when multithreaded concurrent communication takes place on hierarchical memory systems. Our results indicate that the mutex-based approach that most MPI implementations use today can incur performance penalties due to unfair arbitration. We then present methods to mitigate these penalties with a first-come, first-served arbitration and a priority locking scheme that favors threads doing useful work. Through evaluations using several benchmarks and applications, we demonstrate up to 5-fold improvement in performance.},
  author          = {Amer, Abdelhalim and Lu, Huiwei and Wei, Yanjie and Balaji, Pavan and Matsuoka, Satoshi},
  booktitle       = {Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPOPP)},
  doi             = {10.1145/2688500.2688522},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPOPP)/MPIThreads Runtime contention and remedies - Amer et al. - Proceedings of the ACM SIGPLAN Symposium on.pdf:pdf},
  isbn            = {9781450332057},
  keywords        = {Critical section,MPI,Multithreaded{\_}MPI,Runtime contention,Threads},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Multithreaded{\_}MPI},
  pages           = {239--248},
  title           = {{MPI+Threads: Runtime contention and remedies}},
  year            = {2015}
}
@inproceedings{Ammendola2013,
  abstract        = {Modern GPUs support special protocols to exchange data directly across the PCI Express bus. While these protocols could be used to reduce GPU data transmission times, basically by avoiding staging to host memory, they require specific hardware features which are not available on current generation network adapters. In this paper we describe the architectural modifications required to implement peer-to-peer access to NVIDIA Fermi-And Kepler-class GPUs on an FPGA-based cluster interconnect. Besides, the current software implementation, which integrates this feature by minimally extending the RDMA programming model, is discussed, as well as some issues raised while employing it in a higher level API like MPI. Finally, the current limits of the technique are studied by analyzing the performance improvements on low-level benchmarks and on two GPU-Accelerated applications, showing when and how they seem to benefit from the GPU peer-to-peer method. {\textcopyright} 2013 IEEE.},
  author          = {Ammendola, Roberto and Bernaschi, Massimo and Biagioni, Andrea and Bisson, Mauro and Fatica, Massimiliano and Frezza, Ottorino and {Lo Cicero}, Francesca and Lonardo, Alessandro and Mastrostefano, Enrico and Paolucci, Pier Stanislao and Rossetti, Davide and Simula, Francesco and Tosoratto, Laura and Vicini, Piero},
  booktitle       = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
  doi             = {10.1109/IPDPSW.2013.128},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2013/Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)/GPU peer-to-peer techniques applied to a cluster interconnect - Ammendola et al. - Proceedings of th.pdf:pdf},
  isbn            = {9780769549798},
  keywords        = {GPU,Interconnect,Network,P2P,interconnection network,parallel computing,peer-to-peer},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,Interconnect,Network,P2P},
  pages           = {806--815},
  title           = {{GPU peer-to-peer techniques applied to a cluster interconnect}},
  year            = {2013}
}
@misc{ANL2018,
  author        = {ANL},
  keywords      = {MPI,Profile,Web},
  mendeley-tags = {MPI,Profile,Web},
  title         = {{Fast Profiling library for MPI}},
  url           = {https://www.mcs.anl.gov/research/projects/fpmpi/WWW/},
  urldate       = {2020-07-12},
  year          = {2018}
}
@article{Antelmi2022,
  abstract        = {The amount of accessible computational devices over the Internet offers an enormous but latent computational power. Nonetheless, the complexity of orchestrating and managing such devices requires dedicated architectures and tools and hinders the exploitation of this vast processing capacity. Over the last years, the paradigm of (Browser-based) Volunteer Computing emerged as a unique approach to harnessing such computational capabilities, leveraging the idea of voluntarily offering resources. This article proposes VFuse, a groundbreaking architecture to exploit the Browser-based Volunteer Computing paradigm via a ready-to-access volunteer network. VFuse offers a modern multi-language programming environment for developing scientific workflows using WebAssembly technology without requiring the user any local installation or configuration. We equipped our architecture with a secure and transparent rewarding mechanism based on blockchain technology (Ethereum) and distributed P2P file system (IPFS). Further, the use of Non-Fungible Tokens provides a unique, secure, and transparent methodology for recognizing the users' participation in the network. We developed a prototype of the proposed architecture and four example applications implemented with our system. All code and examples are publicly available on GitHub.},
  author          = {Antelmi, Alessia and D'Ambrosio, Giuseppe and Petta, Andrea and Serra, Luigi and Spagnuolo, Carmine},
  doi             = {10.1109/ACCESS.2022.3207167},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/IEEE Access/A Volunteer Computing Architecture for Computational Workflows on Decentralized Web - Antelmi et al. - IEEE Access.pdf:pdf},
  issn            = {21693536},
  journal         = {IEEE Access},
  keywords        = {P2P,Scientific computing,Web 3.0,WebAssembly,browser-based volunteer computing,decentralized web,distributed computing,parallel computing,volunteer computing},
  mendeley-groups = {Web},
  pages           = {98993--99010},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  title           = {{A Volunteer Computing Architecture for Computational Workflows on Decentralized Web}},
  volume          = {10},
  year            = {2022}
}
@article{Arafa2019,
  abstract      = {Performance modeling is a challenging problem due to the complexities of hardware architectures. In this paper, we present PPT-GPU, a scalable and accurate simulation framework that enables GPU code developers and architects to predict the performance of applications in a fast, and accurate manner on different GPU architectures. PPT-GPU is part of the open source project, Performance Prediction Toolkit (PPT) developed at the Los Alamos National Laboratory. We extend the old GPU model in PPT that predict the runtimes of computational physics codes to offer better prediction accuracy, for which, we add models for different memory hierarchies found in GPUs and latencies for different instructions. To further show the utility of PPT-GPU, we compare our model against real GPU device(s) and the widely used cycle-accurate simulator, GPGPU-Sim using different workloads from RODINIA and Parboil benchmarks. The results indicate that the predicted performance of PPT-GPU is within a 10 percent error compared to the real device(s). In addition, PPT-GPU is highly scalable, where it is up to 450x faster than GPGPU-Sim with more accurate results.},
  author        = {Arafa, Yehia and Badawy, Abdel Hameed A. and Chennupati, Gopinath and Santhi, Nandakishore and Eidenbenz, Stephan},
  doi           = {10.1109/LCA.2019.2904497},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/IEEE Computer Architecture Letters/PPT-GPU Scalable GPU Performance Modeling - Arafa et al. - IEEE Computer Architecture Letters.pdf:pdf},
  issn          = {15566064},
  journal       = {IEEE Computer Architecture Letters},
  keywords      = {GPGPU,GPU,GPU modeling,Modeling,PPT,performance prediction,software/hardware co-design},
  mendeley-tags = {GPU,Modeling},
  number        = {1},
  pages         = {55--58},
  title         = {{PPT-GPU: Scalable GPU Performance Modeling}},
  volume        = {18},
  year          = {2019}
}
@inproceedings{Arafa2020,
  abstract      = {In this paper, we introduce an accurate and scalable memory modeling framework for General Purpose Graphics Processor units (GPGPUs), PPT-GPU-Mem. That is Performance Prediction Tool-Kit for GPUs Cache Memories. PPT-GPU-Mem predicts the performance of different GPUs' cache memory hierarchy (L1 {\&} L2) based on reuse profiles. We extract a memory trace for each GPU kernel once in its lifetime using the recently released binary instrumentation tool, NVBIT. The memory trace extraction is architecture-independent and can be done on any available NVIDIA GPU. PPT-GPU-Mem can then model any NVIDIA GPU caches given their parameters and the extracted memory trace. We model Volta Tesla V100 and Turing TITAN RTX and validate our framework using different kernels from Polybench and Rodinia benchmark suites in addition to two deep learning applications from Tango DNN benchmark suite. We provide two models, MBRDP (Multiple Block Reuse Distance Profile) and OBRDP (One Block Reuse Distance Profile), with varying assumptions, accuracy, and speed. Our accuracy ranges from 92{\%} to 99{\%} for the different cache levels compared to real hardware while maintaining the scalability in producing the results. Finally, we illustrate that PPT-GPU-Mem can be used for design space exploration and for predicting the cache performance of future GPUs.},
  author        = {Arafa, Yehia and Badawy, Abdel Hameed and Chennupati, Gopinath and Barai, Atanu and Santhi, Nandakishore and Eidenbenz, Stephan},
  booktitle     = {Proceedings of the International Conference on Supercomputing (ICS)},
  doi           = {10.1145/3392717.3392761},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the International Conference on Supercomputing (ICS)/Fast, accurate, and scalable memory modeling of GPGPUs using reuse profiles - Arafa et al. - Proceedings of the International Conferenc.pdf:pdf},
  isbn          = {9781450379830},
  keywords      = {GPU,GPU computing,Modeling,NVIDIA NVBIT,performance modeling,reuse distance},
  mendeley-tags = {GPU,Modeling},
  pages         = {1--12},
  title         = {{Fast, accurate, and scalable memory modeling of GPGPUs using reuse profiles}},
  year          = {2020}
}
@inproceedings{Arafa2021,
  abstract      = {In this paper, we present PPT-GPU, a scalable performance prediction toolkit for GPUs. PPT-GPU achieves scalability through a hybrid high-level modeling approach where some computations are extrapolated and multiple parts of the model are parallelized. The tool primary prediction models use pre-collected memory and instructions traces of the workloads to accurately capture the dynamic behavior of the kernels. PPT-GPU reports an extensive array of GPU performance metrics accurately while being easily extensible. We use a broad set of benchmarks to verify predictions accuracy. We compare the results against hardware metrics collected using vendor profiling tools and cycle-Accurate simulators. The results show that the performance predictions are highly correlated to the actual hardware (MAPE: 16{\%} and Correlation: 0.98). Moreover, PPT-GPU is orders of magnitude faster than cycle-Accurate simulators. This comprehensiveness of the collected metrics can guide architects and developers to perform design space explorations. Moreover, the scalability of the tool enables conducting efficient and fast sensitivity analyses for performance-critical applications.},
  author        = {Arafa, Yehia and Badawy, Abdel Hameed and Wazir, Ammar El and Barai, Atanu and Eker, Ali and Chennupati, Gopinath and Santhi, Nandakishore and Eidenbenz, Stephan},
  booktitle     = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi           = {10.1145/3458817.3476221},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Hybrid, Scalable, Trace-Driven Performance Modeling of GPGPUs - Arafa et al. - Proceeding.pdf:pdf},
  isbn          = {9781450384421},
  issn          = {21674337},
  keywords      = {Design Space Exploration,GPU,Modeling,Modeling and Simulation,NVIDIA GPUs,PTX,Performance Prediction,SASS},
  mendeley-tags = {GPU,Modeling},
  pages         = {1--15},
  title         = {{Hybrid, Scalable, Trace-Driven Performance Modeling of GPGPUs}},
  year          = {2021}
}
@inproceedings{Awan2016,
  abstract        = {Emerging paradigms like High Performance Data Analytics (HPDA) and Deep Learning (DL) pose at least two new design challenges for existing MPI runtimes. First, these paradigms require an efficient support for communicating unusually large messages across processes. And second, the communication buffers used by HPDA applications and DL frameworks generally reside on a GPU's memory. In this context, we observe that conventional MPI runtimes have been optimized over decades to achieve lowest possible communication latency for relatively smaller message sizes (up-to 1 Megabyte) and that too for CPU memory buffers. With the advent of CUDA-Aware MPI runtimes, a lot of research has been conducted to improve performance of GPU buffer based communication. However, little exists in current state of the art that deals with very large message communication of GPU buffers. In this paper, we investigate these new challenges by analyzing the performance bottlenecks in existing CUDA-Aware MPI runtimes like MVAPICH2-GDR, and propose hierarchical collective designs to improve communication latency of the MPI-Bcast primitive by exploiting a new communication library called NCCL. To the best of our knowledge, this is the first work that addresses these new requirements where GPU buffers are used for communication with message sizes surpassing hundreds of megabytes. We highlight the design challenges for our work along with the details of design and implementation. In addition, we provide a comprehensive performance evaluation using a Micro-benchmark and a CUDA-Aware adaptation of Microsoft CNTK DL framework. We report up to 47{\%} improvement in training time for CNTK using the proposed hierarchical MPI-Bcast design.},
  author          = {Awan, A. A. and Hamidouche, K. and Venkatesh, A. and Panda, D. K.},
  booktitle       = {ACM International Conference Proceeding Series},
  doi             = {10.1145/2966884.2966912},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/ACM International Conference Proceeding Series/Efficient large message broadcast using NCCL and CUDA-Aware MPI for deep learning - Awan et al. - ACM International Conference Proceedin.pdf:pdf},
  isbn            = {9781450342346},
  keywords        = {Broadcast,CUDA,Deep{\_}Learning,NCCL},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {Broadcast,CUDA,Deep{\_}Learning,NCCL},
  pages           = {15--22},
  title           = {{Efficient large message broadcast using NCCL and CUDA-Aware MPI for deep learning}},
  year            = {2016}
}
@article{Awan2019c,
  abstract        = {The current wave of advances in Deep Learning (DL) have been triggered by the availability of large-scale datasets, efficient CPU and GPU hardware, and development of software frameworks like TensorFlow (TF). However, little exists in literature that addresses TensorFlow's distributed training capabilities. In this paper, we provide an in-depth performance characterization and design analysis for distributed TensorFlow. We present three key insights: 1) Horovod designs achieve better performance compared to the official gRPC-based approaches, 2) performance of Horovod design is heavily influenced by the time spent in gradient aggregation that uses the Allreduce primitive, and 3) performance of existing Horovod-MPI implementation is significantly worse compared to Horovod-NCCL. To address this limitation in Horovod-MPI, we propose a novel and efficient CUDA-Aware MPI Allreduce design that 1) exploits CUDA kernels to perform large reductions on the GPU, 2) uses a com-bination of bandwidth-optimal and latency-optimal algorithms, and 3) maintains a pointer cache to avoid CUDA-driver query overheads in the critical path. The proposed designs deliver 5×, 17×, and 29{\%} better performance compared to NCCL2 for small, medium, and large messages. Our designs enable Horovod-MPI to beat state-of-the-art Horovod-NCCL2 by 3{\%} and achieve 90{\%} scaling efficiency for ResNet-50 training on 64 Pascal GPUs.},
  author          = {Awan, Ammar Ahmad and Bedorf, Jereon and Chu, Ching Hsiang and Subramoni, Hari and Panda, Dhabaleswar K.},
  doi             = {10.1109/CCGRID.2019.00064},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the IEEEACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)/Scalable distributed DNN training using TensorFlow and CUDA-Aware MPI Characterization, designs, and perf.pdf:pdf},
  isbn            = {9781728109121},
  journal         = {Proceedings of the IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)},
  keywords        = {CUDA,CUDA Aware MPI,Characterize,DNN Training,Deep{\_}Learning,GPU,GRPC,Horovod,MVAPICH2,TensorFlow},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {CUDA,Characterize,Deep{\_}Learning,GPU},
  pages           = {498--507},
  title           = {{Scalable distributed DNN training using TensorFlow and CUDA-Aware MPI: Characterization, designs, and performance evaluation}},
  year            = {2019}
}
@inproceedings{Awan2015,
  abstract        = {As we move towards efficient exascale systems, heterogeneous accelerators like NVIDIA GPUs are becoming a significant compute component of modern HPC clusters. It has become important to utilize every single cycle of every compute device available in the system. From NICs to GPUs to Co-processors, heterogeneous compute resources are the way to move forward. Another important trend, especially with the introduction of non-blocking collective communication in the latest MPI standard, is overlapping communication with computation. It has become an important design goal for messaging libraries like MVAPICH2 and OpenMPI. In this paper, we present an important benchmark that allows the users of different MPI libraries to evaluate performance of GPU-Aware Non- Blocking Collectives. The main performance metrics are overlap and latency. We provide insights on designing a GPU-Aware benchmark and discuss the challenges associated with identifying and implementing performance parameters like overlap, latency, effect of MPI Test() calls to progress communication, effect of independent GPU communication while the overlapped computation proceeds under the communication, and the effect of complexity, target, and scale of this overlapped computation. To illustrate the efficacy of the proposed benchmark, we provide a comparative performance evaluation of GPU-Aware Non-Blocking Collectives in MVAPICH2 and OpenMPI.},
  author          = {Awan, Ammar Ahmad and Hamidouche, K. and Venkatesh, A. and Perkins, J. and Subramoni, H. and Panda, D. K.},
  booktitle       = {Proceedings of the European MPI Users' Group Meeting (EuroMPI)},
  doi             = {10.1145/2802658.2802672},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Proceedings of the European MPI Users' Group Meeting (EuroMPI)/GPU-Aware design, implementation, and evaluation of non-blocking collective benchmarks - Awan et al. - Proceedings of the European MPI U.pdf:pdf},
  isbn            = {9781450337953},
  keywords        = {Benchmark,Collectives,GPU,GPU-Aware,MVAPICH2,Micro-benchmarking,Non-blocking collectives,OMB},
  mendeley-groups = {MustKnow,UsedInComp1,UsedInComp2},
  mendeley-tags   = {Benchmark,Collectives,GPU},
  pages           = {1--10},
  title           = {{GPU-Aware design, implementation, and evaluation of non-blocking collective benchmarks}},
  year            = {2015}
}
@techreport{Awan2020a,
  author          = {Awan, Ammar Ahmad and Hashmi, Jahanzeb Maqbool and Chu, Ching-hsiang and Subramoni, Hari},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Unknown/Designing a Deep-Learning Aware MPI Library An MVAPICH2 Approach WHAT IS DEEP LEARNING - Awan et al. - Unknown.pdf:pdf},
  keywords        = {Deep{\_}Learning,MPI},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {Deep{\_}Learning,MPI},
  title           = {{Designing a Deep-Learning Aware MPI Library : An MVAPICH2 Approach WHAT IS DEEP LEARNING ?}},
  year            = {2020}
}
@inproceedings{Awan2019a,
  abstract      = {Heterogeneous HPC systems with GPUs are increasingly getting equipped with on-node interconnects like PCIe and NVLink and inter-node interconnects like InfiniBand and Omni-Path. However, the efficient exploitation of these interconnects brings forth many challenges for MPI+CUDA applications. Little exists in the literature that captures the impact of these interconnects on emerging application areas like distributed Deep Learning (DL). In this paper, we choose Horovod; a distributed training middleware, to analyze and profile high-level application workloads (e.g., Training ResNet-50) instead of MPI microbenchmarks. It is challenging to use existing profilers like mpiP and nvprof as they only offer a black box approach and cannot profile emerging communication libraries like NCCL. To address this, we developed a profiler for Horovod that enables profiling of various communication primitives including MPI-Allreduce and ncclAllreduce for gradient exchange as well for Horovod's communication threads and response caches. We analyze the following metrics to gain insights into network-level performance on different interconnects: 1) Message size with tensor fusion, 2) Message size without tensor fusion, 3) Number of MPI and NCCL calls made for each message size, and 4) Time taken by each NCCL and/or MPI call. We also correlate these low-level statistics to higher level end-to-end training metrics like images per second. Three keys insights we gained are: 1) Horovod tensor fusion offers slight performance gains (up to 5{\%}) for CPU-based training on InfiniBand systems, 2) For GPU-based training, disabling tensor fusion improved performance (up to 17{\%}) for GPUs connected with PCIe, and 3) The allreduce latency profiles show some extreme performance variations for non-power-of-two message sizes for both CPUs and GPU on all interconnects when tensor fusion is enabled. To provide a comprehensive view of performance, we use a wide variety of systems with CPUs like Intel Skylake, AMD EPYC, and IBM POWER9, GPUs like Volta V100, and interconnects like PCIe, NVLink, InfiniBand, and Omni-Path.},
  author        = {Awan, Ammar Ahmad and Jain, Arpan and Chu, Ching Hsiang and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle     = {Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)},
  doi           = {10.1109/HOTI.2019.00025},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)/Communication profiling and characterization of deep learning workloads on clusters with high-performance interconnects - Awan e.pdf:pdf},
  isbn          = {9781728155258},
  keywords      = {Deep{\_}Learning,Horovod,InfiniBand,Intel{\_}Omni{\_}Path,MPI,MVAPICH2 MPI,NVLink,Omni-Path,PCI{\_}E,PCIe,TensorFlow},
  mendeley-tags = {Deep{\_}Learning,Horovod,InfiniBand,Intel{\_}Omni{\_}Path,MPI,NVLink,PCI{\_}E},
  pages         = {49--53},
  title         = {{Communication profiling and characterization of deep learning workloads on clusters with high-performance interconnects}},
  year          = {2019}
}
@article{Awan2020,
  abstract      = {Heterogeneous high-performance computing systems with GPUs are equipped with high-performance interconnects like InfiniBand, Omni-Path, PCIe, and NVLink. However, little exists in the literature that captures the performance impact of these interconnects on distributed deep learning (DL). In this article, we choose Horovod, a distributed training middleware, to analyze and profile various DNN training workloads using TensorFlow and PyTorch in addition to standard MPI microbenchmarks. We use a wide variety of systems with CPUs like Intel Xeon and IBM POWER9, GPUs like Volta V100, and various interconnects to analyze the following metrics: 1) message-size with Horovod's tensor-fusion; 2) message-size without tensor-fusion; 3) number of MPI/NCCL calls; and 4) time taken by each MPI/NCCL call. We observed extreme performance variations for non-power-of-two message sizes on different platforms. To address this, we design a message-padding scheme for Horovod, illustrate significantly smoother allreduce latency profiles, and report cases where we observed improvement for end-to-end training.},
  author        = {Awan, Ammar Ahmad and Jain, Arpan and Chu, Ching Hsiang and Subramoni, Hari and Panda, Dhableswar K.},
  doi           = {10.1109/MM.2019.2949986},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/IEEE Micro/Communication profiling and characterization of deep-learning workloads on clusters with high-performance interconnects - Awan et al. -.pdf:pdf},
  issn          = {19374143},
  journal       = {IEEE Micro},
  keywords      = {Characterize,Communication Libraries,Deep{\_}Learning,Horovod,InfiniBand,MVAPICH2 MPI,NVLink,Omni-Path,PCIe,Performance Analysis,Profiling,TensorFlow},
  mendeley-tags = {Characterize,Deep{\_}Learning},
  number        = {1},
  pages         = {35--43},
  title         = {{Communication profiling and characterization of deep-learning workloads on clusters with high-performance interconnects}},
  volume        = {40},
  year          = {2020}
}
@article{Awan2019,
  abstract        = {Traditionally, MPI runtimes have been designed for clusters with a large number of nodes. However, with the advent of MPI+CUDA applications and GPU clusters with a relatively smaller number of nodes, efficient communication schemes need to be designed for such systems. This coupled with new application workloads brought forward by Deep Learning (DL) frameworks like Caffe and Microsoft Cognitive Toolkit (CNTK) pose additional design constraints due to very large message communication of GPU buffers during the training phase. In this context, special-purpose libraries like NVIDIA NCCL have emerged to deal with DL workloads. In this paper, we address these new challenges for MPI runtimes and propose two new designs to deal with them: (1) A pipelined chain (PC) design for MPI{\_}Bcast that provides efficient intra- and inter-node communication of GPU buffers, and (2) A Topology-Aware pipelined chain (TA-PC) design for systems with multiple GPUs to fully exploit all the available PCIe links available within a multi-GPU node. To highlight the benefits of our designs, we present an in-depth performance landscape for the proposed MPI{\_}Bcast (MPI) designs, our earlier NCCL-based MPI{\_}Bcast (MPI+NCCL1) design, and ncclBroadcast (NCCL2) design. The proposed designs offer up to 14 × and 16.6 × better performance than MPI+NCCL1 based solutions for intra- and inter-node broadcast latency, respectively. With the recent introduction of NCCL2 (inter-node capable) library, we have enhanced our performance results by adding comparisons for the proposed MPI{\_}Bcast designs as well as ncclBroadcast (NCCL2) design. We report up to 10 × better performance for small and medium message sizes and comparable performance for large message sizes. We also observed that the TA-PC design is up to 50{\%} better than the PC design for MPI{\_}Bcast to 64 GPUs. Furthermore, we provide application level performance comparison using a CUDA-Aware version of CNTK called CA-CNTK. The proposed MPI{\_}Bcast designs provide up to 7{\%} improvement over MPI+NCCL based solutions for data parallel training of the VGG network on 128 GPUs. We present our performance evaluation on three GPU clusters with diverse characteristics: (1) KESCH; a dense multi-GPU system with 8 K80 GPU cards per node, (2) RI2; with a single K80 GPU card per node, and (3) Owens; with a single P100 GPU per node.},
  author          = {Awan, Ammar Ahmad and Manian, Karthik Vadambacheri and Chu, Ching Hsiang and Subramoni, Hari and Panda, Dhabaleswar K.},
  doi             = {10.1016/j.parco.2019.03.005},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Parallel Computing/Optimized large-message broadcast for deep learning workloads MPI, MPINCCL, or NCCL2 - Awan et al. - Parallel Computing.pdf:pdf},
  issn            = {01678191},
  journal         = {Parallel Computing},
  keywords        = {Broadcast,CUDA,CUDA-Aware MPI,Deep{\_}Learning,Distributed d learning,GPU,HPC,MPI{\_}Bcast,NCCL},
  mendeley-groups = {MustKnow,UsedInComp1,UsedInComp2},
  mendeley-tags   = {Broadcast,CUDA,Deep{\_}Learning,GPU,NCCL},
  pages           = {141--152},
  title           = {{Optimized large-message broadcast for deep learning workloads: MPI, MPI+NCCL, or NCCL2?}},
  volume          = {85},
  year            = {2019}
}
@inproceedings{Awan2018,
  abstract        = {Traditionally, MPI runtimes have been designed for clusters with a large number of nodes. However, with the advent of MPI+CUDA applications and dense multi-GPU systems, it has become important to design efficient communication schemes. This coupled with new application workloads brought forward by Deep Learning frameworks like Caffe and Microsoft CNTK pose additional design constraints due to very large message communication of GPU buffers during the training phase. In this context, special-purpose libraries like NCCL have been proposed. In this paper, we propose a pipelined chain (ring) design for the MPI{\_}Bcast collective operation along with an enhanced collective tuning framework in MVAPICH2-GDR that enables efficient intra-/inter-node multi-GPU communication. We present an in-depth performance landscape for the proposed MPI{\_}Bcast schemes along with a comparative analysis of NCCL Broadcast and NCCL-based MPI{\_}Bcast. The proposed designs for MVAPICH2-GDR enable up to 14X and 16.6X improvement, compared to NCCL-based solutions, for intra- and inter-node broadcast latency, respectively. In addition, the proposed designs provide up to 7{\%} improvement over NCCL-based solutions for data parallel training of the VGG network on 128 GPUs using Microsoft CNTK. The proposed solutions outperform the recently introduced NCCL2 library for small and medium message sizes and offer comparable/better performance for very large message sizes.},
  author          = {Awan, Ammar Ahmad and Subramoni, Hari and Chu, Ching Hsiang and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the European MPI Users' Group Meeting (EuroMPI)},
  doi             = {10.1145/3236367.3236381},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the European MPI Users' Group Meeting (EuroMPI)/Optimized broadcast for deep learning workloads on dense-GPU InfiniBand clusters MPI or NCCL - Awan et al. - Proceedings of the European.pdf:pdf},
  isbn            = {9781450364928},
  keywords        = {Broadcast,CUDA,CUDA-Aware MPI,Deep{\_}Learning,Distributed Deep Learning,GPU,HPC,MPI,MPI{\_}Bcast,NCCL},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {Broadcast,CUDA,Deep{\_}Learning,GPU,MPI,NCCL},
  pages           = {1--9},
  title           = {{Optimized broadcast for deep learning workloads on dense-GPU InfiniBand clusters: MPI or NCCL?}},
  year            = {2018}
}
@article{Awan2017,
  abstract        = {Traditionally, Deep Learning (DL) frameworks like Caffe, TensorFlow, and Cognitive Toolkit exploited GPUs to accelerate the training process. This has been primarily achieved by aggressive improvements in parallel hardware as well as through sophisticated software frameworks like cuDNN and cuBLAS. However, recent enhancements to CPU-based hardware and software has the potential to significantly enhance the performance of CPU-based DL training. In this paper, we provide a complete performance landscape of CPU- and GPU-based DNN training. We characterize performance of DNN training for AlexNet and ResNet-50 for a wide-range of CPU and GPU architectures including the latest Intel Xeon Phi (Knights Landing) processors and NVIDIA Pascal GPUs. We also present multi-node DNN training performance results for AlexNet and ResNet-50 using Intel Machine Learning Scaling (MLSL) Library and Intel-Caffe. In addition, we provide a CPU vs. GPU comparison for multi-node training using OSU-Caffe and Intel-Caffe. To the best of our knowledge, this is the first study that dives deeper into the performance of DNN training in a holistic manner yet provides an in-depth look at layer-wise performance for different DNNs. We provide multiple key insights: 1) Convolutions account for the majority of time (up to 83{\%} time) consumed in DNN training, 2) GPU-based training continues to deliver excellent performance (up to 18{\%} better than KNL) across generations of GPU hardware and software, and 3) Recent CPU-based optimizations like MKL-DNN and OpenMP-based thread parallelism leads to excellent speed-ups over under-optimized designs (up to 3.2X improvement for AlexNet training).},
  author          = {Awan, Ammar Ahmad and Subramoni, Hari and Panda, Dhabaleswar K.},
  doi             = {10.1145/3146347.3146356},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/An In-depth Performance Characterization of CPU- and GPU-based DNN Training on Modern Arc.pdf:pdf},
  isbn            = {9781450351379},
  journal         = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  keywords        = {Caffe,Deep Learning,High-Performance Computing,Pascal Architecture,Unified Memory},
  mendeley-groups = {MustKnow},
  title           = {{An In-depth Performance Characterization of CPU- and GPU-based DNN Training on Modern Architectures}},
  year            = {2017}
}
@inproceedings{Ayala2019,
  abstract        = {Most applications targeting exascale, such as those part of the Exascale Computing Project (ECP), are designed for heterogeneous architectures and rely on the Message Passing Interface (MPI) as their underlying parallel programming model. In this paper we analyze the limitations of collective MPI communication for the computation of fast Fourier transforms (FFTs), which are relied on heavily for large-scale particle simulations. We present experiments made at one of the largest heterogeneous platforms, the Summit supercomputer at ORNL. We discuss communication models from state-of-the-art FFT libraries, and propose a new FFT library, named HEFFTE (Highly Efficient FFTs for Exascale), which supports heterogeneous architectures and yields considerable speedups compared with CPU libraries, while maintaining good weak as well as strong scalability.},
  author          = {Ayala, Alan and Tomov, Stanimire and Luo, Xi and Shaeik, Hejer and Haidar, Azzam and Bosilca, George and Dongarra, Jack},
  booktitle       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi             = {10.1109/ExaMPI49596.2019.00007},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Impacts of Multi-GPU MPI Collective Communications on Large FFT Computation - Ayala et al.pdf:pdf},
  isbn            = {9781728160092},
  keywords        = {Collectives,GPU,Multi{\_}GPU},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Collectives,GPU,Multi{\_}GPU},
  pages           = {12--18},
  title           = {{Impacts of Multi-GPU MPI Collective Communications on Large FFT Computation}},
  year            = {2019}
}
@inproceedings{Bak2019,
  abstract      = {On-node parallelism continues to increase in importance for high-performance computing and most newly deployed supercomputers have tens of processor cores per node. These higher levels of on-node parallelism exacerbate the impact of load imbalance and locality in parallel computations, and current programming systems notably lack features to enable efficient use of these large numbers of cores or require users to modify codes significantly. Our work is motivated by the need to address application-specific load balance and locality requirements with minimal changes to application codes. In this paper, we propose a new approach to extend the specification of parallel loops via user functions that specify iteration chunks. We also extend the runtime system to invoke these user functions when determining how to create chunks and schedule them on worker threads. Our runtime system starts with subspaces specified in the user functions, performs load balancing of chunks concurrently, and stores the balanced groups of chunks to reduce load imbalance in future invocations. Our approach can be used to improve load balance and locality in many dynamic iterative applications, including graph and sparse matrix applications. We demonstrate the benefits of this work using MiniMD, a miniapp derived from LAMMPS, and three kernels from the GAP Benchmark Suite: Breadth-First Search, Connected Components, and PageRank, each evaluated with six different graph data sets. Our approach achieves geometric mean speedups of 1.16× to 1.54× over four standard OpenMP schedules and 1.07× over the static{\_}steal schedule from recent research.},
  author        = {Bak, Seonmyeong and Guo, Yanfei and Balaji, Pavan and Sarkar, Vivek},
  booktitle     = {ACM International Conference Proceeding Series},
  doi           = {10.1145/3337821.3337913},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/ACM International Conference Proceeding Series/Optimized execution of parallel loops via user-defined scheduling policies - Bak et al. - ACM International Conference Proceeding Series.pdf:pdf},
  isbn          = {9781450362955},
  keywords      = {Load Balancing,Load{\_}Balancing,Loop Parallelism,OpenMP,User-Defined Scheduling},
  mendeley-tags = {Load{\_}Balancing,OpenMP},
  title         = {{Optimized execution of parallel loops via user-defined scheduling policies}},
  year          = {2019}
}
@inproceedings{Balaji2009,
  abstract      = {Petascale machines with close to a million processors will soon be available. Although MPI is the dominant programming model today, some researchers and users wonder (and perhaps even doubt) whether MPI will scale to such large processor counts. In this paper, we examine this issue of how scalable is MPI. We first examine the MPI specification itself and discuss areas with scalability concerns and how they can be overcome. We then investigate issues that an MPI implementation must address to be scalable. We ran some experiments to measure MPI memory consumption at scale on up to 131,072 processes or 80{\%} of the IBM Blue Gene/P system at Argonne National Laboratory. Based on the results, we tuned the MPI implementation to reduce its memory footprint. We also discuss issues in application algorithmic scalability to large process counts and features of MPI that enable the use of other techniques to overcome scalability limitations in applications. {\textcopyright} 2009 Springer Berlin Heidelberg.},
  author        = {Balaji, Pavan and Buntinas, Darius and Goodell, David and Gropp, William and Kumar, Sameer and Lusk, Ewing and Thakur, Rajeev and Tr{\"{a}}ff, Jesper Larsson},
  booktitle     = {Proceedings of the European Parallel Virtual Machine / Message Passing Interface Users' Group Meeting (EuroPVM/MPI)},
  doi           = {10.1007/978-3-642-03770-2-9},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2009/Proceedings of the European Parallel Virtual Machine Message Passing Interface Users' Group Meeting (EuroPVMMPI)/MPI on a million processors - Balaji et al. - Proceedings of the European Parallel Virtua.pdf:pdf},
  isbn          = {3642037690},
  issn          = {03029743},
  keywords      = {BlueGene,MPI},
  mendeley-tags = {BlueGene,MPI},
  pages         = {20--30},
  title         = {{MPI on a million processors}},
  year          = {2009}
}
@article{Balaji2010,
  abstract      = {Modern HEC systems, such as Blue Gene/P, rely on achieving high-performance by using the parallelism of a massive number of low-frequency/low-power processing cores. This means that the local pre- and post-communication processing required by the MPI stack might not be very fast, owing to the slow processing cores. Similarly, small amounts of serialization within the MPI stack that were acceptable on small/medium systems can be brutal on massively parallel systems. In this paper, we study different non-data-communication overheads within the MPI implementation on the IBM Blue Gene/P system.},
  author        = {Balaji, Pavan and Chan, A. and Gropp, W. and Thakur, Rajeev and Lusk, E.},
  doi           = {10.1177/1094342009359258},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2010/The International Journal of High Performance Computing Applications/The Importance of Non-Data-Communication Overheads in MPI - Balaji et al. - The International Journal of High Performance Computing Ap.pdf:pdf},
  isbn          = {1094342009},
  issn          = {1094-3420},
  journal       = {The International Journal of High Performance Computing Applications},
  keywords      = {BlueGene,MPI,blue gene,mpi,non-data-communication,p},
  mendeley-tags = {BlueGene,MPI},
  number        = {1},
  pages         = {5--15},
  title         = {{The Importance of Non-Data-Communication Overheads in MPI}},
  volume        = {24},
  year          = {2010}
}
@inproceedings{Banerjee2016,
  abstract      = {Graphics Processing Units (GPUs) have gained the position of a main stream accelerator due to its low power footprint and massive parallelism. CUDA 6.0 onward, NVIDIA has introduced the Managed Memory capability which unifies the host and device memory allocations into a single allocation and removes the requirement for explicit memory transfers between either memories. Several applications particularly of irregular nature can have immense benefits from managed memory because of the high productivity in programming that can be achieved owing to the minimal effort involved in the data management and movement. The MVAPICH2 library utilizes runtime designs such as CUDA Inter Process Communications (IPC) and GPUDirect RDMA (GDR) under the CUDA-Aware concept, to offer high productivity and programmability with MPI on modern clusters. However, integration and interaction of managed memory with these features raises challenges for efficient small and large message communications. In this study, we present an initial evaluation of managed memory capability and its interaction with existing high performance designs and features available in MVAPICH2 library. We propose new designs to enable efficient communication support between managed memory buffers. We also perform fine tuning to optimize the transfers between managed memories residing in GPUs. To the best of our knowledge, this is the first evaluation and study of managed memory and its interaction with MPI runtimes. A detailed evaluation and analysis of the performance of the proposed designs is presented. The Stencil2D communication kernel available in the SHOC suite was re-designed to enable the managed memory support. The evaluation shows a 4x improvement in the timings of stencil exchanges on 16 GPU nodes.},
  author        = {Banerjee, Dip Sankar and Hamidouche, Khaled and Panda, Dhabaleswar K.},
  booktitle     = {Proceedings of the Workshop on General Purpose Processing using GPUs (GPGPU)},
  doi           = {10.1145/2884045.2884050},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the Workshop on General Purpose Processing using GPUs (GPGPU)/Designing high performance communication runtime for GPU managed memory Early experiences - Banerjee, Hamidouche, Panda - Proc.pdf:pdf},
  isbn          = {9781450341950},
  keywords      = {GPU,Runtime},
  mendeley-tags = {GPU,Runtime},
  pages         = {82--91},
  title         = {{Designing high performance communication runtime for GPU managed memory: Early experiences}},
  year          = {2016}
}
@inproceedings{Worley2020,
  author        = {Bangalore, Purushotham and Worley, Andrew and Schafer, Derek and Grant, Ryan E and Skjellum, Anthony},
  booktitle     = {Proceedings of the European MPI Users' Group Meeting (EuroMPI)},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the European MPI Users' Group Meeting (EuroMPI)/A Portable Implementation of Partitioned Point-to-Point Communication Primitives - Bangalore et al. - Proceedings of the European MPI Us.pdf:pdf},
  keywords      = {MPI,P2P,acm reference format,high-performance computing,hybrid programming,message passing,middleware,portability},
  mendeley-tags = {MPI,P2P},
  pages         = {1--3},
  title         = {{A Portable Implementation of Partitioned Point-to-Point Communication Primitives}},
  year          = {2020}
}
@inproceedings{Bangalore2021,
  author        = {Bangalore, Purushotham and Worley, Andrew and Schafer, Derek and Grant, Ryan E and Skjellum, Anthony},
  booktitle     = {Proceedings of the International Conference on Parallel Processing Workshops},
  doi           = {10.1145/3458744.3474046},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the International Conference on Parallel Processing Workshops/Design of a Portable Implementation of Partitioned Point-to-Point Communication Primitives - Bangalore et al. - Proceedings of.pdf:pdf},
  isbn          = {9781450384414},
  keywords      = {MPI,P2P,Partitioned,high-performance computing,hybrid programming,message passing,middleware,portability},
  mendeley-tags = {MPI,P2P,Partitioned},
  pages         = {1--11},
  title         = {{Design of a Portable Implementation of Partitioned Point-to-Point Communication Primitives}},
  year          = {2021}
}
@article{Barham2022,
  archiveprefix = {arXiv},
  arxivid       = {2203.12533},
  author        = {Barham, Paul and Chowdhery, Aakanksha and Dean, Jeff and Ghemawat, Sanjay and Hand, Steven and Hurt, Dan and Isard, Michael and Lim, Hyeontaek and Pang, Ruoming and Roy, Sudip and Saeta, Brennan and Schuh, Parker and Sepassi, Ryan and El, Laurent and Chandramohan, Shafey and Yonghui, A Thekkath},
  eprint        = {2203.12533},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/arXiv/Pathways A Synchronous Distributed Dataflow For ML - Barham et al. - arXiv.pdf:pdf},
  journal       = {arXiv},
  keywords      = {Deep{\_}Learning,Distributed,Machine{\_}Learning,TPU},
  mendeley-tags = {Deep{\_}Learning,Distributed,Machine{\_}Learning,TPU},
  pages         = {1--20},
  title         = {{Pathways: A Synchronous Distributed Dataflow For ML}},
  year          = {2022}
}
@article{Barrett2014,
  abstract        = {Power and energy concerns are motivating chip manufacturers to consider future hybrid-core processor designs that may combine a small number of traditional cores optimized for single-thread performance with a large number of simpler cores optimized for throughput performance. This trend is likely to impact the way in which compute resources for network protocol processing functions are allocated and managed. In particular, the performance of MPI match processing is critical to achieving high message throughput. In this paper, we analyze the ability of simple and more complex cores to perform MPI matching operations for various scenarios in order to gain insight into how MPI implementations for future hybrid-core processors should be designed.},
  author          = {Barrett, Brian W. and Brightwell, Ron and Grant, Ryan and Hammond, Simon D. and Hemmert, K. Scott},
  doi             = {10.1177/1094342014552085},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/International Journal of High Performance Computing Applications/An evaluation of MPI message rate on hybrid-core processors - Barrett et al. - International Journal of High Performance Computing Appli.pdf:pdf},
  issn            = {17412846},
  journal         = {International Journal of High Performance Computing Applications},
  keywords        = {HPC,MPI,Message Rate,Xeon Phi,network},
  mendeley-groups = {ELEC-878},
  number          = {4},
  pages           = {415--424},
  title           = {{An evaluation of MPI message rate on hybrid-core processors}},
  volume          = {28},
  year            = {2014}
}
@article{Barrett2022,
  author          = {Barrett, Brian W and Brightwell, Ron and Grant, Ryan E and Schonbein, Whit and Hemmert, Scott and Pedretti, Kevin and Underwood, Keith and Riesen, Rolf and Hoefler, Torsten and Barbe, Mathieu and Filho, Luiz H Suraty and Ratchov, Alexandre and Maccabe, Arthur B},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Unknown/SANDIA REPORT The Portals 4.3 Network Programming Interface - Barrett et al. - Unknown.pdf:pdf},
  keywords        = {Portals Sandia network programming API},
  mendeley-groups = {ELEC-878},
  number          = {June},
  title           = {{SANDIA REPORT The Portals 4.3 Network Programming Interface}},
  url             = {https://classic.ntis.gov/help/order-methods},
  year            = {2022}
}
@techreport{Barrett2017,
  abstract      = {Portals 4 is an advanced network programming interface which allows for the development of a rich set of upper layer protocols. By careful selection of interfaces and strong progress guarantees, Portals 4 is able to support multiple protocols without significant overhead. Recent developments with Portals 4, including development of MPI, SHMEM, and GASNet protocols are discussed. {\textcopyright} 2012 IEEE.},
  author        = {Barrett, Brian and Brightwell, Ron and Underwood, Keith and Hemmert, K. Scott},
  booktitle     = {Sandia National Laboratories},
  doi           = {10.1109/SC.Companion.2012.264},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Sandia National Laboratories/Portals 4 network programming interface - Barrett et al. - Sandia National Laboratories.pdf:pdf},
  isbn          = {9780769549569},
  keywords      = {Network,Portals,hpc,network,portals},
  mendeley-tags = {Network,Portals},
  number        = {April},
  pages         = {1--154},
  title         = {{Portals 4 network programming interface}},
  year          = {2017}
}
@inproceedings{Bayatpour2016,
  abstract      = {The Message Passing Interface (MPI) standard specifies the use of (source, tag, communicator) tuple to identify whether an incoming message is what the receiver process is expecting. The cost associated with this process, commonly known as "tag matching", is tightly coupled with the communication pattern of the application and the load it generates at each individual process. Although researchers have proposed several schemes to mitigate the cost of tag matching, they have all been static and do not adapt dynamically to the communication load at individual processes and can lead to degradation in tag matching times. Such static designs can also lead to unnecessary memory overheads for queue management at processes whose communication loads do not justify enhanced tag matching schemes. In this paper, we take up this challenge and propose a tag matching design which dynamically adapts to the communication load at each individual process at runtime. Our experimental evaluation shows that the proposed adaptive and dynamic tag matching scheme is able to deliver the best performance when compared with multiple state-of-the-art tag matching schemes while limiting the memory consumed to the absolute minimum necessary to deliver the desired performance benefits. For instance, with HPCG, the adaptive scheme delivers 20{\%}, 32{\%} and up to 2X improvements in tag matching performance when compared to the default, binbased and rank-based schemes, respectively. To the best of our knowledge this is the first tag matching design that is capable of dynamically adapting to the communication requirements of end applications.},
  author        = {Bayatpour, M. and Subramoni, H. and Chakraborty, S. and Panda, D. K.},
  booktitle     = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi           = {10.1109/CLUSTER.2016.69},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/Adaptive and dynamic design for MPI tag matching - Bayatpour et al. - Proceedings of the IEEE International Conference on C.pdf:pdf},
  isbn          = {9781509036530},
  issn          = {15525244},
  keywords      = {Adaptive,MPI,Message{\_}Matching,Tag{\_}Matching},
  mendeley-tags = {Adaptive,MPI,Message{\_}Matching,Tag{\_}Matching},
  pages         = {1--10},
  title         = {{Adaptive and dynamic design for MPI tag matching}},
  year          = {2016}
}
@inproceedings{Bayatpour2017,
  abstract        = {Existing designs for MPI Allreduce do not take advantage of the vast parallelism available in modern multi-/many-core processors like Intel Xeon/Xeon Phis or the increases in communication throughput and recent advances in high-end features seen with modern interconnects like InfiniBand and Omni-Path. In this paper, we propose a high-performance and scalable Data Partitioning-based Multi-Leader (DPML) solution for MPI Allreduce that can take advantage of the parallelism ofered by multi-/many-core architectures in conjunction with the high throughput and high-end features offered by InfiniBand and Omni-Path to significantly enhance the performance of MPI Allreduce on modern HPC systems. We also model DPML-based designs to analyze the communication costs theoretically. Microbenchmark level evaluations show that the proposed DPML-based designs are able to deliver up to 3.5 times performance improvement for MPI Allreduce for multiple HPC systems at scale. At the application-level, up to 35{\%} and 60{\%} improvement is seen in communication for HPCG and miniAMR respectively.},
  author          = {Bayatpour, Mohammadreza and Chakraborty, Sourav and Subramoni, Hari and Lu, Xiaoyi and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi             = {10.1145/3126908.3126954},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Scalable reduction collectives with data partitioning-based multi-leader design - Bayatpo.pdf:pdf},
  isbn            = {9781450351140},
  keywords        = {Collectives,Data partitioning,MPI,MPI allreduce,Multi-leader,SHArP,Sharp},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,MPI,Sharp},
  pages           = {1--11},
  title           = {{Scalable reduction collectives with data partitioning-based multi-leader design}},
  year            = {2017}
}
@inproceedings{Bayatpour2020,
  abstract        = {Message Passing Interface (MPI) standard uses (source rank, tag, and communicator id) to properly place the incoming data into the application receive buffer. The act of searching through the receive queues and finding the appropriate match is called Tag Matching (TM). In the state-of-the-art MPI libraries, this operation is either being performed by the main thread or a separate communication progress thread. Either way leads to underutilization of the resources and major synchronization overheads leading to less optimal performance. Mellanox ConnectX-5 network architecture has introduced a feature to offload the Tag Matching and communication progress from host to InfiniBand network card. This paper proposes a Hardware Tag Matching aware MPI library and discusses various aspects and challenges of leveraging this feature in MPI library. Moreover, it characterizes hardware Tag Matching using different benchmarks and provides guidelines for the application developers to develop Hardware Tag Matching-aware applications to maximize their usage of this feature. Our proposed designs are able to improve the performance of non-blocking collectives up to 42{\%} on 512 nodes and improve the performance of 3Dstencil application kernel on 7168 processes and Nekbone on 512 processes by a factor 40{\%} and 3.5{\%}, respectively.},
  author          = {Bayatpour, Mohammadreza and Ghazimirsaeed, S. Mahdieh and Xu, Shulei and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)},
  doi             = {10.1109/CCGrid49817.2020.00-83},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the IEEEACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)/Design and Characterization of InfiniBand Hardware Tag Matching in MPI - Bayatpour et al. - Proceedings o.pdf:pdf},
  isbn            = {9781728160955},
  keywords        = {Hardware Offload,InfiniBand,MPI,Message{\_}Matching,Point-to-point communication,Tag Matching},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {InfiniBand,MPI,Message{\_}Matching},
  pages           = {101--110},
  title           = {{Design and Characterization of InfiniBand Hardware Tag Matching in MPI}},
  year            = {2020}
}
@article{Bayatpour2018,
  abstract        = {Message Passing Interface (MPI), thus far, has remained a dominant programming model to program large-scale scientific applications. Collective communication operations in MPI are of significant importance due to their communication intensive nature and use in scientific applications. With the emergence of multi-/many-core systems and rise of deep learning applications, it is important to revisit MPI collectives, particularly MPI Allreduce to exploit vast parallelism offered by modern architectures. In this paper, we take up this challenge and propose Scalable and Adaptive designs for Large message Reduction collectives (SALaR). We focus on MPI Allreduce due to its use in deep learning frameworks and propose new designs that can significantly improve its performance by exploiting architectural features of modern multi-/many-cores in tandem with high-throughput network such as InfiniBand. We also propose a theoretical model to analyze communication and computation cost and use these insights to guide our designs. The evaluation of the proposed SALaR based designs shows significant performance gains over state-of-the-art designs on a wide variety of micro-benchmarks and applications.},
  author          = {Bayatpour, Mohammadreza and {Maqbool Hashmi}, Jahanzeb and Chakraborty, Sourav and Subramoni, Hari and Kousha, Pouya and Panda, Dhabaleswar K.},
  doi             = {10.1109/CLUSTER.2018.00014},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/SALaR Scalable and Adaptive Designs for Large Message Reduction Collectives - Bayatpour et al. - Proceedings of the IEEE In.pdf:pdf},
  isbn            = {9781538683194},
  issn            = {15525244},
  journal         = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  keywords        = {Allreduce,Collectives,MPI,Shared memory,Xpmem},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,MPI},
  pages           = {12--23},
  title           = {{SALaR: Scalable and Adaptive Designs for Large Message Reduction Collectives}},
  year            = {2018}
}
@inproceedings{Bayatpour2020a,
  abstract        = {Abstract. Overlap of computation and communication is critical for good application-level performance. Modern high-performance networks offer Hardware-assisted tag matching and rendezvous offload to enable communication progress without involving the host CPU. However, hardware based offload cannot be used in many situations due to various hardware limitations and performance issues. Furthermore, hardware-based designs cannot provide good overlap for common communication patterns involving unexpected messages or non-contiguous datatypes. In this paper, we address these limitations by designing a communication-aware overlap engine for MPI that uses novel hardware-assisted and softwarebased solutions to extract overlap for both expected and unexpected messages. The proposed design adapts to the application's communication requirements including message size, datatype, and relative timing of processes using heuristics and history-driven predictions. We evaluate the proposed designs against state-of-the-art MPI libraries and show up to 41{\%} and 22{\%} reduction in latency for collective operations and stencil-based application kernels on 1024 and 128 nodes, respectively, as well as 23{\%} improvement in communication performance of the P3DFFT application},
  author          = {Bayatpour, Mohammadreza and Maqbool, Jahanzeb Hashmi and Chakraborty, Sourav and Ghazimirsaeed, S. Mahdieh and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the International Conference on Supercomputing (ICS)},
  doi             = {10.1007/978-3-030-50743-5},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the International Conference on Supercomputing (ICS)/Communication-Aware Hardware-Assisted MPI Overlap Engine - Bayatpour et al. - Proceedings of the International Conference on Supercompu.pdf:pdf},
  isbn            = {9783030507435},
  keywords        = {MPI,Message{\_}Matching},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Message{\_}Matching},
  pages           = {517--535},
  title           = {{Communication-Aware Hardware-Assisted MPI Overlap Engine}},
  year            = {2020}
}
@article{BeheshtiRoui2020,
  abstract      = {Graphics processing units (GPUs) are widely used for scientific and engineering applications with high level of parallelism. The computing power of GPUs is improving through enhancing their architectural facilities. NVIDIA's compute unified device architecture (CUDA) stream using hyper-Q on NVIDIA graphic cards is a reputable capability for performance improvement. Without any synchronization and based on architectural capabilities, NVIDIA's CUDA stream allows some processes to run simultaneously. Experimental results show that how to stream a number of programs affect the execution time. Therefore, the stream set with the highest amount of performance improvement is the efficient stream set. This article proposes a framework to predict the efficient stream set on two streams without trying all combinations, which would be a very time-consuming process. The proposed framework employs a performance model and a scheduler. The performance model estimates the duration of simultaneous portions of streamed programs and the scheduler uses the estimation of the model to predict the efficient stream set. The proposed prediction method relies on non-stream features of programs. The results show that even with 33{\%} error of performance model in average, the scheduler predicts the optimized sets with 100{\%} precision.},
  author        = {{Beheshti Roui}, Mohamad and Shekofteh, S. Kazem and Noori, Hamid and Harati, Ahad},
  doi           = {10.1007/s11227-020-03209-x},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Journal of Supercomputing/Efficient scheduling of streams on GPGPUs - Beheshti Roui et al. - Journal of Supercomputing.pdf:pdf},
  issn          = {15730484},
  journal       = {Journal of Supercomputing},
  keywords      = {Efficient CUDA streaming,Efficient stream combination,GPGPU code optimization,GPU,Performance estimation,Performance model,Scheduling,Stream scheduling},
  mendeley-tags = {GPU,Scheduling},
  pages         = {1--34},
  title         = {{Efficient scheduling of streams on GPGPUs}},
  year          = {2020}
}
@article{Ben-Nun2019,
  abstract        = {Deep Neural Networks (DNNs) are becoming an important tool in modern computing applications. Accelerating their training is a major challenge and techniques range from distributed algorithms to low-level circuit design. In this survey, we describe the problem from a theoretical perspective, followed by approaches for its parallelization. We present trends in DNN architectures and the resulting implications on parallelization strategies. We then review and model the different types of concurrency in DNNs: from the single operator, through parallelism in network inference and training, to distributed deep learning. We discuss asynchronous stochastic optimization, distributed system architectures, communication schemes, and neural architecture search. Based on those approaches, we extrapolate potential directions for parallelism in deep learning.},
  author          = {Ben-Nun, Tal and Hoefler, Torsten},
  doi             = {10.1145/3320060},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/ACM Computing Surveys/Demystifying parallel and distributed deep learning An in-depth concurrency analysis - Ben-Nun, Hoefler - ACM Computing Surveys.pdf:pdf},
  issn            = {15577341},
  journal         = {ACM Computing Surveys},
  keywords        = {Deep learning,Deep{\_}Learning,Distributed,Distributed computing,Parallel algorithms,Survey},
  mendeley-groups = {MustKnow,UsedInComp1,UsedInComp2},
  mendeley-tags   = {Deep{\_}Learning,Distributed,Survey},
  number          = {4},
  pages           = {1--43},
  title           = {{Demystifying parallel and distributed deep learning: An in-depth concurrency analysis}},
  volume          = {52},
  year            = {2019}
}
@inproceedings{Ben-Nun2015,
  abstract      = {With the increased popularity of multi-GPU nodes in modern HPC clusters, it is imperative to develop matching programming paradigms for their efficient utilization. In order to take advantage of the local GPUs and the low-latency high-throughput interconnects that link them, programmers need to meticulously adapt parallel applications with respect to load balancing, boundary conditions and device synchronization. This paper presents MAPS-Multi, an automatic multi-GPU partitioning framework that distributes the workload based on the underlying memory access patterns. The framework consists of host- and device-level APIs that allow programs to efficiently run on a variety of GPU and multi-GPU architectures. The framework implements several layers of code optimization, device abstraction, and automatic inference of inter-GPU memory exchanges. The paper demonstrates that the performance of MAPS-Multi achieves near-linear scaling on fundamental computational operations, as well as real-world applications in deep learning and multivariate analysis.},
  author        = {Ben-Nun, Tal and Levy, Ely and Barak, Amnon and Rubin, Eri},
  booktitle     = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi           = {10.1145/2807591.2807611},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Memory access patterns The missing piece of the multi-GPU puzzle - Ben-Nun et al. - Proce.pdf:pdf},
  isbn          = {9781450337236},
  issn          = {21674337},
  keywords      = {GPU,Multi{\_}GPU,memory access patterns,multi-GPU programming},
  mendeley-tags = {GPU,Multi{\_}GPU},
  pages         = {1--12},
  publisher     = {ACM},
  title         = {{Memory access patterns: The missing piece of the multi-GPU puzzle}},
  year          = {2015}
}
@techreport{Bernaschi,
  author          = {Bernaschi, Massimo},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Unknown/Multi Gpu Programming ( With Mpi ) Some of the Slides Come From a Tutorial Presented During the 2014 Gtc - Bernaschi - Unknown.pdf:pdf},
  keywords        = {GPU,MPI},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {GPU,MPI},
  title           = {{Multi Gpu Programming ( With Mpi ) Some of the Slides Come From a Tutorial Presented During the 2014 Gtc}},
  year            = {2014}
}
@article{Bernaschi2019,
  abstract        = {GPUs are very powerful computing accelerators that are often employed in single-device configuration. However, there is a steadily growing interest in using multiple GPUs in a concurrent way both to overcome the memory limitations of the single device and to further reduce execution times. Until recently, communication among GPUs had been carried out mainly by using networking technologies originally devised for standard CPUs with the CPU playing an active role in the communication. However, new alternatives start to be available in which a moderate number of GPUs are directly connected each other by means of proprietary technologies. We present the results of a set of experiments aimed at assessing the performance of some of these hardware/software platforms using a particularly challenging application as a benchmark. We release its source code to facilitate people interested in reproducing or extending our results.},
  author          = {Bernaschi, Massimo and Agostini, Elena and Rossetti, Davide},
  doi             = {10.1002/cpe.5470},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Concurrency and Computation Practice and Experience (CCPE)/Benchmarking multi-GPU applications on modern multi-GPU integrated systems - Bernaschi, Agostini, Rossetti - Concurrency and Computation.pdf:pdf},
  issn            = {15320634},
  journal         = {Concurrency and Computation: Practice and Experience (CCPE)},
  keywords        = {Benchmark,DGX-1,GPU,GPUDirec,POWER9,approximate inverse,spin},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Benchmark,GPU,POWER9},
  pages           = {1--15},
  title           = {{Benchmarking multi-GPU applications on modern multi-GPU integrated systems}},
  year            = {2019}
}
@article{Bernholdt2020,
  abstract        = {The Exascale Computing Project (ECP) is currently the primary effort in the United States focused on developing “exascale” levels of computing capabilities, including hardware, software, and applications. In order to obtain a more thorough understanding of how the software projects under the ECP are using, and planning to use the Message Passing Interface (MPI), and help guide the work of our own project within the ECP, we created a survey. Of the 97 ECP projects active at the time the survey was distributed, we received 77 responses, 56 of which reported that their projects were using MPI. This paper reports the results of that survey for the benefit of the broader community of MPI developers.},
  author          = {Bernholdt, David E. and Boehm, Swen and Bosilca, George and {Gorentla Venkata}, Manjunath and Grant, Ryan E. and Naughton, Thomas and Pritchard, Howard P. and Schulz, Martin and Vallee, Geoffroy R.},
  doi             = {10.1002/cpe.4851},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Concurrency and Computation Practice and Experience (CCPE)/A survey of MPI usage in the US exascale computing project - Bernholdt et al. - Concurrency and Computation Practice and Experience (CCP.pdf:pdf},
  issn            = {15320634},
  journal         = {Concurrency and Computation: Practice and Experience (CCPE)},
  keywords        = {Exascale,MPI,Survey,exascale},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Exascale,MPI,Survey},
  number          = {3},
  pages           = {1--16},
  title           = {{A survey of MPI usage in the US exascale computing project}},
  year            = {2020}
}
@article{Besta2014,
  abstract        = {We introduce a high-performance cost-effective network topology called Slim Fly that approaches the theoretically optimal network diameter. Slim Fly is based on graphs that approximate the solution to the degree-diameter problem. We analyze Slim Fly and compare it to both traditional and state-of the-art networks. Our analysis shows that Slim Fly has significant advantages over other topologies in latency, bandwidth, resiliency, cost, and power consumption. Finally, we propose deadlock-free routing schemes and physical layouts for large computing centres as well as a detailed cost and power model. Slim Fly enables constructing cost effective and highly resilient data enter and HPC networks that offer low latency and high bandwidth under different HPC workloads such as stencil or graph computations.},
  annote          = {SlimFly provides low-diameter network topology to reduce latency, cost, packet loss, etc. 
                     
                     They provide deadlock-free and adaptive routing strategies. 
                     
                     They increase bandwidth and resiliency. 
                     
                     - Motivation: Figure 1: other networks has higher number of hops.
                     
                     For network sizes {\~{}}100K enpoints -{\textgreater} diameter 2
                     For network sizes {\~{}}10s of millions enpoints -{\textgreater} diameter 3},
  archiveprefix   = {arXiv},
  arxivid         = {1912.08968},
  author          = {Besta, Maciej and Hoefler, Torsten},
  doi             = {10.1109/SC.2014.34},
  eprint          = {1912.08968},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/International Conference for High Performance Computing, Networking, Storage and Analysis, SC/Slim Fly A Cost Effective Low-Diameter Network Topology - Besta, Hoefler - International Conference for High.pdf:pdf},
  issn            = {21674337},
  journal         = {International Conference for High Performance Computing, Networking, Storage and Analysis, SC},
  mendeley-groups = {ELEC-878},
  number          = {January},
  pages           = {348--359},
  title           = {{Slim Fly: A Cost Effective Low-Diameter Network Topology}},
  volume          = {2015-Janua},
  year            = {2014}
}
@inproceedings{Bienz2019,
  abstract        = {The MPI-Allreduce collective operation is a core kernel of many parallel codebases, particularly for reductions over a single value per process. The commonly used allreduce recursive-doubling algorithm obtains the lower bound message count, yielding optimality for small reduction sizes based on node-agnostic performance models. However, this algorithm yields duplicate messages between sets of nodes. Node-aware optimizations in MPICH remove duplicate messages through use of a single master process per node, yielding a large number of inactive processes at each inter-node step. In this paper, we present an algorithm that uses the multiple processes available per node to reduce the maximum number of inter-node messages communicated by a single process, improving the performance of allreduce operations, particularly for small message sizes.},
  archiveprefix   = {arXiv},
  arxivid         = {1910.09650},
  author          = {Bienz, Amanda and Olson, Luke and Gropp, William},
  booktitle       = {Proceedings of the IEEE/ACM Workshop on Exascale MPI (ExaMPI)},
  doi             = {10.1109/ExaMPI49596.2019.00008},
  eprint          = {1910.09650},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the IEEEACM Workshop on Exascale MPI (ExaMPI)/Node-Aware Improvements to Allreduce - Bienz, Olson, Gropp - Proceedings of the IEEEACM Workshop on Exascale MPI (ExaMPI).pdf:pdf},
  isbn            = {9781728160092},
  keywords        = {Collectives,MPI,MPI{\_}Allreduce},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,MPI,MPI{\_}Allreduce},
  pages           = {19--28},
  publisher       = {IEEE},
  title           = {{Node-Aware Improvements to Allreduce}},
  year            = {2019}
}
@article{Boito2018,
  abstract      = {We present a comprehensive survey on parallel I/O in the high-performance computing (HPC) context. This is an important field for HPC because of the historic gap between processing power and storage latency, which causes application performance to be impaired when accessing or generating large amounts of data. As the available processing power and amount of data increase, I/O remains a central issue for the scientific community. In this survey article, we focus on a traditional I/O stack, with a POSIX parallel file system. We present background concepts everyone could benefit from. Moreover, through the comprehensive study of publications from the most important conferences and journals in a 5-year time window, we discuss the state of the art in I/O optimization approaches, access pattern extraction techniques, and performance modeling, in addition to general aspects of parallel I/O research. With this approach, we aim at identifying the general characteristics of the field and the main current and future research topics.},
  author        = {Boito, Francieli Zanon and Inacio, Eduardo C. and Bez, Jean Luca and Navaux, Philippe O.A. and Dantas, Mario A.R. and Denneulin, Yves},
  doi           = {10.1145/3152891},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/ACM Computing Surveys/A checkpoint of research on parallel IO for high-performance computing - Boito et al. - ACM Computing Surveys.pdf:pdf},
  issn          = {15577341},
  journal       = {ACM Computing Surveys},
  keywords      = {High-performance computing,Parallel file systems,Parallel{\_}IO,Storage systems,Survey},
  mendeley-tags = {Parallel{\_}IO,Survey},
  number        = {2},
  title         = {{A checkpoint of research on parallel I/O for high-performance computing}},
  volume        = {51},
  year          = {2018}
}
@techreport{Booth,
  author          = {Booth, O S U and Sc, Talk},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Unknown/Scalable and Distributed Deep Learning ( DL ) Co-Design MPI Runtimes and DL Frameworks - Booth, Sc - Unknown.pdf:pdf},
  mendeley-groups = {Presentations {\&} Reports},
  number          = {Dl},
  title           = {{Scalable and Distributed Deep Learning ( DL ): Co-Design MPI Runtimes and DL Frameworks}},
  year            = {2018}
}
@article{Bosshart2014,
  abstract        = {P4 is a high-level language for programming protocol-inde-pendent packet processors. P4 works in conjunction with SDN control protocols like OpenFlow. In its current form, OpenFlow explicitly specifies protocol headers on which it operates. This set has grown from 12 to 41 fields in a few years, increasing the complexity of the specification while still not providing the exibility to add new headers. In this paper we propose P4 as a strawman proposal for how Open-Flow should evolve in the future. We have three goals: (1) Reconfigurability in the field: Programmers should be able to change the way switches process packets once they are deployed. (2) Protocol independence: Switches should not be tied to any specific network protocols. (3) Target inde- pendence: Programmers should be able to describe packet-processing functionality independently of the specifics of the underlying hardware. As an example, we describe how to use P4 to configure a switch to add a new hierarchical label.},
  archiveprefix   = {arXiv},
  arxivid         = {1312.1719},
  author          = {Bosshart, Pat and Daly, Dan and Gibb, Glen and Izzard, Martin and McKeown, Nick and Rexford, Jennifer and Schlesinger, Cole and Talayco, Dan and Vahdat, Amin and Varghese, George and Walker, David},
  doi             = {10.1145/2656877.2656890},
  eprint          = {1312.1719},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Computer Communication Review/P4 Programming protocol-independent packet processors - Bosshart et al. - Computer Communication Review.pdf:pdf},
  issn            = {19435819},
  journal         = {Computer Communication Review},
  mendeley-groups = {ELEC-878},
  number          = {3},
  pages           = {87--95},
  title           = {{P4: Programming protocol-independent packet processors}},
  volume          = {44},
  year            = {2014}
}
@inproceedings{Brightwell2010,
  abstract        = {Achieving the next three orders of magnitude performance increase to move from petascale to exascale computing will require a significant advancements in several fundamental areas. Recent studies have outlined many of the challenges in hardware and software that will be needed. In this paper, we examine these challenges with respect to high-performance networking. We describe the repercussions of anticipated changes to computing and networking hardware and discuss the impact that alternative parallel programming models will have on the network software stack. We also present some ideas on possible approaches that address some of these challenges. {\textcopyright} 2010 IEEE.},
  author          = {Brightwell, Ron and Barrett, Brian W. and Hemmert, K. Scott and Underwood, Keith D.},
  booktitle       = {Proceedings of the International Conference on Computer Communications and Networks (ICCCN)},
  doi             = {10.1109/ICCCN.2010.5560144},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2010/Proceedings of the International Conference on Computer Communications and Networks (ICCCN)/Challenges for high-performance networking for exascale computing - Brightwell et al. - Proceedings of the Inte.pdf:pdf},
  keywords        = {Exascale,MPI,Survey},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Exascale,MPI,Survey},
  pages           = {1--6},
  title           = {{Challenges for high-performance networking for exascale computing}},
  year            = {2010}
}
@article{Brightwell2006,
  abstract      = {The global, synchronous nature of some collective operations implies that they will become the bottleneck when scaling to hundreds of thousands of nodes. One approach improves collective performance using a programmable network interface to directly implement collectives. While these implementations improve micro-benchmark performance, accelerating applications will require deeper understanding of application behaviour. We describe several characteristics of applications that impact collective communication performance. We analyse network resource usage data to guide the design of collective offload engines and their associated programming interfaces. In particular, we provide an analysis of the potential benefit of non-blocking collective communication operations for MPI. {\textcopyright} 2006 Inderscience Enterprises Ltd.},
  author        = {Brightwell, Ron and Goudy, Sue P. and Rodrigues, Arun and Underwood, Keith D.},
  doi           = {10.1504/ijhpcn.2006.010633},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2006/International Journal of High Performance Computing and Networking/Implications of application usage characteristics for collective communication offload - Brightwell et al. - International Journal of Hi.pdf:pdf},
  issn          = {17400570},
  journal       = {International Journal of High Performance Computing and Networking},
  keywords      = {Collectives,MPI,Offloading,collective,network interface,non-blocking,resource management,resource usage},
  mendeley-tags = {Collectives,MPI,Offloading},
  number        = {3-4},
  pages         = {104--116},
  title         = {{Implications of application usage characteristics for collective communication offload}},
  volume        = {4},
  year          = {2006}
}
@inproceedings{Brightwell2005,
  abstract        = {Understanding the message passing behavior and network resource usage of distributed-memory message-passing parallel applications is critical to achieving high performance and scalability. While much research has focused on how applications use critical compute related resources, relatively little attention has been devoted to characterizing the usage of network resources, specifically those needed by the network interface. This paper discusses the importance of understanding network interface resource usage requirements for parallel applications and describes an initial attempt to gather network resource usage data for several real-world codes. The results show widely varying usage patterns between processes in the same parallel job and indicate that resource requirements can change dramatically as process counts increase and input data changes. This suggests that general network resource management strategies may not be widely applicable, and that adaptive strategies or more fine-grained controls may be necessary for environments where network interface resources are severely constrained. {\textcopyright} 2005 IEEE.},
  author          = {Brightwell, Ron and Goudy, Sue and Underwood, Keith},
  booktitle       = {Proceedings of the International Conference on Parallel Processing (ICPP)},
  doi             = {10.1109/ICPP.2005.13},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2005/Proceedings of the International Conference on Parallel Processing (ICPP)/A preliminary analysis of the MPI queue characterisitics of several applications - Brightwell, Goudy, Underwood - Proceedings of.pdf:pdf},
  isbn            = {0769523803},
  issn            = {01903918},
  keywords        = {MPI,Message{\_}Matching},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Message{\_}Matching},
  pages           = {175--183},
  title           = {{A preliminary analysis of the MPI queue characterisitics of several applications}},
  year            = {2005}
}
@article{Systems1997,
  abstract      = {We present efficient algorithms for two all-to-all communication operations in message-passing systems: index (or all-to-all personalized communication) and concatenation (or all-to-all broadcast). We assume a model of a fully connected message-passing system, in which the performance of any point-to-point communication is independent of the sender-receiver pair. We also assume that each processor has k ≥ 1 ports, through which it can send and receive k messages in every communication round. The complexity measures we use are independent of the particular system topology and are based on the communication start-up time, and on the communication bandwidth. In the index operation among n processors, initially, each processor has n blocks of data, and the goal is to exchange the ith block of processor j with the jth block of processor i. We present a class of index algorithms that is designed for all values of n and that features a trade-off between the communication start-up time and the data transfer time. This class of algorithms includes two special cases: an algorithm that is optimal with respect to the measure of the start-up time, and an algorithm that is optimal with respect to the measure of the data transfer time. We also present experimental results featuring the performance tuneability of our index algorithms on the IBM SP-1 parallel system. In the concatenation operation, among n processors, initially, each processor has one block of data, and the goal is to concatenate the n blocks of data from the n processors, and to make the concatenation result known to all the processors. We present a concatenation algorithm that is optimal, for most values of n, in the number of communication rounds and in the amount of data transferred. {\textcopyright} 1997 IEEE.},
  author        = {Bruck, Jehoshua and Ho, Ching Tien and Kipnis, Shlomo and Upfal, Eli and Weathersby, Derrick},
  doi           = {10.1109/71.642949},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/1997/IEEE Transactions on Parallel and Distributed Systems/Efficient algorithms for all-to-all communications in multiport message-passing systems - Bruck et al. - IEEE Transactions on Parallel a.pdf:pdf},
  issn          = {10459219},
  journal       = {IEEE Transactions on Parallel and Distributed Systems},
  keywords      = {All-to-all broadcast,All-to-all personalized communication,All{\_}to{\_}All,Broadcast,Collectives,Complete exchange,Concatenation operation,Distributed-memory system,Index operation,MPI,Message-passing system,Multiscatter/gather,Parallel system},
  mendeley-tags = {All{\_}to{\_}All,Broadcast,Collectives,MPI},
  number        = {11},
  pages         = {1143--1156},
  title         = {{Efficient algorithms for all-to-all communications in multiport message-passing systems}},
  volume        = {8},
  year          = {1997}
}
@inproceedings{Bureddy2012,
  abstract        = {General-Purpose Graphics Processing Units (GPGPUs) are becoming a common component of modern supercomputing systems. Many MPI applications are being modified to take advantage of the superior compute potential offered by GPUs. To facilitate this process, many MPI libraries are being extended to support MPI communication from GPU device memory. However, there is lack of a standardized benchmark suite that helps users evaluate common communication models on GPU clusters and do a fair comparison for different MPI libraries. In this paper, we extend the widely used OSU Micro-Benchmarks (OMB) suite with benchmarks that evaluate performance of point-point, multi-pair and collective MPI communication for different GPU cluster configurations. Benefits of the proposed benchmarks for MVAPICH2 and OpenMPI libraries are illustrated. {\textcopyright} 2012 Springer-Verlag.},
  author          = {Bureddy, Devendar and Wang, H. and Venkatesh, A. and Potluri, S. and Panda, D. K.},
  booktitle       = {Proceedings of the European MPI Users' Group Meeting (EuroMPI)},
  doi             = {10.1007/978-3-642-33518-1_16},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2012/Proceedings of the European MPI Users' Group Meeting (EuroMPI)/OMB-GPU A micro-benchmark suite for evaluating MPI libraries on GPU clusters - Bureddy et al. - Proceedings of the European MPI Users' G.pdf:pdf},
  isbn            = {9783642335174},
  issn            = {03029743},
  keywords        = {Benchmark,GPGPU,GPU,MPI,clusters,micro-benchmarks},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Benchmark,GPU,MPI},
  pages           = {110--120},
  title           = {{OMB-GPU: A micro-benchmark suite for evaluating MPI libraries on GPU clusters}},
  year            = {2012}
}
@inproceedings{Castello2021a,
  abstract      = {Training deep neural networks is a costly procedure, often performed via sophisticated deep learning frameworks on clusters of computers. As faster processor technologies are integrated into these cluster facilities (e.g., NVIDIA's graphics accelerators or Google's tensor processing units), the communication component of the training process rapidly becomes a performance bottleneck. In this paper, we offer a complete analysis of the key collective communication primitive for the distributed data-parallel training of convolutional network networks (CNNs) focused on three relevant instances of the Message Passing Interface (MPI): MPICH, OpenMPI, and IntelMPI. In addition, our experimental evaluation is extended to expose the practical impact of this collective primitive when the training is performed using TensorFlow+ Horovod on a 16-node cluster. Finally, the theoretical analysis is further refined to a number of accelerated cluster configurations that are emulated by adjusting the communication-arithmetic ratio of the training process.},
  author        = {Castell{\'{o}}, Adri{\'{a}}n and Catal{\'{a}}n, Mar and Dolz, Manuel F. and Mestre, Jos{\'{e}} I. and Quintana-Ort{\'{i}}, Enrique S. and Duato, Jos{\'{e}}},
  booktitle     = {Proceedings of the Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)},
  doi           = {10.1109/PDP52278.2021.00025},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)/Evaluation of MPI Allreduce for Distributed Training of Convolutional Neural Networks - C.pdf:pdf},
  isbn          = {9781665414555},
  keywords      = {Allreduce,Deep{\_}Learning,MPI,MPI{\_}Allreduce,Message Passing Interface (MPI),collective communication primitives,convolutional neural networks,deep learning,distributed training},
  mendeley-tags = {Deep{\_}Learning,MPI,MPI{\_}Allreduce},
  pages         = {109--116},
  title         = {{Evaluation of MPI Allreduce for Distributed Training of Convolutional Neural Networks}},
  year          = {2021}
}
@article{Castello2021b,
  author        = {Castell{\'{o}}, Adri{\'{a}}n and Catal{\'{a}}n, Mar and Dolz, Manuel F. and Quintana-Ort{\'{i}}, Enrique S.},
  doi           = {10.1007/s00607-021-01029-2},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Computing/Analyzing the impact of the MPI allreduce in distributed training of convolutional neural networks - Castell{\'{o}} et al. - Computing.pdf:pdf},
  journal       = {Computing},
  keywords      = {Deep{\_}Learning,MPI,MPI{\_}Allreduce},
  mendeley-tags = {Deep{\_}Learning,MPI,MPI{\_}Allreduce},
  pages         = {1--19},
  title         = {{Analyzing the impact of the MPI allreduce in distributed training of convolutional neural networks}},
  year          = {2021}
}
@article{Castello2021,
  abstract        = {TensorFlow (TF) is usually combined with the Horovod (HVD) workload distribution package to obtain a parallel tool to train deep neural network on clusters of computers. HVD in turn utilizes a blocking Allreduce primitive to share information among processes, combined with a communication thread to overlap communication with computation. In this work, we perform a thorough experimental analysis to expose (1) the importance of selecting the best algorithm in MPI libraries to realize the Allreduce operation; and (2) the performance acceleration that can be attained when replacing a blocking Allreduce with its non-blocking counterpart (while maintaining the blocking behaviour via the appropriate synchronization mechanism). Furthermore, (3) we explore the benefits of applying pipelining to the communication exchange, demonstrating that these improvements carry over to distributed training via TF+HVD. Finally, (4) we show that pipelining can also boost performance for applications that make heavy use of other collectives, such as Broadcast and Reduce-Scatter.},
  author          = {Castell{\'{o}}, Adri{\'{a}}n and Quintana-Ort{\'{i}}, Enrique S. and Duato, Jos{\'{e}}},
  doi             = {10.1007/s10586-021-03370-9},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Cluster Computing/Accelerating distributed deep neural network training with pipelined MPI allreduce - Castell{\'{o}}, Quintana-Ort{\'{i}}, Duato - Cluster Computing.pdf:pdf},
  isbn            = {0123456789},
  issn            = {15737543},
  journal         = {Cluster Computing},
  keywords        = {Allreduce,Collective communication primitives,Collectives,Deep learning,Distributed training,MPI,Message Passing Interface (MPI)},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {Collectives,MPI},
  pages           = {1--17},
  title           = {{Accelerating distributed deep neural network training with pipelined MPI allreduce}},
  year            = {2021}
}
@article{Chakraborty2019,
  abstract        = {Amazon has recently announced a new network interface named Elastic Fabric Adapter (EFA) targeted towards tightly coupled HPC workloads. In this paper, we characterize the features, capabilities and performance of the adapter. We also explore how its transport models such as UD and SRD (Scalable Reliable Datagram) impact the design of high-performance MPI libraries. Our evaluations show that hardware level reliability provided by SRD can significantly improve the performance of MPI communication. We also propose a new zero-copy transfer mechanism over unreliable and orderless channels that can reduce the communication latency of large messages. The proposed design also shows significant improvement in collective and application performance against the vendor provided MPI library.},
  author          = {Chakraborty, Sourav and Xu, Shulei and Subramoni, Hari and Panda, Dhabaleswar},
  doi             = {10.1109/HOTI.2019.00023},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)/Designing scalable and high-performance MPI libraries on amazon elastic fabric adapter - Chakraborty et al. - Proceedings of the.pdf:pdf},
  isbn            = {9781728155258},
  journal         = {Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)},
  keywords        = {EC2,EFA,Elastic Fabric Adapter,HPC,MPI,SRD},
  mendeley-groups = {ELEC-878},
  pages           = {40--44},
  title           = {{Designing scalable and high-performance MPI libraries on amazon elastic fabric adapter}},
  year            = {2019}
}
@inproceedings{Chan2004,
  abstract      = {In this paper we discuss issues related to the high-performance implementation of collective communications operations on distributed-memory computer architectures. Using a combination of known techniques (many of which were first proposed in the 1980s and early 1990s) along with careful exploitation of communication modes supported by MPI, we have developed implementations that have improved performance in most situations compared to those currently supported by public domain implementations of MPI such as MPICH. Performance results from a large Intel Pentium 4 (R) processor cluster are included. {\textcopyright}2004 IEEE.},
  author        = {Chan, Ernie W. and Heimlich, Marcel F. and Purkayastha, Avi and {Van De Geijn}, Robert A.},
  booktitle     = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi           = {10.1109/CLUSTR.2004.1392612},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2004/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/On optimizing collective communication - Chan et al. - Proceedings of the IEEE International Conference on Cluster Computin.pdf:pdf},
  isbn          = {0780386949},
  issn          = {15525244},
  keywords      = {Collectives,MPI},
  mendeley-tags = {Collectives,MPI},
  pages         = {145--155},
  title         = {{On optimizing collective communication}},
  year          = {2004}
}
@inproceedings{Chatterjee2013,
  abstract      = {Effective combination of inter-node and intra-node parallelism is recognized to be a major challenge for future extreme-scale systems. Many researchers have demonstrated the potential benefits of combining both levels of parallelism, including increased communication-computation overlap, improved memory utilization, and effective use of accelerators. However, current "hybrid programming" approaches often require significant rewrites of application code and assume a high level of programmer expertise. Dynamic task parallelism has been widely regarded as a programming model that combines the best of performance and programmability for shared-memory programs. For distributed-memory programs, most users rely on efficient implementations of MPI. In this paper, we propose HCMPI (Habanero-C MPI), an integration of the Habanero-C dynamic task-parallel programming model with the widely used MPI message-passing interface. All MPI calls are treated as asynchronous tasks in this model, thereby enabling unified handling of messages and tasking constructs. For programmers unfamiliar with MPI, we introduce distributed data-driven futures (DDDFs), a new data-flow programming model that seamlessly integrates intra-node and inter-node data-flow parallelism without requiring any knowledge of MPI. Our novel runtime design for HCMPI and DDDFs uses a combination of dedicated communication and computation specific worker threads. We evaluate our approach on a set of micro-benchmarks as well as larger applications and demonstrate better scalability compared to the most efficient MPI implementations, while offering a unified programming model to integrate asynchronous task parallelism with distributed-memory parallelism. {\textcopyright} 2013 IEEE.},
  author        = {Chatterjee, Sanjay and Taşirlar, Saǧnak and Budimli{\'{c}}, Zoran and Cav{\'{e}}, Vincent and Chabbi, Milind and Grossman, Max and Sarkar, Vivek and Yan, Yonghong},
  booktitle     = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi           = {10.1109/IPDPS.2013.78},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2013/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/Integrating asynchronous task parallelism with MPI - Chatterjee et al. - Proceedings of the IEEE International.pdf:pdf},
  keywords      = {Hybrid{\_}MPI,MPI,asynchronous task parallelism,data flow,data-driven tasks,phasers},
  mendeley-tags = {Hybrid{\_}MPI,MPI},
  pages         = {712--725},
  title         = {{Integrating asynchronous task parallelism with MPI}},
  year          = {2013}
}
@inproceedings{Chen2022a,
  abstract        = {In recent years, High Performance Computing (HPC) and Deep Learning (DL) applications have been modified to run on top supercomputers and utilize the high compute power of GPUs. While GPUs provide high computational power, communication of data between GPUs and across a network continues to be a bottleneck. In particular, with the increasing amount of FFT compute and sparse matrix transpose operations in these applications, Alltoall MPI collective operations are heavily used. Alltoall communication is considered the heaviest communication pattern compared to other MPI collective calls. Few techniques and algorithms effectively help in optimizing Alltoall communication, much less improving the performance on a dense GPU cluster while exploiting the features of modern inter-connects and topologies. Despite the introduction of Inter-Process Communication (IPC) in CUDA 4.1 by NVIDIA, state-of-the-art MPI libraries have not utilized these IPC-based mechanisms to design novel Alltoall algorithms that exploit the capabilities of modern GPUs. In this paper, we propose hybrid IPC-advanced designs for Alltoall and Alltoallv communication on novel GPU systems. By utilizing zero-copy load-store IPC mechanisms for multi-GPU communication within a node, we are able to overlap the intra-node and inter-node communication, yielding improved performance on GPU systems. We evaluate the benefits of our designs at the benchmark and application layers on the ThetaGPU system at ALCF and the Lassen system at LLNL. Our designs provide up to 13.5x and 71{\%} improvements on 128 GPUs and 64 GPUs at the benchmark-level over state-of-the-art MPI libraries on ThetaGPU and Lassen respectively. At the application level, our designs have up to 59x performance improvement for an HPC application, heFFTe, and 5.7x performance improvement for a Deep Learning application, DeepSpeed, on 64 GPUs on ThetaGPU and 256 GPUs on Lassen.},
  author          = {Chen, Chen Chun and Khorassani, Kawthar Shafie and Anthony, Quentin G. and Shafi, Aamir and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
  doi             = {10.1109/IPDPSW55747.2022.00014},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)/Highly Efficient Alltoall and Alltoallv Communication Algorithms for GPU Systems - Chen et al. - Pro.pdf:pdf},
  isbn            = {9781665497473},
  keywords        = {All{\_}to{\_}All,Alltoall,Alltoallv,DGX,GPU,IPC,MPI},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {All{\_}to{\_}All,DGX,GPU,MPI},
  pages           = {1--10},
  publisher       = {IEEE},
  title           = {{Highly Efficient Alltoall and Alltoallv Communication Algorithms for GPU Systems}},
  year            = {2022}
}
@article{Chen2019,
  abstract  = {To achieve high computation throughput, heterogeneous architectures utilize many special-purpose cores to work as floating point computing coprocessors. Popular programming models typically offload computing intensive operations to coprocessors and then aggregate the results. This approach results in the need of transferring a large amount of data via the peripheral component interconnect express (PCIe). To leverage the limited bandwidth of PCIe, we develop a reverse offload (rOffload) model that treats the autonomous Intel Many Integrated Core (MIC) coprocessor as the host processor while the CPU is treated as the coprocessor. The MICs orchestrate the computation and offload work, which cannot be accelerated on MIC, to the CPUs, thus reducing the overhead introduced by moving data among distinct memory regions. In this paper, we present an overview of rOffload, including the basic programming interface and its implementation on a CPU-MIC system. The results from benchmarking and from application experiments conducted on the Tianhe-2 supercomputer demonstrate the efficiency of our rOffload model in terms of programmability, portability, and performance.},
  author    = {Chen, Cheng and Yang, Wenxiang and Wang, Fang and Zhao, Dan and Liu, Yang and Deng, Liang and Yang, Canqun},
  doi       = {10.1109/ACCESS.2019.2891740},
  file      = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/IEEE Access/Reverse Offload Programming on Heterogeneous Systems - Chen et al. - IEEE Access.pdf:pdf},
  issn      = {21693536},
  journal   = {IEEE Access},
  keywords  = {Heterogeneous computing,MIC,programming,reverse offload},
  pages     = {10787--10797},
  publisher = {IEEE},
  title     = {{Reverse Offload Programming on Heterogeneous Systems}},
  volume    = {7},
  year      = {2019}
}
@inproceedings{Chen2022b,
  annote          = {1- Different options for communication granularity:
                     
                     - Fine-grained one-sided communication for NVLink
                     - IB is less efficient for small messages so they use a communication aggregator to utilize bandwidth 
                     
                     2- GPU threads fetch task from a distributed queue of task
                     
                     3- Kernels can be persistent or not. If persistent, they use the maximum no. of threads that can work on an SM
                     
                     4- Various worker size options: thread-, warp- and CTA-sized workers
                     
                     5- Uses warp intrinsics to improve performance
                     
                     6- Uses Unified memory to allow intra-node GPU communications, and uses NVSHMEM's put, get, and atomic operations for other nodes' GPUs.
                     
                     7- They have used memory padding to make sure that various flags are stored in different cachelines. 
                     
                     8- IB memory requests are offloaded to the NIC, and IB requests require only one or a few threads to initiate data transfer
                     
                     9- Their aggregator improves IB bandwidth at the cost of higher message latency. Their optimal batch size is 1 MiB
                     
                     10- They use a second threshold to control the aggregator behavior: maximum wait time
                     
                     11- They allocate 512 threads per block
                     
                     12- Interesting fact: Their system perform poor (still better than previous studies) at strong-scaling tests, because of inter-socket communications. (idea: Maybe design hierarchical data transfers?)
                     
                     13-},
  author          = {Chen, Yuxin and Brock, Benjamin and Yelick, Katherine and Owens, John D},
  booktitle       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Scalable Irregular Parallelism with GPUs Getting CPUs Out of the Way - Chen et al. - Pro.pdf:pdf},
  isbn            = {9781665454445},
  keywords        = {GPU,MPI},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,MPI},
  pages           = {1--16},
  title           = {{Scalable Irregular Parallelism with GPUs : Getting CPUs Out of the Way}},
  year            = {2022}
}
@article{Cho2023,
  abstract      = {As multi/many-core processors are widely deployed in high-performance computing systems, efficient intra-node communication becomes more important. Intra-node communication involves data copy operations to move messages from source to destination buffer. Researchers have tried to reduce the overhead of this copy operation, but the copy operation performed by CPU still wastes the CPU resources and even hinders overlapping between computation and communication. The copy engine is a hardware component that can move data between intra-node buffers without intervention of CPU. Thus, we can offload the copy operation performed by CPU onto the copy engine. In this paper, we aim at exploiting copy engines for MPI blocking collective communication, such as broadcast and gather operations. MPI is a messaging-based parallel programming model and provides point-to-point, collective, and one-sided communications. Research has been conducted to utilize the copy engine for MPI, but the support for collective communication has not yet been studied. We propose the asynchronism in blocking collective communication and the CE-CPU hybrid approach to utilize both copy engine and CPU for intra-node collective communication. The measurement results show that the proposed approach can reduce the overall execution time of a microbenchmark and a synthetic application that perform collective communication and computation up to 72{\%} and 57{\%}, respectively.},
  author        = {Cho, Joong Yeon and Seo, Pu Rum and Jin, Hyun Wook},
  doi           = {10.1007/s11227-023-05340-x},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/Journal of Supercomputing/Exploiting copy engines for intra-node MPI collective communication - Cho, Seo, Jin - Journal of Supercomputing.pdf:pdf},
  isbn          = {1122702305340},
  issn          = {15730484},
  journal       = {Journal of Supercomputing},
  keywords      = {Collective communication,Collectives,Copy engine,Intra-node communication,MPI,Message-passing interface},
  mendeley-tags = {Collectives,MPI},
  pages         = {1--21},
  publisher     = {Springer US},
  title         = {{Exploiting copy engines for intra-node MPI collective communication}},
  url           = {https://doi.org/10.1007/s11227-023-05340-x},
  year          = {2023}
}
@inproceedings{Choi2021,
  abstract        = {As an increasing number of leadership-class systems embrace GPU accelerators in the race towards exascale, efficient communication of GPU data is becoming one of the most critical components of high-performance computing. For developers of parallel programming models, implementing support for GPU-aware communication using native APIs for GPUs such as CUDA can be a daunting task as it requires considerable effort with little guarantee of performance. In this work, we demonstrate the capability of the Unified Communication X (UCX) framework to compose a GPU-aware communication layer that serves multiple parallel programming models of the Charm++ ecosystem: Charm++, Adaptive MPI (AMPI), and Charm4py. We demonstrate the performance impact of our designs with microbenchmarks adapted from the OSU benchmark suite, obtaining improvements in latency of up to 10.2x, 11.7x, and 17.4x in Charm++, AMPI, and Charm4py, respectively. We also observe increases in bandwidth of up to 9.6x in Charm++, 10x in AMPI, and 10.5x in Charm4py. We show the potential impact of our designs on real-world applications by evaluating a proxy application for the Jacobi iterative method, improving the communication performance by up to 12.4x in Charm++, 12.8x in AMPI, and 19.7x in Charm4py.},
  archiveprefix   = {arXiv},
  arxivid         = {2102.12416},
  author          = {Choi, Jaemin and Fink, Zane and White, Sam and Bhat, Nitin and Richards, David F. and Kale, Laxmikant V.},
  booktitle       = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
  doi             = {10.1109/IPDPSW52791.2021.00079},
  eprint          = {2102.12416},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)/GPU-aware Communication with UCX in Parallel Programming Models Charm, MPI, and Python - Choi et al..pdf:pdf},
  isbn            = {9781665435772},
  keywords        = {AMPI,CUDA-aware MPI,Charm++,Charm4py,GPU,GPU communication,MPI,Python,UCX},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {GPU,MPI,UCX},
  pages           = {479--488},
  title           = {{GPU-aware Communication with UCX in Parallel Programming Models: Charm++, MPI, and Python}},
  year            = {2021}
}
@article{Choi2022b,
  abstract        = {As an increasing number of leadership-class systems embrace GPU accelerators in the race towards exascale, efficient communication of GPU data is becoming one of the most critical components of high-performance computing. For developers of parallel programming models, implementing support for GPU-aware communication using native APIs for GPUs such as CUDA can be a daunting task as it requires considerable effort with little guarantee of performance. In this work, we demonstrate the capability of the Unified Communication X (UCX) framework to compose a GPU-aware communication layer that serves multiple parallel programming models of the Charm++ ecosystem: Charm++, Adaptive MPI (AMPI), and Charm4py. We demonstrate the performance impact of our designs with microbenchmarks adapted from the OSU benchmark suite, obtaining improvements in latency of up to 10.1x in Charm++, 11.7x in AMPI, and 17.4x in Charm4py. We also observe increases in bandwidth of up to 10.1x in Charm++, 10x in AMPI, and 10.5x in Charm4py. We show the potential impact of our designs on real-world applications by evaluating a proxy application for the Jacobi iterative method, improving the communication performance by up to 12.4x in Charm++, 12.8x in AMPI, and 19.7x in Charm4py.},
  author          = {Choi, Jaemin and Fink, Zane and White, Sam and Bhat, Nitin and Richards, David F. and Kale, Laxmikant V.},
  doi             = {10.1016/j.parco.2022.102969},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Parallel Computing/Accelerating communication for parallel programming models on GPU systems - Choi et al. - Parallel Computing.pdf:pdf},
  issn            = {01678191},
  journal         = {Parallel Computing},
  keywords        = {AMPI,CUDA-aware MPI,Charm,Charm++,Charm4py,GPU,GPU-aware communication,MPI,Python,UCX},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Charm,GPU,MPI,UCX},
  pages           = {1--10},
  publisher       = {Elsevier B.V.},
  title           = {{Accelerating communication for parallel programming models on GPU systems}},
  year            = {2022}
}
@inproceedings{Choi2022a,
  abstract        = {Asynchronous tasks, when created with over-decomposition, enable automatic computation-communication overlap which can substantially improve performance and scal-ability. This is not only applicable to traditional CPU-based systems, but also to modern GPU -accelerated platforms. While the ability to hide communication behind computation can be highly effective in weak scaling scenarios, performance begins to suffer with smaller problem sizes or in strong scaling due to fine-grained overheads and reduced room for overlap. In this work, we integrate G PU -aware communication into asynchronous tasks in addition to computation-communication overlap, with the goal of reducing time spent in communication and further increasing GPU utilization. We demonstrate the performance impact of our approach using a proxy application that performs the Jacobi iterative method, Jacobi3D. In addition to optimizations to minimize synchronizations between the host and GPU devices and increase the concurrency of GPU operations, we explore techniques such as kernel fusion and CUDA Graphs to mitigate fine-grained overheads at scale.},
  archiveprefix   = {arXiv},
  arxivid         = {2202.11819},
  author          = {Choi, Jaemin and Richards, David F. and Kale, Laxmikant V.},
  booktitle       = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
  doi             = {10.1109/IPDPSW55747.2022.00097},
  eprint          = {2202.11819},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)/Improving Scalability with GPU-Aware Asynchronous Tasks - Choi, Richards, Kale - Proceedings of the.pdf:pdf},
  isbn            = {9781665497473},
  keywords        = {CUDA{\_}Graphs,GPU,GPU-aware communication,GPUDirect{\_}Async,asynchronous tasks,computation-communication overlap,overdecom-position,scalability},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {CUDA{\_}Graphs,GPU,GPUDirect{\_}Async},
  pages           = {1--10},
  publisher       = {IEEE},
  title           = {{Improving Scalability with GPU-Aware Asynchronous Tasks}},
  year            = {2022}
}
@inproceedings{Chu2016c,
  abstract      = {High-performance streaming applications are beginning to leverage the compute power offered by graphics processing units (GPUs) and high network throughput offered by high performance interconnects such as InfiniBand (IB) to boost their performance and scalability. These applications rely heavily on broadcast operations to move data, which is stored in the host memory, from a single source-typically live-to multiple GPU-based computing sites. While homogeneous broadcast designs take advantage of IB hardware multicast feature to boost their performance, their heterogeneous counterpart requires an explicit data movement between Host and GPU, which significantly hurts the overall performance. There is a dearth of efficient heterogeneous broadcast designs for streaming applications especially on emerging multi-GPU configurations. In this work, we propose novel techniques to fully and conjointly take advantage of NVIDIA GPUDirect RDMA (GDR), CUDA inter-process communication (IPC) and IB hardware multicast features to design high-performance heterogeneous broadcast operations for modern multi-GPU systems. We propose intra-node, topology-aware schemes to maximize the performance benefits while minimizing the utilization of valuable PCIe resources. Further, we optimize the communication pipeline by overlapping the GDR + IB hardware multicast operations with CUDA IPC operations. Compared to existing solutions, our designs show up to 3X improvement in the latency of a heterogeneous broadcast operation. Our designs also show up to 67{\%} improvement in execution time of a streaming benchmark on a GPU-dense Cray CS-Storm system with 88 GPUs.},
  author        = {Chu, C. H. and Hamidouche, K. and Subramoni, H. and Venkatesh, A. and Elton, B. and Panda, D. K.},
  booktitle     = {Proceedings of the International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)},
  doi           = {10.1109/SBAC-PAD.2016.16},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)/Designing High Performance Heterogeneous Broadcast for Streaming Applications on GPU Clusters.pdf:pdf},
  keywords      = {GPU,GPUDirect{\_}RDMA,InfiniBand},
  mendeley-tags = {GPU,GPUDirect{\_}RDMA,InfiniBand},
  pages         = {59--66},
  publisher     = {IEEE},
  title         = {{Designing High Performance Heterogeneous Broadcast for Streaming Applications on GPU Clusters}},
  year          = {2016}
}
@inproceedings{Chu2016a,
  abstract      = {GPU accelerators are widely used in HPC clusters due to their massive parallelism and high throughput-per-watt. Data movement continues to be the major bottleneck on GPU clusters, more so when data is non-contiguous, which is common in scientific applications. CUDA-Aware MPI libraries optimize the non-contiguous data movement processing using latency oriented techniques such as using GPU kernels to accelerate the packing/unpacking operations. Although they optimize the latency of a single operation, the inherent restrictions of the designs limit their efficiency for throughput oriented patterns. Indeed, none of the existing designs fully exploit the massive parallelism of the GPUs to provide high throughput and efficient resources utilization by enabling maximal overlap. In this paper, we propose novel designs for CUDA-Aware MPI libraries to achieve efficient GPU resource utilization and maximal overlap between CPUs and GPUs for non-contiguous data processing and movement. The proposed designs take advantage of several CUDA features, such as Hyper-Q/multi-streams and callback function, to deliver high performance and efficiency. To the best of our knowledge, this is the first such study to provide high throughput and efficient resource utilization for non-contiguous MPI data processing and movement to/from GPUs. The performance evaluation with the proposed designs using DDTBench shows up to 54{\%}, 67{\%}, 61{\%} performance improvement on the SPECFEM3D-oc, SPECFEM3D-cm and WRF-y-sa benchmarks respectively for intra-node inter-GPU ping-pong experiments. The proposed designs also deliver up to 33{\%} improvement on the total execution time over the existing designs for the HaloExchange-based application kernel that models the communication pattern of the MeteoSwiss weather forecasting model over 32 GPU nodes on Wilkes GPU cluster.},
  author        = {Chu, C. H. and Hamidouche, K. and Venkatesh, A. and Banerjee, Dip Sankar and Subramoni, H. and Panda, Dhabaleswar K.},
  booktitle     = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi           = {10.1109/IPDPS.2016.99},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/Exploiting Maximal Overlap for Non-Contiguous Data Movement Processing on Modern GPU-Enabled Systems - Chu et a.pdf:pdf},
  isbn          = {9781509021406},
  keywords      = {CUDA-Aware MPI,Datatype,MPI,Non-contiguous data processing,Overlap},
  mendeley-tags = {Datatype,MPI},
  pages         = {983--992},
  title         = {{Exploiting Maximal Overlap for Non-Contiguous Data Movement Processing on Modern GPU-Enabled Systems}},
  year          = {2016}
}
@inproceedings{Chu2016,
  abstract        = {Accelerators like NVIDIA GPUs have changed the landscape of current HPC clusters to a great extent. Massive heterogeneous parallelism offered by these accelerators have led to GPU-Aware MPI libraries that are widely used for writing distributed parallel scientific applications. Compute-oriented collective operations like MPI-Reduce perform computation on data in addition to the usual communication performed by collectives. Historically, these collectives, due to their compute requirements have been implemented on CPU (or Host) only. However, with the advent of GPU technologies it has become important for MPI libraries to provide better design for their GPU (or Device) based versions.In this paper, we tackle the above challenges and provide designsand implementations for most commonly used compute-oriented collectives-MPI-Reduce, MPI-Allreduce, and MPI-Scan-for GPU clusters. We propose extensions to the state-of-the-art algorithms to fully take advantage of the GPU capabilities like GPUDirect RDMA (GDR) and CUDA compute kernel to efficiently perform these operations. With our new designs, we report reduced execution time for all computebased collectives up to 96 GPUs. Experimental results show an improvement of 50{\%} for small messages and 85{\%} for large messages using MPI-Reduce. For MPI-Allreduce and MPI-Scan, we report more than 40{\%} reduction in time for large messages. Furthermore, analytical models are developed and evaluated to understand and predict the performance of proposed designs for extremely large-scale GPU clusters.},
  author          = {Chu, Ching Hsiang and Hamidouche, Khaled and Venkatesh, Akshay and Awan, Ammar Ahmad and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)},
  doi             = {10.1109/CCGrid.2016.111},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the IEEEACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)/CUDA Kernel Based Collective Reduction Operations on Large-scale GPU Clusters - Chu et al. - Proceedings.pdf:pdf},
  isbn            = {9781509024520},
  keywords        = {CUDA,Collectives,GPU,GPU-Aware MPI,High-Performance Computing (HPC),Kernel-based Collective Operations,Reduction},
  mendeley-groups = {MustKnow,UsedInComp1,UsedInComp2},
  mendeley-tags   = {CUDA,Collectives,GPU,Reduction},
  pages           = {726--735},
  title           = {{CUDA Kernel Based Collective Reduction Operations on Large-scale GPU Clusters}},
  year            = {2016}
}
@inproceedings{Chu2019,
  abstract      = {The recent advent of the NVLink interconnect and Peripheral Component Interconnect express (PCIe) switch has resulted in the creation of extremely dense Graphics Processing Unit (GPU) systems like Cray CS-Storm and NVIDIA DGX. In addition to the extremely high computational capability and communication capacity within a single machine, these systems expose novel capabilities like performing load-store operations from remote GPU memory across interconnects. While researchers have proposed solutions that take advantage of load-store semantics to provide support for high-performance datatype processing on CPUs, there exists no scholarly work on how one can orchestrate such high-performance datatype-based communication for GPU-resident data. In this paper, we take up this challenge and propose high-performance and architecture-aware designs for GPU-based non-contiguous datatype processing that uses the load-store semantics exposed by modern dense GPU systems. We demonstrate that the proposed solutions can reduce the overhead of datatype processing by up to 4.7X compared to the state-of-the-art schemes for GPU-based MILC communication kernel on an NVLink2-enabled dense GPU system. For a weather forecast application kernel, the proposed designs demonstrate up to 9.9X faster HaloExchange kernel among 64 GPUs over state-of-the-art designs. The proposed adaptive scheme also reports 10{\%} higher throughput than existing designs for a 2D Jacobi solver on 16 GPUs. To the best of our knowledge, this is the first scholarly work that takes advantage of the zero-copy based load-store semantics to perform high-performance GPU to GPU derived datatype communication on modern dense GPU systems.},
  author        = {Chu, Ching Hsiang and Hashmi, Jahanzeb Maqbool and Khorassani, Kawthar Shafie and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle     = {Proceedings of the IEEE International Conference on High Performance Computing (HiPC)},
  doi           = {10.1109/HiPC.2019.00041},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the IEEE International Conference on High Performance Computing (HiPC)/High-Performance Adaptive MPI Derived Datatype Communication for Modern Multi-GPU Systems - Chu et al. - Proceedings.pdf:pdf},
  isbn          = {9781728145358},
  keywords      = {Dense GPU systems,Derived Datatype,Dervied{\_}Data{\_}Type,GPU,Load-store,MPI,Multi{\_}GPU,NVLink,Non contiguous Memory Transfer,PCIe},
  mendeley-tags = {Dervied{\_}Data{\_}Type,GPU,MPI,Multi{\_}GPU},
  pages         = {267--276},
  title         = {{High-Performance Adaptive MPI Derived Datatype Communication for Modern Multi-GPU Systems}},
  year          = {2019}
}
@inproceedings{Chu2020a,
  abstract        = {In the last decade, many scientific applications have been significantly accelerated by large-scale GPU systems. However, the movement of non-contiguous GPU-resident data is one of the most challenging components of scaling these applications using communication middleware like MPI. Although plenty of research has discussed improving noncontiguous data movement within communication middleware, the packing/unpacking operations on GPUs are still expensive. They cannot be hidden due to the limitation of MPI standard and the not-well-optimized designs in existing MPI implementations for GPU-resident data. Consequently, application developers tend to implement customized packing/unpacking kernels to improve GPU utilization by avoiding unnecessary synchronizations in MPI routines. However, this reduces productivity as well as performance as it cannot overlap the packing/unpacking operations with communication. In this paper, we propose a novel approach to achieve low-latency and high-bandwidth by dynamically fusing the packing/unpacking GPU kernels to reduce the expensive kernel launch overhead. The evaluation of the proposed designs shows up to 8X and 5X performance improvement for sparse and dense non-contiguous layout, respectively, compared to the state-of-the-art approaches on the Lassen system. Similarly, we observe up to 19X improvement over existing approaches on the ABCI system. Furthermore, the proposed design also outperforms the production libraries, such as SpectrumMPI, OpenMPI, and MVAPICH2, by many orders of magnitude.},
  author          = {Chu, Ching Hsiang and Khorassani, Kawthar Shafie and Zhou, Qinghua and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi             = {10.1109/CLUSTER49012.2020.00023},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/Dynamic Kernel Fusion for Bulk Non-contiguous Data Transfer on GPU Clusters - Chu et al. - Proceedings of the IEEE Internat.pdf:pdf},
  isbn            = {9781728166773},
  keywords        = {Datatype,GPU,MPI},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {Datatype,GPU,MPI},
  pages           = {130--141},
  title           = {{Dynamic Kernel Fusion for Bulk Non-contiguous Data Transfer on GPU Clusters}},
  year            = {2020}
}
@article{Chu2019a,
  abstract      = {Broadcast is a widely used operation in many streaming and deep learning applications to disseminate large amounts of data on emerging heterogeneous High-Performance Computing (HPC) systems. However, traditional broadcast schemes do not fully utilize hardware features for Graphics Processing Unit (GPU)-based applications. In this paper, a model-oriented analysis is presented to identify performance bottlenecks of existing broadcast schemes on GPU clusters. Next, streaming-based broadcast schemes are proposed to exploit InfiniBand hardware multicast (IB-MCAST) and NVIDIA GPUDirect technology for efficient message transmission. The proposed designs are evaluated in the context of using Message Passing Interface (MPI) based benchmarks and applications. The experimental results indicate improved scalability and up to 82 percent reduction of latency compared to the state-of-the-art solutions in the benchmark-level evaluation. Furthermore, compared to the state-of-the-art, the proposed design yields stable higher throughput for a synthetic streaming workload, and 1.3x faster training time for a deep learning framework.},
  author        = {Chu, Ching Hsiang and Lu, Xiaoyi and Awan, Ammar Ahmad and Subramoni, Hari and Elton, Bracy and Panda, Dhabaleswar K.},
  doi           = {10.1109/TPDS.2018.2867222},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/IEEE Transactions on Parallel and Distributed Systems/Exploiting Hardware Multicast and GPUDirect RDMA for Efficient Broadcast - Chu et al. - IEEE Transactions on Parallel and Distributed Sy.pdf:pdf},
  issn          = {15582183},
  journal       = {IEEE Transactions on Parallel and Distributed Systems},
  keywords      = {Broadcast,Deep{\_}Learning,GPU,GPUDirect RDMA,GPUDirect{\_}RDMA,RDMA,deep learning,hardware multicast,heterogeneous broadcast,streaming},
  mendeley-tags = {Deep{\_}Learning,GPU,GPUDirect{\_}RDMA,RDMA},
  number        = {3},
  pages         = {575--588},
  publisher     = {IEEE},
  title         = {{Exploiting Hardware Multicast and GPUDirect RDMA for Efficient Broadcast}},
  volume        = {30},
  year          = {2019}
}
@inproceedings{Chu2017,
  abstract        = {Broadcast operations (e.g. MPI-Bcast) have been widely used in deep learning applications to exchange a large amount of data among multiple graphics processing units (GPUs). Recent studies have shown that leveraging the InfiniBand hardware-based multicast (IB-MCAST) protocol can enhance scalability of GPU-based broadcast operations. However, these initial designs with IB-MCAST are not optimized for multi-source broadcast operations with large messages, which is the common communication scenario for deep learning applications. In this paper, we first model existing broadcast schemes and analyze their performance bottlenecks on GPU clusters. Then, we propose a novel broadcast design based on message streaming to better exploit IB-MCAST and NVIDIA GPUDirect RDMA (GDR) technology for efficient large message transfer operation. The proposed design can provide high overlap among multi-source broadcast operations. Experimental results show up to 68{\%} reduction of latency compared to state-of-the-art solutions in a benchmark-level evaluation. The proposed design also shows near-constant latency for a single broadcast operation as a system grows. Furthermore, it yields up to 24{\%} performance improvement in the popular deep learning framework, Microsoft CNTK, which uses multi-source broadcast operations; notably, the performance gains are achieved without modifications to applications. Our model validation shows that the proposed analytical model and experimental results match within a 10{\%} range. Our model also predicts that the proposed design outperforms existing schemes for multi-source broadcast scenarios with increasing numbers of broadcast sources in large-scale GPU clusters.},
  author          = {Chu, Ching Hsiang and Lu, Xiaoyi and Awan, Ammar Ahmad and Subramoni, Hari and Hashmi, Jahanzeb and Elton, Bracy and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the International Conference on Parallel Processing (ICPP)},
  doi             = {10.1109/ICPP.2017.25},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the International Conference on Parallel Processing (ICPP)/Efficient and Scalable Multi-Source Streaming Broadcast on GPU Clusters for Deep Learning - Chu et al. - Proceedings of the Inter.pdf:pdf},
  isbn            = {9781538610428},
  issn            = {01903918},
  keywords        = {Broadcast,Deep Learning,Deep{\_}Learning,GPU,GPUDirect RDMA,GPUDirect{\_}RDMA,Hardware Multicast,InfiniBand,MPI,Multi-source Broadcast,Streaming},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Broadcast,Deep{\_}Learning,GPU,GPUDirect{\_}RDMA,InfiniBand,Streaming},
  pages           = {161--170},
  title           = {{Efficient and Scalable Multi-Source Streaming Broadcast on GPU Clusters for Deep Learning}},
  year            = {2017}
}
@phdthesis{Chu2020b,
  author          = {Chu, Ching-hsiang},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Unknown/Accelerator-enabled Communication Middleware for Large-scale Heterogeneous HPC Systems with Modern Interconnects - Chu - Unknown.pdf:pdf},
  keywords        = {GPU,MPI,Thesis},
  mendeley-groups = {MustKnow,Theses},
  mendeley-tags   = {GPU,MPI,Thesis},
  pages           = {1--227},
  school          = {OSU},
  title           = {{Accelerator-enabled Communication Middleware for Large-scale Heterogeneous HPC Systems with Modern Interconnects}},
  year            = {2020}
}
@inproceedings{Chu2020,
  author          = {Chu, Ching-Hsiang and Kousha, Pouya and Awan, Ammar Ahmad and Khorassani, Kawthar Shafie and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the International Conference on Supercomputing (ICS)},
  doi             = {10.1145/3392717.3392771},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the International Conference on Supercomputing (ICS)/NV-Group Link-Efficient Reduction for Distributed Deep Learning on Modern Dense GPU Systems - Chu et al. - Proceedings of the Internati.pdf:pdf},
  isbn            = {9781450379830},
  keywords        = {2020,Deep{\_}Learning,GPU,MPI,MPI{\_}Allreduce,NV{\_}Group,acm reference format,allreduce,anonymous author,deep learning,gpu,link-efficient reduction for dis-,mpi,nv-group,nvlink},
  mendeley-groups = {MustKnow,UsedInComp1,UsedInComp2},
  mendeley-tags   = {Deep{\_}Learning,GPU,MPI,MPI{\_}Allreduce,NV{\_}Group},
  pages           = {1--12},
  title           = {{NV-Group: Link-Efficient Reduction for Distributed Deep Learning on Modern Dense GPU Systems}},
  year            = {2020}
}
@inproceedings{Chunduri2019,
  abstract      = {MPI is the most prominent programming model used in scientific computing today. Despite the importance of MPI, however, how scientific computing applications use it in production is not well understood. This lack of understanding is attributed primarily to the fact that production systems are often wary of incorporating automatic profiling tools that perform such analysis because of concerns about potential performance over-heads. In this study, we used a lightweight profiling tool, called Autoperf, to log the MPI usage characteristics of production applications on a large IBM BG/Q supercomputing system (Mira) and its corresponding development system (Cetus). Autoperf limits the amount of information that it records, in order to keep the overhead to a minimum while still storing enough data to derive useful insights. MPI usage statistics have been collected for over 100K jobs that were run within a two-year period and are analyzed in this paper. The analysis is intended to provide useful insights for MPI developers and network hardware developers for their next generation of improvements and for supercomputing center operators for their next system procurements.},
  author        = {Chunduri, Sudheer and Parker, Scott and Balaji, Pavan and Harms, Kevin and Kumaran, Kalyan},
  booktitle     = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi           = {10.1109/SC.2018.00033},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Characterization of MPI usage on a production supercomputer - Chunduri et al. - Proceedin.pdf:pdf},
  isbn          = {9781538683842},
  keywords      = {Autoperf,Core-hours,MPI,Monitoring,Survey},
  mendeley-tags = {MPI,Survey},
  pages         = {386--400},
  title         = {{Characterization of MPI usage on a production supercomputer}},
  year          = {2019}
}
@inproceedings{Congiu2018,
  abstract      = {Modern high-end computing clusters are becoming increasingly heterogeneous and include accelerators such as general-purpose GPUs and many integrated core processors. These components are often equipped with high-bandwidth on-package memory (HBM) offering higher aggregated bandwidth than standard DRAM technology has but substantially less capacity. In this paper we carry out a fine-grained evaluation of HBM usage in MPI using Knights Landing Multi-Channel DRAM (MCDRAM). Our contribution is twofold. First, we analyze the performance of point-to-point and remote memory access with HBM; Second, we introduce capacity constraints and consider the impact that the MPI library has on the total memory budget. Our analysis shows that although MCDRAM can improve MPI communication performance, this improvement comes at the cost of higher memory usage. Since HBM is a scarce resource, we also provide a list of recommendations that can help users with diverse budgetary requirements for memory decide what MPI objects to place in MCDRAM in order to achieve the best performance possible with their codes.},
  author        = {Congiu, Giuseppe and Balaji, Pavan},
  booktitle     = {Proceedings of the IEEE International Conference on Computer and Communications (ICCC)},
  doi           = {10.1109/CompComm.2018.8780911},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the IEEE International Conference on Computer and Communications (ICCC)/Evaluating the impact of high-bandwidth memory on MPI communications - Congiu, Balaji - Proceedings of the IEEE Inte.pdf:pdf},
  isbn          = {9781538683392},
  keywords      = {Heterogeneous memory,High-bandwidth memory,High-performance computing,KNL MCDRAM,MPI,Message passing interface},
  mendeley-tags = {MPI},
  pages         = {341--350},
  publisher     = {IEEE},
  title         = {{Evaluating the impact of high-bandwidth memory on MPI communications}},
  year          = {2018}
}
@inproceedings{Dang2017,
  abstract        = {Concurrent multithreaded access to the Message Passing Interface (MPI) is gaining importance to support emerging hybrid MPI applications. The interoperability between threads and MPI, however, is complex and renders efficient implementations nontrivial. Prior studies showed that threads waiting for communication progress (waiting threads) often interfere with others (active threads) and degrade their progress. This situation occurs when both classes of threads compete for the same MPI resource and ownership passing to waiting threads does not guarantee communication to advance. The best-known practical solution prioritizes active threads and adapts first-in-first-out arbitration within each class. This approach, however, suffers from residual wasted resource acquisitions (waste) and ignores data locality, thus resulting in poor scalability. In this work, we propose thread synchronization improvements to eliminate waste while preserving data locality in a production MPI implementation. First, we leverage MPI knowledge and a fast synchronization method to eliminate waste and accelerate progress. Second, we rely on a cooperative progress model that dynamically elects and restricts a single waiting thread to drive a communication context for improved data locality. Third, we prioritize active threads and synchronize them with a locality-preserving lock that is hierarchical and exploits unbounded bias for high throughput. Results show significant improvement in synthetic microbenchmarks and two MPI+OpenMP applications.},
  author          = {Dang, Hoang Vu and Seo, Sangmin and Amer, Abdelhalim and Balaji, Pavan},
  booktitle       = {Proceedings of the IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)},
  doi             = {10.1109/CCGRID.2017.65},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the IEEEACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)/Advanced Thread Synchronization for Multithreaded MPI Implementations - Dang et al. - Proceedings of the.pdf:pdf},
  isbn            = {9781509066100},
  keywords        = {Hybrid{\_}MPI,Lock,MPI,Multithreaded{\_}MPI,Mutex,OpenMP,Synchronization,Thread safety,Threads},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {Hybrid{\_}MPI,MPI,Multithreaded{\_}MPI,OpenMP},
  pages           = {314--324},
  title           = {{Advanced Thread Synchronization for Multithreaded MPI Implementations}},
  year            = {2017}
}
@article{DeSensi2020,
  abstract        = {The interconnect is one of the most critical components in large scale computing systems, and its impact on the performance of applications is going to increase with the system size. In this paper, we will describe SLINGSHOT, an interconnection network for large scale computing systems. SLINGSHOT is based on high-radix switches, which allow building exascale and hyper-scale datacenters networks with at most three switch-to-switch hops. Moreover, SLINGSHOT provides efficient adaptive routing and congestion control algorithms, and highly tunable traffic classes. SLINGSHOT uses an optimized Ethernet protocol, which allows it to be interoperable with standard Ethernet devices while providing high performance to HPC applications. We analyze the extent to which SLINGSHOT provides these features, evaluating it on microbenchmarks and on several applications from the datacenter and AI worlds, as well as on HPC applications. We find that applications running on SLINGSHOT are less affected by congestion compared to previous generation networks.},
  annote          = {- Tail latency still severely affect performance
                     
                     - Routing with pre-determined the best route
                     
                     - Why there is a limit on the number of groups to 511?
                     
                     - Isolated systems to get the benchmarks.
                     
                     - Congestion control for the last hop},
  archiveprefix   = {arXiv},
  arxivid         = {2008.08886},
  author          = {{De Sensi}, Daniele and {Di Girolamo}, Salvatore and McMahon, Kim H. and Roweth, Duncan and Hoefler, Torsten},
  doi             = {10.1109/SC41405.2020.00039},
  eprint          = {2008.08886},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/International Conference for High Performance Computing, Networking, Storage and Analysis, SC/An in-depth analysis of the slingshot interconnect - De Sensi et al. - International Conference for High Perf.pdf:pdf},
  isbn            = {9781728199986},
  issn            = {21674337},
  journal         = {International Conference for High Performance Computing, Networking, Storage and Analysis, SC},
  keywords        = {congestion,datacenters,dragonfly,exascale,interconnection network},
  mendeley-groups = {ELEC-878},
  title           = {{An in-depth analysis of the slingshot interconnect}},
  volume          = {2020-Novem},
  year            = {2020}
}
@article{DeWael2015,
  abstract      = {The Partitioned Global Address Space (PGAS) model is a parallel programming model that aims to improve programmer productivity while at the same time aiming for high performance. The main premise of PGAS is that a globally shared address space improves productivity, but that a distinction between local and remote data accesses is required to allow performance optimizations and to support scalability on large-scale parallel architectures. To this end, PGAS preserves the global address space while embracing awareness of nonuniform communication costs. Today, about a dozen languages exist that adhere to the PGAS model. This survey proposes a definition and a taxonomy along four axes: how parallelism is introduced, how the address space is partitioned, how data is distributed among the partitions, and finally, how data is accessed across partitions. Our taxonomy reveals that today's PGAS languages focus on distributing regular data and distinguish only between local and remote data access cost, whereas the distribution of irregular data and the adoption of richer data access cost models remain open challenges.},
  author        = {{De Wael}, Mattias and Marr, Stefan and {De Fraine}, Bruno and {Van Cutsem}, Tom and {De Meuter}, Wolfgang},
  doi           = {10.1145/2716320},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/ACM Computing Surveys/Partitioned global address space languages - De Wael et al. - ACM Computing Surveys.pdf:pdf},
  issn          = {15577341},
  journal       = {ACM Computing Surveys},
  keywords      = {Data access,Data distribution,HPC,Message passing,Message{\_}Passing,One-sided communication,PGAS,Parallel programming,Survey},
  mendeley-tags = {Message{\_}Passing,PGAS,Survey},
  number        = {4},
  pages         = {1--27},
  title         = {{Partitioned global address space languages}},
  volume        = {47},
  year          = {2015}
}
@techreport{Denis2020,
  author          = {Denis, Alexandre and Jaeger, Julien and Jeannot, Emmanuel and Reynier, Florian},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Unknown/Experiments for Assessing Computation Communication Overlap of MPI Nonblocking Collectives To cite this version Experiments for Assess.pdf:pdf},
  mendeley-groups = {Presentations {\&} Reports},
  title           = {{Experiments for Assessing Computation / Communication Overlap of MPI Nonblocking Collectives To cite this version : Experiments for Assessing Computa- tion / Communication Overlap of MPI Nonblocking Collectives}},
  year            = {2020}
}
@article{Derradji2015,
  abstract        = {BXI, Bull eXascale Interconnect, is the new interconnection network developed by Atos for High Performance Computing. In this paper, we first present an overview of the BXI network. The BXI network is designed and optimized for HPC workloads at very large scale. It is based on the Portals 4 protocol and permits a complete offload of communication primitives in hardware, thus enabling independent progress of computation and communication. We then describe the two BXI ASIC components, the network interface and the BXI switch, and the BXI software environment. We finally explain how the Bull exascale platform integrates BXI to build a large scale parallel system and we give some performance estimations.},
  author          = {Derradji, Sa{\"{i}}d and Palfer-Sollier, Thibaut and Panziera, Jean Pierre and Poudes, Axel and Wellenreiter, Fran{\c{c}}ois},
  doi             = {10.1109/HOTI.2015.15},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Proceedings of the Annual Symposium on High-Performance Interconnects, HOTI/The BXI Interconnect Architecture - Derradji et al. - Proceedings of the Annual Symposium on High-Performance Interconnects, HO.pdf:pdf},
  isbn            = {9781467391603},
  journal         = {Proceedings of the Annual Symposium on High-Performance Interconnects, HOTI},
  keywords        = {Interconnect technologies,high performance computing,parallel and scalable system architecture},
  mendeley-groups = {ELEC-878},
  pages           = {18--25},
  title           = {{The BXI Interconnect Architecture}},
  year            = {2015}
}
@phdthesis{Dialesandro2021,
  abstract        = {Exposure to heat exacerbated by an increase in urbanization as well as increasing global temperatures has become a growing concern for cities and their residents. Excess heat can cause increased heat-related morbidity, mortality, and energy costs. A large goal of climate adaptation is to reduce this urban heat island effect. However, cooling strategies for dryland cities will likely be different from those for wetter, temperate cities. In addition, different socioeconomic and racial groups often face unequal exposure to heat as well as increased heat-related sickness, mortality, and energy costs. Many experts have found that historically red lined neighborhoods often experience the greatest amount of excess urban heat with the least amount of resources to mitigate it.This dissertation consists of three standalone articles that make independent scientific contributions to the same problem of measuring and mitigating urban heat in dryland cities. The articles use thermal infrared remote sensing to measure the thermal footprint of cities, and a variety of sociodemographic and biophysical ancillary data. In the first article we measure how urban heat behaves in 10 large global cities in relation to different types of land cover and built form. The cities included desert cities of Cairo, Egypt and Dubai, UAE, as well as monsoon dryland cities like Delhi, India which goes 9 months of the year with almost no rainfall. The results showed that urban forest and green spaces can be up to 12° C cooler than city wide averages for both day and night. We also found spillover cooling of up to 5 km for the urban green spaces. In the second article we mapped the thermal footprint of 20 southwestern US cities for average summer, and extreme heat event temperatures. We then compared the wealthiest and poorest block groups as well as LatinX and white neighborhoods. We found that low income block groups were subject to temperatures 2-5° C warmer than wealthier block groups as were LatinX neighborhoods. In the final chapter we developed a vulnerability index for the cities of Bakersfield and Fresno California as well as utilizing the InVEST Urban Cooling model from the Stanford Natural Capital Project to model cooling scenarios from planning interventions such as increasing surface albedo of built form and increasing tree canopy. By modeling 10 and 25{\%} increases of tree canopy and albedo we found increasing tree canopy on developed land uses by as little as 10{\%} could lead to a decrease in temperatures of 1.2° C (2° F) or more throughout the cities, and made a greater difference for low income block groups compared to higher income block groups. The cooling impact of urban trees based on the InVEST model extended up to 2 kilometers. Increasing albedo of paved surfaces by 10{\%} resulted in a non substantial decrease in temperatures throughout the cities. Our research using this model showed that increasing tree canopy is more effective at mitigating high temperatures for vulnerable neighborhoods than decreasing albedo, and high vulnerability neighborhoods. This research demonstrates that unequal heat burden exists amongst dryland cities, but there are effective ways to mitigate the excess heat.},
  author          = {Dialesandro, John M},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Unknown/Fully Concurrent GPU Data Structures - Dialesandro - Unknown.pdf:pdf},
  keywords        = {GPU,Thesis},
  mendeley-groups = {MustKnow,Theses},
  mendeley-tags   = {GPU,Thesis},
  pages           = {1--116},
  school          = {UNIVERSITY OF CALIFORNIA DAVIS},
  title           = {{Fully Concurrent GPU Data Structures}},
  year            = {2021}
}
@article{Diener2016,
  abstract      = {Shared memory architectures have recently experienced a large increase in thread-level parallelism, leading to complex memory hierarchies with multiple cache memory levels and memory controllers. These new designs created a Non-Uniform Memory Access (NUMA) behavior, where the performance and energy consumption of memory accesses depend on the place where the data is located in the memory hierarchy. Accesses to local caches or memory controllers are generally more efficient than accesses to remote ones. A common way to improve the locality and balance of memory accesses is to determine the mapping of threads to cores and data to memory controllers based on the affinity between threads and data. Such mapping techniques can operate at different hardware and software levels, which impacts their complexity, applicability, and the resulting performance and energy consumption gains. In this article, we introduce a taxonomy to classify different mapping mechanisms and provide a comprehensive overview of existing solutions.},
  author        = {Diener, Matthias and Cruz, Eduardo H.M. and Alves, Marco A.Z. and Navaux, Philippe O.A. and Koren, Israel},
  doi           = {10.1145/3006385},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/ACM Computing Surveys/Affinity-based thread and data mapping in shared memory systems - Diener et al. - ACM Computing Surveys.pdf:pdf},
  issn          = {15577341},
  journal       = {ACM Computing Surveys},
  keywords      = {Cache memories,Communication,Data mapping,Mapping,Multithread,NUMA,Shared memory,Survey,Thread mapping},
  mendeley-tags = {Mapping,Multithread,Survey},
  number        = {4},
  pages         = {1--38},
  title         = {{Affinity-based thread and data mapping in shared memory systems}},
  volume        = {49},
  year          = {2016}
}
@techreport{Dinan2020,
  author          = {Dinan, James},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Unknown/MPI HYBRID {\&} ACCELERATOR ( HACC ) WG KICKOFF - Dinan - Unknown.pdf:pdf},
  mendeley-groups = {Presentations {\&} Reports},
  title           = {{MPI HYBRID {\&} ACCELERATOR ( HACC ) WG KICKOFF}},
  year            = {2020}
}
@inproceedings{Dinan2013,
  abstract      = {The current MPI model defines a one-to-one relationship between MPI processes and MPI ranks. This model captures many use cases effectively, such as one MPI process per core and one MPI process per node. However, this semantic has limited interoperability between MPI and other programming models that use threads within a node. In this paper, we describe an extension to MPI that introduces communication endpoints as a means to relax the one-to-one relationship between processes and threads. Endpoints enable a greater degree interoperability between MPI and other programming models, and we illustrate their potential for additional performance and computation management benefits through the decoupling of ranks from processes.},
  author        = {Dinan, James and Balaji, Pavan and Goodell, David and Miller, Douglas and Snir, Marc and Thakur, Rajeev},
  booktitle     = {Proceedings of the European MPI Users' Group Meeting (EuroMPI)},
  doi           = {10.1145/2488551.2488553},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2013/Proceedings of the European MPI Users' Group Meeting (EuroMPI)/Enabling MPI interoperability through flexible communication endpoints - Dinan et al. - Proceedings of the European MPI Users' Group Mee.pdf:pdf},
  isbn          = {9788461651337},
  keywords      = {Endpoints,Hybrid parallel programming,Hybrid{\_}MPI,Interoperability,MPI,Multithreaded{\_}MPI},
  mendeley-tags = {Endpoints,Hybrid{\_}MPI,MPI,Multithreaded{\_}MPI},
  pages         = {13--18},
  title         = {{Enabling MPI interoperability through flexible communication endpoints}},
  year          = {2013}
}
@inproceedings{Dinan2010,
  abstract      = {The Message Passing Interface (MPI) is one of the most widely used programming models for parallel computing. However, the amount of memory available to an MPI process is limited by the amount of local memory within a compute node. Partitioned Global Address Space (PGAS) models such as Unified Parallel C (UPC) are growing in popularity because of their ability to provide a shared global address space that spans the memories of multiple compute nodes. However, taking advantage of UPC can require a large recoding effort for existing parallel applications. In this paper, we explore a new hybrid parallel programming model that combines MPI and UPC. This model allows MPI programmers incremental access to a greater amount of memory, enabling memory-constrained MPI codes to process larger data sets. In addition, the hybrid model offers UPC programmers an opportunity to create static UPC groups that are connected over MPI. As we demonstrate, the use of such groups can significantly improve the scalability of locality-constrained UPC codes. This paper presents a detailed description of the hybrid model and demonstrates its effectiveness in two applications: a random access benchmark and the Barnes-Hut cosmological simulation. Experimental results indicate that the hybrid model can greatly enhance performance; using hybrid UPC groups that span two cluster nodes, RA performance increases by a factor of 1.33 and using groups that span four cluster nodes, Barnes-Hut experiences a twofold speedup at the expense of a 2{\%} increase in code size. {\textcopyright} 2010 ACM.},
  author        = {Dinan, James and Balaji, Pavan and Lusk, Ewing and Sadayappan, P. and Thakur, Rajeev},
  booktitle     = {Proceedings of the International Conference on Computing Frontiers (CF)},
  doi           = {10.1145/1787275.1787323},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2010/Proceedings of the International Conference on Computing Frontiers (CF)/Hybrid parallel programming with MPI and unified parallel C - Dinan et al. - Proceedings of the International Conference on Computi.pdf:pdf},
  isbn          = {9781450300445},
  keywords      = {Hybrid{\_}MPI,MPI,Multithreaded{\_}MPI,UPC,hybrid parallel programming,mpi,pgas,upc},
  mendeley-tags = {Hybrid{\_}MPI,MPI,Multithreaded{\_}MPI,UPC},
  pages         = {177--185},
  title         = {{Hybrid parallel programming with MPI and unified parallel C}},
  year          = {2010}
}
@article{Dinan2014a,
  abstract        = {MPI defines a one-to-one relationship between MPI processes and ranks. This model captures many use cases effectively; however, it also limits communication concurrency and interoperability between MPI and programming models that utilize threads. This paper describes the MPI endpoints extension, which relaxes the longstanding one-to-one relationship between MPI processes and ranks. Using endpoints, an MPI implementation can map separate communication contexts to threads, allowing them to drive communication independently. Endpoints also enable threads to be addressable in MPI operations, enhancing interoperability between MPI and other programming models. These characteristics are illustrated through several examples and an empirical study that contrasts current multithreaded communication performance with the need for high degrees of communication concurrency to achieve peak communication performance.},
  author          = {Dinan, James and Grant, Ryan E. and Balaji, Pavan and Goodell, David and Miller, Douglas and Snir, Marc and Thakur, Rajeev},
  doi             = {10.1177/1094342014548772},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/International Journal of High Performance Computing Applications/Enabling communication concurrency through flexible MPI endpoints - Dinan et al. - International Journal of High Performance Computing A.pdf:pdf},
  issn            = {17412846},
  journal         = {International Journal of High Performance Computing Applications},
  keywords        = {MPI,communication concurrency,endpoints,hybrid parallel programming,interoperability},
  mendeley-groups = {ELEC-878},
  number          = {4},
  pages           = {390--405},
  title           = {{Enabling communication concurrency through flexible MPI endpoints}},
  volume          = {28},
  year            = {2014}
}
@article{Dinan2014,
  abstract        = {MPI defines a one-to-one relationship between MPI processes and ranks. This model captures many use cases effectively; however, it also limits communication concurrency and interoperability between MPI and programming models that utilize threads. This paper describes the MPI endpoints extension, which relaxes the longstanding one-to-one relationship between MPI processes and ranks. Using endpoints, an MPI implementation can map separate communication contexts to threads, allowing them to drive communication independently. Endpoints also enable threads to be addressable in MPI operations, enhancing interoperability between MPI and other programming models. These characteristics are illustrated through several examples and an empirical study that contrasts current multithreaded communication performance with the need for high degrees of communication concurrency to achieve peak communication performance.},
  author          = {Dinan, James and Grant, Ryan E. and Balaji, Pavan and Goodell, David and Miller, Douglas and Snir, Marc and Thakur, Rajeev},
  doi             = {10.1177/1094342014548772},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/The International Journal of High Performance Computing Applications/Enabling communication concurrency through flexible MPI endpoints - Dinan et al. - The International Journal of High Performance Compu.pdf:pdf},
  issn            = {17412846},
  journal         = {The International Journal of High Performance Computing Applications},
  keywords        = {MPI,Multithreaded{\_}MPI,communication concurrency,endpoints,hybrid parallel programming,interoperability},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Multithreaded{\_}MPI},
  number          = {4},
  pages           = {390--405},
  title           = {{Enabling communication concurrency through flexible MPI endpoints}},
  volume          = {28},
  year            = {2014}
}
@inproceedings{Dosanjh2018,
  abstract        = {The performance critical path for MPI implementations relies on fast receive side operation, which in turn requires fast list traversal. The performance of list traversal is dependent on data-locality; whether the data is currently contained in a close-to-core cache due to its temporal locality or if its spacial locality allows for predictable pre-fetching. In this paper, we explore the effects of data locality on the MPI matching problem by examining both forms of locality. First, we explore spacial locality, by combining multiple entries into a single linked list element, we can control and modify this form of locality. Secondly, we explore temporal locality by utilizing a new technique called “hot caching”, a process that creates a thread to periodically access certain data, increasing its temporal locality. In this paper, we show that by increasing data locality, we can improve MPI performance on a variety of architectures up to 4x for micro-benchmarks and up to 2x for an application.},
  author          = {Dosanjh, Matthew G.F. and Ghazimirsaeed, S. Mahdieh and Grant, Ryan E. and Schonbein, Whit and Levenhagen, Michael J. and Bridges, Patrick G. and Afsahi, Ahmad},
  booktitle       = {Proceedings of the International Conference on Parallel Processing (ICPP)},
  doi             = {10.1145/3225058.3225130},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the International Conference on Parallel Processing (ICPP)/The Case for Semi-Permanent Cache Occupancy Understanding the Impact of Data Locality on Network Processing - Dosanjh et al. - Pr.pdf:pdf},
  isbn            = {9781450365109},
  keywords        = {MPI,Message passing,Message{\_}Matching,Performance},
  mendeley-groups = {UsedInComp1,ByPPRL},
  mendeley-tags   = {MPI,Message{\_}Matching},
  pages           = {1--11},
  title           = {{The Case for Semi-Permanent Cache Occupancy: Understanding the Impact of Data Locality on Network Processing}},
  year            = {2018}
}
@article{Dosanjh2019a,
  abstract        = {As we approach exascale, computational parallelism will have to drastically increase in order to meet throughput targets. Many-core architectures have exacerbated this problem by trading reduced clock speeds, core complexity, and computation throughput for increasing parallelism. This presents two major challenges for communication libraries such as MPI: the library must leverage the performance advantages of thread level parallelism and avoid the scalability problems associated with increasing the number of processes to that scale. Hybrid programming models, such as MPI+X, have been proposed to address these challenges. MPI THREAD MULTIPLE is MPI's thread safe mode. While there has been work to optimize it, it largely remains non-performant in most implementations. While current applications avoid MPI multithreading due to performance concerns, it is expected to be utilized in future applications. One of the major synchronous data structures required by MPI is the matching engine. In this paper, we present a parallel matching algorithm that can improve MPI matching for multithreaded applications. We then perform a feasibility study to demonstrate the performance benefit of the technique.},
  author          = {Dosanjh, Matthew G.F. and Grant, Ryan E. and Schonbein, Whit and Bridges, Patrick G.},
  doi             = {10.1002/cpe.5158},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Concurrency and Computation Practice and Experience (CCPE)/Tail queues A multi-threaded matching architecture - Dosanjh et al. - Concurrency and Computation Practice and Experience (CCPE).pdf:pdf},
  issn            = {15320634},
  journal         = {Concurrency and Computation: Practice and Experience (CCPE)},
  keywords        = {MPI,Message{\_}Matching,Multithreaded{\_}MPI,Network,high performance computing,many core,networks},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Message{\_}Matching,Multithreaded{\_}MPI,Network},
  pages           = {1--13},
  title           = {{Tail queues: A multi-threaded matching architecture}},
  year            = {2019}
}
@inproceedings{Dosanjh2016,
  abstract      = {Reaching Exascale will require leveraging massive parallelism while potentially leveraging asynchronous communication to help achieve scalability at such large levels of concurrency. MPI is a good candidate for providing the mechanisms to support communication at such large scales. Two existing MPI mechanisms are particularly relevant to Exascale: multi-threading, to support massive concurrency, and Remote Memory Access (RMA), to support asynchronous communication. Unfor-tunately, multi-threaded MPI RMA code has not been extensively studied. Part of the reason for this is that no public benchmarks or proxy applications exist to assess its performance. The contributions of this paper are the design and demonstration of the first available proxy applications and micro-benchmark suite for multi-threaded RMA in MPI, a study of multi-threaded RMA performance of different MPI implementations, and an evaluation of how these benchmarks can be used to test development for both performance and correctness.},
  author        = {Dosanjh, Matthew G.F. and Groves, Taylor and Grant, Ryan E. and Brightwell, Ron and Bridges, Patrick G.},
  booktitle     = {Proceedings of the IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)},
  doi           = {10.1109/CCGrid.2016.84},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the IEEEACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)/RMA-MT A Benchmark Suite for Assessing MPI Multi-threaded RMA Performance - Dosanjh et al. - Proceedings.pdf:pdf},
  isbn          = {9781509024520},
  keywords      = {Benchmark,Benchmark Suite,MPI,Multi-threading,Multithreaded{\_}MPI,One-sided,RDMA,RMA},
  mendeley-tags = {Benchmark,MPI,Multithreaded{\_}MPI,RDMA,RMA},
  pages         = {550--559},
  publisher     = {IEEE},
  title         = {{RMA-MT: A Benchmark Suite for Assessing MPI Multi-threaded RMA Performance}},
  year          = {2016}
}
@inproceedings{Dosanjh2019,
  abstract        = {Contemporary parallel scientific codes often rely on message passing for inter-process communication. However, inefficient coding practices or multithreading (e.g., via MPI-THREAD-MULTIPLE) can severely stress the underlying message processing infrastructure, resulting in potentially un-acceptable impacts on application performance. In this article, we propose and evaluate a novel method for addressing this issue: 'Fuzzy Matching'. This approach has two components. First, it exploits the fact most server-class CPUs include vector operations to parallelize message matching. Second, based on a survey of point-to-point communication patterns in representative scientific applications, the method further increases parallelization by allowing matches based on 'partial truth', i.e., by identifying probable rather than exact matches. We evaluate the impact of this approach on memory usage and performance on Knight's Landing and Skylake processors. At scale (262,144 Intel Xeon Phi cores), the method shows up to 1.13 GiB of memory savings per node in the MPI library, and improvement in matching time of 95.9{\%}; smaller-scale runs show run-time improvements of up to 31.0{\%} for full applications, and up to 6.1{\%} for optimized proxy applications.},
  author          = {Dosanjh, Matthew G.F. and Schonbein, Whit and Grant, Ryan E. and Bridges, Patrick G. and Ghazimirsaeed, S. Mahdieh and Afsahi, Ahmad},
  booktitle       = {Proceedings of the IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)},
  doi             = {10.1109/CCGRID.2019.00035},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the IEEEACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)/Fuzzy matching Hardware accelerated MPI communication middleware - Dosanjh et al. - Proceedings of the IE.pdf:pdf},
  isbn            = {9781728109121},
  keywords        = {KNL,MPI,MPI Message Matching,Message Matching,Message{\_}Matching,Networks,Optimization,Scalable System Software,Vectors},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Message{\_}Matching},
  pages           = {210--220},
  title           = {{Fuzzy matching: Hardware accelerated MPI communication middleware}},
  year            = {2019}
}
@inproceedings{Dryden2019,
  abstract      = {We identify communication as a major bottleneck for training deep neural networks on large-scale GPU clusters, taking over 10x as long as computation. To reduce this overhead, we discuss techniques to overlap communication and computation as much as possible. This leads to much of the communication being latency-bound instead of bandwidth-bound, and we find that using a combination of latency- and bandwidth-optimized allreduce algorithms significantly reduces communication costs. We also discuss a semantic mismatch between MPI and CUDA that increases overheads and limits asynchrony, and propose a solution that enables communication to be aware of CUDA streams. We implement these optimizations in the open-source Aluminum communication library, enabling optimized, asynchronous, GPU-aware communication. Aluminum demonstrates improved performance in benchmarks and end-to-end training of deep networks, for both strong and weak scaling.},
  author        = {Dryden, Nikoli and Maruyama, Naoya and Moon, Tim and Benson, Tom and Yoo, Andy and Snir, Marc and {Van Essen}, Brian},
  booktitle     = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi           = {10.1109/MLHPC.2018.8638639},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Aluminum An Asynchronous, GPU-Aware Communication Library Optimized for Large-Scale Train.pdf:pdf},
  isbn          = {9781728101804},
  keywords      = {Collective algorithms,Collectives,Communication optimization,Deep learning,Deep{\_}Learning,HPC,Machine learning},
  mendeley-tags = {Collectives,Deep{\_}Learning},
  pages         = {1--13},
  title         = {{Aluminum: An Asynchronous, GPU-Aware Communication Library Optimized for Large-Scale Training of Deep Neural Networks on HPC Systems}},
  year          = {2019}
}
@article{Duato2010,
  abstract      = {The increasing computing requirements for GPUs (Graphics Processing Units) have favoured the design and marketing of commodity devices that nowadays can also be used to accelerate general purpose computing. Therefore, future high performance clusters intended for HPC (High Performance Computing) will likely include such devices. However, high-end GPU-based accelerators used in HPC feature a considerable energy consumption, so that attaching a GPU to every node of a cluster has a strong impact on its overall power consumption. In this paper we detail a framework that enables remote GPU acceleration in HPC clusters, thus allowing a reduction in the number of accelerators installed in the cluster. This leads to energy, acquisition, maintenance, and space savings. {\textcopyright}2010 IEEE.},
  author        = {Duato, Jos{\'{e}} and Pe{\~{n}}a, Antonio J. and Silla, Federico and Mayo, Rafael and Quintana-Ort, Enrique S.},
  doi           = {10.1109/HPCS.2010.5547126},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2010/Proceedings of the International Conference on High Performance Computing and Simulation (HPCS)/rCUDA Reducing the number of GPU-based accelerators in high performance clusters - Duato et al. - Proceedin.pdf:pdf},
  isbn          = {9781424468287},
  journal       = {Proceedings of the International Conference on High Performance Computing and Simulation (HPCS)},
  keywords      = {CUDA,Clusters,Energy saving,GPU,High performance computing,Virtualization},
  mendeley-tags = {CUDA,GPU},
  pages         = {224--231},
  title         = {{rCUDA: Reducing the number of GPU-based accelerators in high performance clusters}},
  year          = {2010}
}
@inproceedings{Faraj2009,
  abstract      = {The IBM Blue Gene/P (BG/P) system is a massively parallel supercomputer succeeding BG/L, and it is based on orders of magnitude in system size and significant power consumption efficiency. BG/P comes with many enhancements to the machine design and new architectural features at the hardware and software levels. In this work, we demonstrate techniques to leverage the architectural features of BG/P to deliver high performance MPI collective communication primitives.},
  author        = {Faraj, Ahmad and Kumar, Sameer and Smih, Brian and Mamidala, Amith and Gunnels, John and Heidelberger, Philip},
  booktitle     = {Proceedings of the International Conference on Supercomputing (ICS)},
  doi           = {10.1145/1542275.1542344},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2009/Proceedings of the International Conference on Supercomputing (ICS)/MPI collective communications on the Blue GeneP supercomputer - Faraj et al. - Proceedings of the International Conference on Supercomp.pdf:pdf},
  isbn          = {9781605584980},
  keywords      = {BlueGene,Collectives,MPI,blue gene,collective,communication,mpi},
  mendeley-tags = {BlueGene,Collectives,MPI},
  pages         = {489--490},
  title         = {{MPI collective communications on the Blue Gene/P supercomputer}},
  year          = {2009}
}
@article{Faraj2008,
  abstract        = {Process arrival pattern, which denotes the timing when different processes arrive at an MPI collective operation, can have a significant impact on the performance of the operation. In this work, we characterize the process arrival patterns in a set of MPI programs on two common cluster platforms, use a micro-benchmark to study the process arrival patterns in MPI programs with balanced loads, and investigate the impacts of different process arrival patterns on collective algorithms. Our results show that (1) the differences between the times when different processes arrive at a collective operation are usually sufficiently large to affect the performance; (2) application developers in general cannot effectively control the process arrival patterns in their MPI programs in the cluster environment: balancing loads at the application level does not balance the process arrival patterns; and (3) the performance of collective communication algorithms is sensitive to process arrival patterns. These results indicate that process arrival pattern is an important factor that must be taken into consideration in developing and optimizing MPI collective routines. We propose a scheme that achieves high performance with different process arrival patterns, and demonstrate that by explicitly considering process arrival pattern, more efficient MPI collective routines than the current ones can be obtained. {\textcopyright} 2008 Springer Science+Business Media, LLC.},
  author          = {Faraj, Ahmad and Patarasuk, Pitch and Yuan, Xin},
  doi             = {10.1007/s10766-008-0070-9},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2008/International Journal of Parallel Programming/A study of process arrival patterns for MPI collective operations - Faraj, Patarasuk, Yuan - International Journal of Parallel Programmi.pdf:pdf},
  issn            = {08857458},
  journal         = {International Journal of Parallel Programming},
  keywords        = {Collective communication,Collectives,Communication algorithm,MPI,PAP,Process arrival pattern},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {Collectives,MPI,PAP},
  pages           = {543--570},
  title           = {{A study of process arrival patterns for MPI collective operations}},
  year            = {2008}
}
@inproceedings{Faraj2005,
  abstract        = {In order for collective communication routines to achieve high performance on different platforms, they must be able to adapt to the system architecture and use different algorithms for different situations. Current Message Passing Interface (MPI) implementations, such as MPICH and LAM/MPI, are not fully adaptable to the system architecture and are not able to achieve high performance on many platforms. In this paper, we present a system that produces efficient MPI collective communication routines. By automatically generating topology specific routines and using an empirical approach to select the best implementations, our system adapts to a given platform and constructs routines that are customized for the platform. The experimental results show that the tuned routines consistently achieve high performance on clusters with different network topologies. Copyright {\textcopyright} 2005, ACM.},
  author          = {Faraj, Ahmad and Yuan, Xin},
  booktitle       = {Proceedings of the International Conference on Supercomputing (ICS)},
  doi             = {10.1145/1088149.1088202},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2005/Proceedings of the International Conference on Supercomputing (ICS)/Automatic generation and tuning of MPI collective communication routines - Faraj, Yuan - Proceedings of the International Conference on.pdf:pdf},
  isbn            = {1595931678},
  keywords        = {Auto{\_}Tune,Cluster of Workstations,Collectives,Empirical,MPI,Tuning System},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Auto{\_}Tune,Collectives,MPI},
  pages           = {393--402},
  title           = {{Automatic generation and tuning of MPI collective communication routines}},
  year            = {2005}
}
@inproceedings{Faraj2006,
  abstract        = {Message Passing Interface (MPI) collective communication routines are widely used in parallel applications. In order for a collective communication routine to achieve high performance for different applications on different platforms, it must be adaptable to both the system architecture and the application workload. Current MPI implementations do not support such software adaptability and are not able to achieve high performance on many platforms. In this paper, we present STAR-MPI (Self Tuned Adaptive Routines for MPI collective operations), a set of MPI collective communication routines that are capable of adapting to system architecture and application workload. For each operation, STAR-MPI maintains a set of communication algorithms that can potentially be efficient at different situations. As an application executes, a STAR-MPI routine applies the Automatic Empirical Optimization of Software (AEOS) technique at run time to dynamically select the best performing algorithm for the application on the platform. We describe the techniques used in STAR-MPI, analyze STAR-MPI overheads, and evaluate the performance of STAR-MPI with applications and benchmarks. The results of our study indicate that STAR-MPI is robust and efficient. It is able to and efficient algorithms with reasonable overheads, and it out-performs traditional MPI implementations to a large degree in many cases. Copyright {\textcopyright} 2006 ACM.},
  author          = {Faraj, Ahmad and Yuan, Xin and Lowenthal, David},
  booktitle       = {Proceedings of the International Conference on Supercomputing (ICS)},
  doi             = {10.1145/1183401.1183431},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2006/Proceedings of the International Conference on Supercomputing (ICS)/STAR-MPI Self tuned adaptive routines for MPI collective operations - Faraj, Yuan, Lowenthal - Proceedings of the International Confere.pdf:pdf},
  isbn            = {1595932828},
  keywords        = {Adaptive,Auto{\_}Tune,Collectives,GPU,MPI},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Adaptive,Auto{\_}Tune,Collectives,GPU,MPI},
  pages           = {199--208},
  title           = {{STAR-MPI: Self tuned adaptive routines for MPI collective operations}},
  year            = {2006}
}
@misc{Faraji2016a,
  abstract      = {A benchmark suite to evaluate CPU and GPU communication efficiency of MPI using different communication patterns},
  author        = {Faraji, Iman},
  keywords      = {Benchmark,GPU,MPI,Web},
  mendeley-tags = {Benchmark,GPU,MPI,Web},
  title         = {{Accelerated MPI benchmark}},
  url           = {https://github.com/imanfaraji/MPI-ACC},
  urldate       = {2020-07-12},
  year          = {2016}
}
@phdthesis{Faraji2018a,
  author          = {Faraji, Iman},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Unknown/Improving Communication Performance in GPU-Accelerated HPC Clusters - Faraji - Unknown.pdf:pdf},
  keywords        = {GPU,MPI,Thesis},
  mendeley-groups = {ByPPRL,Theses},
  mendeley-tags   = {GPU,MPI,Thesis},
  number          = {January},
  pages           = {1--192},
  school          = {Queen's University},
  title           = {{Improving Communication Performance in GPU-Accelerated HPC Clusters}},
  year            = {2018}
}
@inproceedings{Faraji2014,
  abstract        = {Modern multi-core clusters are increasingly using GPUs to achieve higher performance and power efficiency. In such clusters, efficient communication among processes with data residing in GPU memory is of paramount importance to the performance of MPI applications. This paper investigates the efficient design of intranode MPI Allreduce operation in GPU clusters. We propose two design alternatives that exploit in-GPU reduction and fast intranode communication capabilities of modern GPUs. Our GPU shared-buffer aware design and GPU-aware Binomial reduce-broadcast algorithmic approach provide significant speedup over MVAPICH2 by up to 22 and 16 times, respectively.},
  author          = {Faraji, Iman and Afsahi, Ahmad},
  booktitle       = {Proceedings of the European MPI Users' Group Meeting (EuroMPI)},
  doi             = {10.1145/2642769.2642773},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Proceedings of the European MPI Users' Group Meeting (EuroMPI)/GPU-aware intranode MPI-Allreduce - Faraji, Afsahi - Proceedings of the European MPI Users' Group Meeting (EuroMPI).pdf:pdf},
  isbn            = {9781450328753},
  keywords        = {GPU,IPC,Intra{\_}node,Intranode MPI Allreduce,MPI,MPI{\_}Allreduce,Shared Buffer},
  mendeley-groups = {MustKnow,ByPPRL},
  mendeley-tags   = {GPU,Intra{\_}node,MPI{\_}Allreduce},
  pages           = {45--50},
  title           = {{GPU-aware intranode MPI-Allreduce}},
  year            = {2014}
}
@article{Faraji2015a,
  abstract      = {In GPU clusters, high GPU utilization and efficient communication play an important role in the performance of the MPI applications. To improve the GPU utilization, NVIDIA has introduced the Multi Process Service (MPS), eliminating the context-switching overhead among processes accessing the GPU and allowing multiple intranode processes to further overlap their CUDA tasks on the GPU and potentially share its resources through the Hyper-Q feature. Prior to MPS, Hyper-Q could only provide such resource sharing within a single process. In this paper, we evaluate the effect of the MPS service on the GPU communications with the focus on CUDA IPC and host-staged copies. We provide evidence that utilizing the MPS service is beneficial on multiple interprocess communications using these copy types. However, we show that efficient design decisions are required to further harness the potential of this service. To this aim, we propose a Static algorithm and Dynamic algorithm that can be applied to various intranode MPI collective operations, and as a test case we provide the results for the MPI-Allreduce operation. Both approaches, while following different algorithms, use a combination of the host-staged and CUDA IPC copies for the interprocess communications of their collective designs. By selecting the right number and type of the copies, our algorithms are capable of effciently leveraging the MPS and Hyper-Q feature and provide improvement over MVAPICH2 and MVAPICH2-GDR for most of the medium and all of the large messages. Our results suggest that the Dynamic algorithm is comparable with the Static algorithm, while is independent of any tuning table and thus can be portable across platforms.},
  author        = {Faraji, Iman and Afsahi, Ahmad},
  doi           = {10.1145/2832241.2832247},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Proceedings of the International Workshop on Extreme Scale Programming Models and Middleware (ESPM)/Hyper-Q aware intranode MPI collectives on the GPU - Faraji, Afsahi - Proceedings of the International.pdf:pdf},
  isbn          = {9781450339964},
  journal       = {Proceedings of the International Workshop on Extreme Scale Programming Models and Middleware (ESPM)},
  keywords      = {GPU,Hyper-Q,Interprocess copy,Intranode collective,MPI},
  mendeley-tags = {GPU,MPI},
  pages         = {47--50},
  title         = {{Hyper-Q aware intranode MPI collectives on the GPU}},
  year          = {2015}
}
@article{Faraji2018,
  abstract        = {GPU accelerators have established themselves in the state-of-the-art clusters by offering high performance and energy efficiency. In such systems, efficient inter-process GPU communication is of paramount importance to application performance. This paper investigates various algorithms in conjunction with the latest GPU features to improve GPU collective operations. First, we propose a GPU Shared Buffer-aware (GSB) algorithm and a Binomial Tree Based (BTB) algorithm for GPU collectives on single-GPU nodes. We then propose a hierarchical framework for clusters with multi-GPU nodes. By studying various combinations of algorithms, we highlight the importance of choosing the right algorithm within each level. The evaluation of our framework on MPI{\_}Allreduce shows promising performance results for large message sizes. To address the shortcoming for small and medium messages, we present the benefit of using the Hyper-Q feature and the MPS service in jointly using CUDA IPC and host-staged copy types to perform multiple inter-process communications. However, we argue that efficient designs are still required to further harness this potential. Accordingly, we propose a static and a dynamic algorithm for MPI{\_}Allgather and MPI{\_}Allreduce and present their effectiveness on various message sizes. Our profiling results indicate that the achieved performance is mainly rooted in overlapping different copy types.},
  author          = {Faraji, Iman and Afsahi, Ahmad},
  doi             = {10.1002/cpe.4667},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Concurrency and Computation Practice and Experience (CCPE)/Design considerations for GPU-aware collective communications in MPI - Faraji, Afsahi - Concurrency and Computation Practice and Experie.pdf:pdf},
  issn            = {15320634},
  journal         = {Concurrency and Computation: Practice and Experience (CCPE)},
  keywords        = {Collectives,GPU,Hierarchical,MPI,MPS,collectives,hierarchical framework,inter-process communications},
  mendeley-groups = {MustKnow,UsedInComp1,UsedInComp2,ByPPRL},
  mendeley-tags   = {Collectives,GPU,Hierarchical,MPI},
  number          = {17},
  pages           = {1--24},
  title           = {{Design considerations for GPU-aware collective communications in MPI}},
  volume          = {30},
  year            = {2018}
}
@techreport{Faraji2021,
  author          = {Faraji, Iman and Herche, Logan and Docca, Akhil},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Unknown/Overcoming HPC Application Communication Bottlenecks with Intelligent and Automatic Resource Selection - Faraji, Herche, Docca - Unknown.pdf:pdf},
  keywords        = {CUDA,GPU,Topology{\_}Aware},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {CUDA,GPU,Topology{\_}Aware},
  pages           = {1--31},
  title           = {{Overcoming HPC Application Communication Bottlenecks with Intelligent and Automatic Resource Selection}},
  url             = {https://developer.nvidia.com/nvidia-nvtags},
  year            = {2021}
}
@inproceedings{Faraji2016,
  abstract        = {GPU accelerators have successfully established themselves in modern HPC clusters due to their high performance and energy efficiency. To increase the GPU computational power in a cluster node and tackle larger problems, multi-GPU nodes have become the platform of choice for scientific applications. In a multi-GPU node, GPU devices are interconnected together via different communication channels. Thus, intranode inter-process communications among GPUs may traverse different paths with different latency and bandwidth capacity. As the number of GPUs within a multi-GPU node increases, the topology of GPU interconnects becomes more hierarchical, effectively increasing the heterogeneity of the GPU communication channels. In this paper, we provide evidence that the performance of different intranode GPU communication channels can be considerably different from each other. This is specially true for larger message sizes. Taking this into account, our goal in this work is to efficiently assign the available GPU devices on a multi-GPU node to MPI processes in order to improve the GPU-to-GPU communication performance. We tackle this challenge by proposing a topology-aware GPU selection scheme. Our scheme is capable of efficiently mapping MPI processes to the available intranode GPU devices, in a way that more intensive inter-process GPU communications take place on the more efficient communication channels. Our experimental results show that our topology-aware GPU selection scheme can improve the communication performance of the microbenchmarks with different communication patterns, specifically those with weighted and asymmetrical communications.},
  author          = {Faraji, Iman and Mirsadeghi, Seyed Hessam and Afsahi, Ahmad},
  booktitle       = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi             = {10.1109/IPDPSW.2016.44},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/Topology-aware GPU selection on multi-GPU nodes - Faraji, Mirsadeghi, Afsahi - Proceedings of the IEEE Internat.pdf:pdf},
  isbn            = {9781509021406},
  keywords        = {GPU,MPI,Mapping,Multi-GPU node,Multi{\_}GPU,Topology-aware GPU Selection,Topology{\_}Aware},
  mendeley-groups = {MustKnow,UsedInComp2,ByPPRL},
  mendeley-tags   = {GPU,MPI,Mapping,Multi{\_}GPU,Topology{\_}Aware},
  pages           = {712--720},
  title           = {{Topology-aware GPU selection on multi-GPU nodes}},
  year            = {2016}
}
@article{Faraji2017,
  abstract        = {Multi-GPU nodes have become the platform of choice for scientific applications. In a multi-GPU node, GPUs are interconnected together via different communication channels. The intranode communications among GPUs may traverse different paths with different latency and bandwidth characteristics. As the number of GPUs within a multi-GPU node increases, the physical topology of the GPU interconnects tend to have more levels of hierarchy, which in turn increases the heterogeneity of the GPU communication channels.In this paper, we show that the performance of different intranode GPU communication channels can be considerably different from each other. Accordingly, we propose a topology-aware GPU selection scheme for efficient assignment of GPUs to the MPI processes within a node. The resulting assignment helps to improve the communication performance by mapping more intensive inter-process GPU-to-GPU communications on the stronger communication channels. We leverage three metrics in our scheme to distinguish among different GPU-to-GPU communication channels: latency, bandwidth, and distance. We evaluate our scheme through extensive experiments conducted on a 16-GPU node, and show that our scheme can provide considerable performance improvements over the default GPU selection scheme. In particular, we can achieve up to 70{\%} and 21{\%} performance improvement at the microbenchmark and application level, respectively.},
  author          = {Faraji, Iman and Mirsadeghi, Seyed Hessam and Afsahi, Ahmad},
  doi             = {10.1016/j.parco.2017.07.001},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Parallel Computing/Exploiting heterogeneity of communication channels for efficient GPU selection on multi-GPU nodes - Faraji, Mirsadeghi, Afsahi - Paralle.pdf:pdf},
  issn            = {01678191},
  journal         = {Parallel Computing},
  keywords        = {GPU,MPI,Mapping,Multi-GPU node,Multi{\_}GPU,Topology-aware GPU Selection,Topology{\_}Aware},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,MPI,Multi{\_}GPU,Topology{\_}Aware},
  pages           = {3--16},
  publisher       = {Elsevier B.V.},
  title           = {{Exploiting heterogeneity of communication channels for efficient GPU selection on multi-GPU nodes}},
  volume          = {68},
  year            = {2017}
}
@inproceedings{Feng2022,
  abstract        = {The Message Passing Interface (MPI) is the most prominent and dominant programming model for scientific computing in super-computing systems today. Although many general and efficient algorithms have been proposed for MPI collective operations, there is still room for topology-aware optimization. Dragonfly is a high-scalability, low-diameter, and cost-efficient network topology adopted in more and more supercomputing networks. However, Dragonfly topology limits the performance of some MPI collective operations. In this paper, our analysis shows that the bottlenecks of collective algorithms in Dragonfly topology are intra-job interference, inter-job interference, and topology mismatch. We propose 5 different optimizations, i.e., Pseudo-random Pairwise, Tree-based Shuffle, Reversed Recursive Doubling, Reordered Bruck, and Matched Rabenseifner, for MPI collective operations including All-Gather, All-to-All, All-Reduce, and Reduce-Scatter. We evaluate each optimization through CODES network simulation framework with minimal, non-minimal, and adaptive routing. The simulation results demonstrate that the performance of All-to-All, All-Gather, All-Reduce, and Reduce-Scatter can be improved by 4.7X, 3.4X, 12.7{\%}, and 4.1X, respectively, for 32768-node jobs with adaptive routing.},
  author          = {Feng, Guangnan and Dong, Dezun and Lu, Yutong},
  booktitle       = {Proceedings of the International Conference on Supercomputing (ICS)},
  doi             = {10.1145/3524059.3532380},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the International Conference on Supercomputing (ICS)/Optimized MPI collective algorithms for dragonfly topology - Feng, Dong, Lu - Proceedings of the International Conference on Supercompu.pdf:pdf},
  isbn            = {9781450392815},
  keywords        = {Collective,Collectives,Dragonfly,MPI},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,MPI},
  pages           = {1--11},
  publisher       = {Association for Computing Machinery},
  title           = {{Optimized MPI collective algorithms for dragonfly topology}},
  year            = {2022}
}
@article{Ferreira2020,
  abstract        = {This paper explores key differences of MPI match lists for several important United States Department of Energy (DOE) applications and proxy applications. This understanding is critical in determining the most promising hardware matching design for any given high-speed network. The results of MPI match list studies for the major open-source MPI implementations, MPICH and Open MPI, are presented, and we modify an MPI simulator, LogGOPSim, to provide match list statistics. These results are discussed in the context of several different potential design approaches to MPI matching–capable hardware. The data illustrate the requirements for different hardware designs in terms of performance and memory capacity. This paper's contributions are the collection and analysis of data to help inform hardware designers of common MPI requirements and highlight the difficulties in determining these requirements by only examining a single MPI implementation.},
  author          = {Ferreira, Kurt and Grant, Ryan E. and Levenhagen, Michael J. and Levy, Scott and Groves, Taylor},
  doi             = {10.1002/cpe.5150},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Concurrency and Computation Practice and Experience (CCPE)/Hardware MPI message matching Insights into MPI matching behavior to inform design - Ferreira et al. - Concurrency and Computation Pract.pdf:pdf},
  issn            = {15320634},
  journal         = {Concurrency and Computation: Practice and Experience (CCPE)},
  keywords        = {MPI,MPI matching,Message{\_}Matching,hardware matching},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Message{\_}Matching},
  number          = {3},
  pages           = {1--18},
  title           = {{Hardware MPI message matching: Insights into MPI matching behavior to inform design}},
  volume          = {32},
  year            = {2020}
}
@article{Firestone2018,
  abstract        = {Modern cloud architectures rely on each server running its own networking stack to implement policies such as tunneling for virtual networks, security, and load balancing. However, these networking stacks are becoming increasingly complex as features are added and as network speeds increase. Running these stacks on CPU cores takes away processing power from VMs, increasing the cost of running cloud services, and adding latency and variability to network performance. We present Azure Accelerated Networking (AccelNet), our solution for offloading host networking to hardware, using custom Azure SmartNICs based on FPGAs. We define the goals of AccelNet, including programmability comparable to software, and performance and efficiency comparable to hardware. We show that FPGAs are the best current platform for offloading our networking stack as ASICs do not provide sufficient programmability, and embedded CPU cores do not provide scalable performance, especially on single network flows. Azure SmartNICs implementing AccelNet have been deployed on all new Azure servers since late 2015 in a fleet of {\textgreater}1M hosts. The AccelNet service has been available for Azure customers since 2016, providing consistent {\textless}15µs VM-VM TCP latencies and 32Gbps throughput, which we believe represents the fastest network available to customers in the public cloud. We present the design of AccelNet, including our hardware/software co-design model, performance results on key workloads, and experiences and lessons learned from developing and deploying AccelNet on FPGA-based Azure SmartNICs.},
  author          = {Firestone, Daniel and Putnam, Andrew and Mundkur, Sambhrama and Chiou, Derek and Dabagh, Alireza and Andrewartha, Mike and Angepat, Hari and Bhanu, Vivek and Caulfield, Adrian and Chung, Eric and Chandrappa, Harish Kumar and Chaturmohta, Somesh and Humphrey, Matt and Lavier, Jack and Lam, Norman and Liu, Fengfen and Ovtcharov, Kalin and Padhye, Jitu and Popuri, Gautham and Raindel, Shachar and Sapre, Tejas and Shaw, Mark and Silva, Gabriel and Sivakumar, Madhan and Srivastava, Nisheeth and Verma, Anshuman and Zuhair, Qasim and Bansal, Deepak and Burger, Doug and Vaid, Kushagra and Maltz, David A. and Greenberg, Albert},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the 15th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2018/Azure accelerated networking Smartnics in the public cloud - Firestone et al. - Proceedings of the 15th.pdf:pdf},
  isbn            = {9781939133014},
  journal         = {Proceedings of the 15th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2018},
  mendeley-groups = {ELEC-878},
  pages           = {51--64},
  title           = {{Azure accelerated networking: Smartnics in the public cloud}},
  year            = {2018}
}
@misc{Fischer2020,
  abstract      = {A fast and scalable high-order solver for computational fluid dynamics},
  author        = {Fischer, F and Kruse, J and Mullen, J},
  keywords      = {Library,MPI,Web},
  mendeley-tags = {Library,MPI,Web},
  title         = {{Nek5000}},
  url           = {https://nek5000.mcs.anl.gov/},
  urldate       = {2020-07-13},
  year          = {2020}
}
@inproceedings{Flajslik2016,
  author          = {Flajslik, Mario and Dinan, James and Underwood, Keith D.},
  booktitle       = {Proceedings of the IEEE International Conference on High Performance Computing (HiPC)},
  doi             = {10.1007/978-3-319-41321-1_15},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the IEEE International Conference on High Performance Computing (HiPC)/Mitigating MPI Message Matching Misery - Flajslik, Dinan, Underwood - Proceedings of the IEEE International Conferenc.pdf:pdf},
  keywords        = {Message{\_}Matching,Multithreaded{\_}MPI},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {Message{\_}Matching,Multithreaded{\_}MPI},
  pages           = {281--299},
  title           = {{Mitigating MPI Message Matching Misery}},
  year            = {2016}
}
@inproceedings{Friedley2013,
  abstract        = {Multi-core shared memory architectures are ubiquitous in both High-Performance Computing (HPC) and commodity systems because they provide an excellent trade-off between performance and programmability. MPI's abstraction of explicit communication across distributed memory is very popular for programming scientific applications. Unfortunately, OS-level process separations force MPI to perform unnecessary copying of messages within shared memory nodes. This paper presents a novel approach that transparently shares memory across MPI processes executing on the same node, allowing them to communicate like threaded applications. While prior work explored thread-based MPI libraries, we demonstrate that this approach is impractical and performs poorly in practice. We instead propose a novel process-based approach that enables shared memory communication and integrates with existing MPI libraries and applications without modifications. Our protocols for shared memory message passing exhibit better performance and reduced cache footprint. Communication speedups of more than 26{\%} are demonstrated for two applications. Copyright 2013 ACM.},
  author          = {Friedley, Andrew and Bronevetsky, Greg and Hoefler, Torsten and Lumsdaine, Andrew},
  booktitle       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi             = {10.1145/2503210.2503294},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2013/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Hybrid MPI Efficient message passing for multi-core systems - Friedley et al. - Proceedin.pdf:pdf},
  isbn            = {9781450323789},
  issn            = {21674337},
  keywords        = {Hybrid{\_}MPI,MPI,Message{\_}Matching,Multithreaded{\_}MPI,Shared{\_}Memory},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Hybrid{\_}MPI,MPI,Message{\_}Matching,Multithreaded{\_}MPI,Shared{\_}Memory},
  pages           = {1--11},
  title           = {{Hybrid MPI: Efficient message passing for multi-core systems}},
  year            = {2013}
}
@techreport{From1802,
  author          = {From, I T H Contributions and At, Others},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Unknown/High-Performance Communication in Machine Learning APP aCE - From, At - Unknown.pdf:pdf},
  keywords        = {Machine{\_}Learning},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {Machine{\_}Learning},
  title           = {{High-Performance Communication in Machine Learning APP / aCE}},
  year            = {2019}
}
@article{Fujita2019,
  abstract      = {The Message Passing Interface (MPI) standard supports Remote Memory Access (RMA) operations, where a process can read or write memory of another process without requiring the target process to be involved in the communication. This enables new more efficient programming models. This paper describes the RMA design and implementation in MPICH-OFI, an MPICH-based open source implementation of the MPI standard that uses the OpenFabrics Interfaces* (OFI*) to communicate with the underlying network fabric. MPICH-OFI is based on a new communication layer called CH4, which was designed to achieve high performance by minimizing the runtime software overhead and by having an internal API that is well aligned with MPI functions. MPICH-OFI uses the OpenFabrics Interfaces (OFI), a lightweight communication framework to support modern high-speed interconnects. Thanks to CH4 and OFI, MPICH-OFI achieves low latency and high bandwidth for RMA operations. Our experimental results using microbenchmarks show that MPICH-OFI achieves more than 3x better put/get latency and bandwidth than MPICH CH3, 10{\%} better latency than Open MPI and MVAPICH2, and more than 1.7x bandwidth than MVAPICH2 for small messages ( ≤ 4KB), on Intel{\textregistered} Omni-Path Architecture.},
  author        = {Fujita, Hajime and Cao, Chongxiao and Sur, Sayantan and Archer, Charles and Paulson, Erik and Garzaran, Maria},
  doi           = {10.1016/j.parco.2019.04.008},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Parallel Computing/Efficient implementation of MPI-3 RMA over openFabrics interfaces - Fujita et al. - Parallel Computing.pdf:pdf},
  issn          = {01678191},
  journal       = {Parallel Computing},
  keywords      = {MPI,MPICH-OFI,Message Passing Interface,One-sided Communications,OpenFabrics Intefaces (OFI),RMA,Remote Memory Access (RMA)},
  mendeley-tags = {MPI,RMA},
  pages         = {1--10},
  publisher     = {Elsevier B.V.},
  title         = {{Efficient implementation of MPI-3 RMA over openFabrics interfaces}},
  volume        = {87},
  year          = {2019}
}
@inproceedings{Fukuoka2019,
  abstract      = {In the era of multi-/many-core processors, there are increasing needs for middleware of high-performance computing to exploit both inter-node and intra-node parallelism. To overlap communication and computation efficiently, many studies have focused on MPI+ULT, a combination of MPI for inter-node parallelism and user-level threads (ULTs) for intra-node parallelism. However, there are mainly two problems in the existing MPI+ULT implementations. First, the use of MPI-THREAD-MULTIPLE to invoke MPI functions from multiple threads causes a performance bottleneck. Second, some MPI+ULT systems focus on the use of non-blocking communication and programmers have to manage both the start and the end of communication explicitly. To solve these problems, we introduce a high-performance MPI+ULT implementation MPI+myth. MPI+myth focuses on implicit overlapping of communication and computation without any code modifications to the applications. Furthermore, it can avoid the overhead of multi-threaded MPI invocations using a communication dedicated thread and adopts a new scheduling technique which achieves efficient load balancing by avoiding a situation that a core is occupied by blocking ULTs. In the evaluation, we demonstrate significant performance improvement compared with the existing hybrid programming methods using several microbenchmarks and one mini application miniFE. In addition, we illustrate that MPI+myth has the potential to overlap communication and computation and our new ULT scheduling technique can achieve load balancing more efficiently than existing ULT scheduling techniques.},
  author        = {Fukuoka, Takuya and Endo, Wataru and Taura, Kenjiro},
  booktitle     = {Proceedings of the IEEE International Conference on High Performance Computing and Communications (HPCC)},
  doi           = {10.1109/HPCC/SmartCity/DSS.2019.00103},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the IEEE International Conference on High Performance Computing and Communications (HPCC)/An efficient inter-node communication system with lightweight-thread scheduling - Fukuoka, Endo, T.pdf:pdf},
  isbn          = {9781728120584},
  keywords      = {Inter{\_}node,MPI,Multithreaded{\_}MPI,implicit load balancing,overlap,thread scheduling,user-level thread},
  mendeley-tags = {Inter{\_}node,MPI,Multithreaded{\_}MPI},
  pages         = {687--696},
  title         = {{An efficient inter-node communication system with lightweight-thread scheduling}},
  year          = {2019}
}
@inproceedings{Gahvari2015,
  abstract      = {Hybrid MPI + OpenMP is a popular means of programming modern machines that feature substantial parallelism both off-node and on-node. Determining the right mix of the two programming models to use, however, is not as straightforward as simply using exclusively OpenMP on-node and limiting MPI to only inter-node communication. We present a step-by-step methodology to help make the decision of which mix of the two programming models to use. It starts with an estimate of the performance of a generic hybrid application on a given machine and incorporates additional available information about the specific application and the machine to provide guidance for selecting effective mixes of MPI processes and OpenMP threads to use when running that application on the machine in question. We validate our approach on four different applications on an IBM Blue Gene/Q, a Cray XK7, and a Cray XC30.},
  author        = {Gahvari, Hormozd and Schulz, Martin and Yang, Ulrike Meier},
  booktitle     = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi           = {10.1109/CLUSTER.2015.64},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/An approach to selecting thread process mixes for hybrid MPI OpenMP applications - Gahvari, Schulz, Yang - Proceedings of.pdf:pdf},
  isbn          = {9781467365987},
  issn          = {15525244},
  keywords      = {Bandwidth,Benchmark testing,Hybrid{\_}MPI,Instruction sets,Message systems,Multithreaded{\_}MPI,OpenMP,Parallel processing,Programming,Runtime},
  mendeley-tags = {Hybrid{\_}MPI,Multithreaded{\_}MPI,OpenMP},
  pages         = {418--427},
  publisher     = {IEEE},
  title         = {{An approach to selecting thread + process mixes for hybrid MPI + OpenMP applications}},
  volume        = {2015-Octob},
  year          = {2015}
}
@inproceedings{Gainaru2016,
  abstract      = {The MPI all-to-all algorithm is a data intensive, high-cost collective algorithm used by many scientific High Performance Computing applications. Optimizations for small data exchange use aggregation techniques, such as the Bruck algorithm, to minimize the number of messages sent, and minimize overall operation latency. This paper presents three variants of the Bruck algorithm, which differ in the way data is laid out in memory at intermediate steps of the algorithm. Mellanox's InfiniBand support for Host Channel Adapter (HCA) hardware scatter/gather is used selectively to replace CPU-based buffer packing and unpacking. Using this offload capability reduces the eight and sixteen byte all-to-all latency on 1024 MPI Processes by 9.7{\%} and 9.1{\%}, respectively. The optimization accounts for a decrease in the total memory handling time of 40.6{\%} and 57.9{\%}, respectively.},
  author        = {Gainaru, Ana and Graham, Richard L. and Polyakov, Artem and Shainer, Gilad},
  booktitle     = {Proceedings of the European MPI Users' Group Meeting (EuroMPI)},
  doi           = {10.1145/2966884.2966918},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the European MPI Users' Group Meeting (EuroMPI)/Using infiniband hardware gather-scatter capabilities to optimize MPI all-to-all - Gainaru et al. - Proceedings of the European MPI User.pdf:pdf},
  isbn          = {9781450342346},
  keywords      = {All-to-all,All{\_}to{\_}All,Collective communication,Collectives,MPI,Network offload,Offloading},
  mendeley-tags = {All{\_}to{\_}All,Collectives,MPI,Offloading},
  pages         = {167--179},
  title         = {{Using infiniband hardware gather-scatter capabilities to optimize MPI all-to-all}},
  volume        = {25-28-Sept},
  year          = {2016}
}
@article{Gan2021,
  abstract      = {Recent years have witnessed a growing list of systems for distributed data-parallel training. Existing systems largely fit into two paradigms, i.e., parameter server and MPI-style collective operations. On the algorithmic side, researchers have proposed a wide range of techniques to lower the communication via "system relaxations": quantization, decentralization, and communication delay. However, most, if not all, existing systems only rely on standard synchronous and asynchronous stochastic gradient (SG) based optimization, therefore, cannot take advantage of all possible optimizations that the machine learning community has been developing recently. Given this emerging gap between the current landscapes of systems and theory, we build Bagua, a MPI-style communication library, providing a collection of primitives, that is both flexible and modular to support state-of-the-art system relaxation techniques of distributed training. Powered by this design, Bagua has a great ability to implement and extend various state-of-the-art distributed learning algorithms. In a production cluster with up to 16 machines (128 GPUs), Bagua can outperform PyTorch-DDP, Horovod and BytePS in the end-to-end training time by a significant margin (up to 2X) across a diverse range of tasks. Moreover, we conduct a rigorous tradeoff exploration showing that different algorithms and system relaxations achieve the best performance over different network conditions.},
  author        = {Gan, Shaoduo and Jiang, Jiawei and Yuan, Binhang and Zhang, Ce and Lian, Xiangru and Wang, Rui and Chang, Jianbin and Liu, Chengjun and Shi, Hongmei and Zhang, Shengzhuo and Li, Xianghong and Sun, Tengxu and Yang, Sen and Liu, Ji},
  doi           = {10.14778/3503585.3503590},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the VLDB Endowment/Bagua scaling up distributed learning with system relaxations - Gan et al. - Proceedings of the VLDB Endowment.pdf:pdf},
  issn          = {2150-8097},
  journal       = {Proceedings of the VLDB Endowment},
  keywords      = {Deep{\_}Learning,MPI},
  mendeley-tags = {Deep{\_}Learning,MPI},
  pages         = {804--813},
  title         = {{Bagua: scaling up distributed learning with system relaxations}},
  year          = {2021}
}
@inproceedings{Ganapathi2017,
  abstract      = {High Performance Computing(HPC) applications are highly optimized to maximize allocated resources for the job such as compute resources, memory and storage. Optimal performance for MPI applications requires the best possible affinity across all the allocated resources. Typically, setting process affinity to compute resources is well defined, i.e MPI processes on a compute node have processor affinity set for one to one mapping between MPI processes and the physical processing cores. Several well defined methods exist to efficiently map MPI processes to a compute node. With the growing complexity of HPC systems, platforms are designed with complex compute and I/O subsystems. Capacity of I/O devices attached to a node are expanded with PCIe switches resulting in large numbers of PCIe endpoint devices. With a lot of heterogeneity in systems, applications programmers are forced to think harder about affinitizing processesas it affects performance based on not only compute but also NUMA placement of IO devices. Mapping of process to processor cores and the closest IO device(s) is not straightforward. While operating systems do a reasonable job of trying to keep a process physically located near the processor core(s) and memory, they lack the application developer's knowledge of process workflow and optimal IO resource allocation when more than one IO device is connected to the compute node.In this paper we look at ways to assuage the problems of affinity choices by abstracting the device selection algorithm from MPI application layer. MPI continues to be the dominant programming model for HPC and hence our focus in this paper is limited to providing a solution for MPI based applications. Our solution can be extended to other HPC programming modelssuch as Partitioned Global Address Space(PGAS) or a hybrid MPI and PGAS based applications. We propose a solution to solve NUMA effects at the MPI runtime level independent of MPI applications. Our experiments are conducted on a two node system where each node consists of two socket Intel{\textregistered} Xeon{\textregistered} servers, attached with up to four Intel{\textregistered} Omni-Path fabric devices connected over PCIe. The performance benefits seen by MPI applications by affinitizing MPI processes with best possible network device is evident from the results where we notice up to 40{\%} improvement in uni-directional bandwidth, 48{\%} bi-directional bandwidth, 32{\%} improvement in latency measurements and finally up to 40{\%} improvement in message rate.},
  author        = {Ganapathi, Ravindra Babu and Gopalakrishnan, Aravind and McGuire, Russell W.},
  booktitle     = {Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)},
  doi           = {10.1109/HOTI.2017.12},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)/MPI process and network device affinitization for optimal HPC application performance - Ganapathi, Gopalakrishnan, McGuire - Pro.pdf:pdf},
  isbn          = {9781538610138},
  keywords      = {Affinity,Fabric,High Performance Computing,InfiniBand,Infiniband,Intel Omni-Path,Intel{\_}Omni{\_}Path,MPI,NUMA,Performance,Process affinity,Topology,Topology{\_}Aware},
  mendeley-tags = {Affinity,InfiniBand,Intel{\_}Omni{\_}Path,NUMA,Topology{\_}Aware},
  pages         = {80--86},
  title         = {{MPI process and network device affinitization for optimal HPC application performance}},
  year          = {2017}
}
@inproceedings{Gerstenberger2014,
  abstract      = {Modern interconnects offer remote direct memory access (RDMA) features. Yet, most applications rely on explicit message passing for communications albeit their unwanted overheads. The MPI-3.0 standard defines a programming interface for exploiting RDMA networks directly, however, it's scalability and practicability has to be demonstrated in practice. In this work, we develop scalable bufferless protocols that implement the MPI-3.0 specification. Our protocols support scaling to millions of cores with negligible memory consumption while providing highest performance and minimal overheads. To arm programmers, we provide a spectrum of performance models for all critical functions and demonstrate the usability of our library and models with several application studies with up to half a million processes. We show that our design is comparable to, or better than UPC and Fortran Coarrays in terms of latency, bandwidth and message rate. We also demonstrate application performance improvements with comparable programming complexity.},
  author        = {Gerstenberger, Robert and Besta, Maciej and Hoefler, Torsten},
  booktitle     = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi           = {10.1155/2014/571902},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Enabling Highly-Scalable Remote Memory Access Programming with MPI-3 One Sided - Gerstenb.pdf:pdf},
  issn          = {1058-9244},
  keywords      = {MPI,RMA},
  mendeley-tags = {MPI,RMA},
  number        = {2},
  pages         = {75--91},
  title         = {{Enabling Highly-Scalable Remote Memory Access Programming with MPI-3 One Sided}},
  volume        = {22},
  year          = {2014}
}
@phdthesis{Ghazimirsaeed2019,
  author          = {Ghazimirsaeed, S. Mahdieh},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Unknown/High-performance Communication in MPI through Message Matching and Neighborhood Collective Design - Ghazimirsaeed - Unknown.pdf:pdf},
  keywords        = {MPI,Message{\_}Matching,Neighborhood{\_}Collectives,Thesis},
  mendeley-groups = {ByPPRL,Theses},
  mendeley-tags   = {MPI,Message{\_}Matching,Neighborhood{\_}Collectives,Thesis},
  number          = {March},
  pages           = {1--213},
  school          = {Queen's University},
  title           = {{High-performance Communication in MPI through Message Matching and Neighborhood Collective Design}},
  year            = {2019}
}
@inproceedings{Ghazimirsaeed2017,
  author          = {Ghazimirsaeed, S. Mahdieh and Afsahi, Ahmad},
  booktitle       = {High Performance Computing Symposium (HPCS)},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/High Performance Computing Symposium (HPCS)/Accelerating MPI Message Matching by a Data Clustering Strategy - Ghazimirsaeed, Afsahi - High Performance Computing Symposium (HPCS).pdf:pdf},
  keywords        = {MPI,Message{\_}Matching,hpc,message matching,message queues,mpi},
  mendeley-groups = {ByPPRL},
  mendeley-tags   = {MPI,Message{\_}Matching},
  pages           = {1--22},
  title           = {{Accelerating MPI Message Matching by a Data Clustering Strategy}},
  year            = {2017}
}
@inproceedings{Ghazimirsaeed2018,
  abstract        = {The Message Passing Interface (MPI) libraries use message queues to guarantee correct message ordering between communicating processes. Message queues are in the critical path of MPI communications and thus, the performance of message queue operations can have significant impact on the performance of applications. Collective communications are widely used in MPI applications and they can have considerable impact on generating long message queues. In this paper, we propose a message matching mechanism that improves the message queue search time by distinguishing messages coming from point-to-point and collective communications and allocating separate queues for them. Moreover, it dynamically profiles the impact of each collective call on message queues during the application runtime and uses this information to adapt the message queue data structure for each collective operation dynamically. The proposed approach can successfully reduce the queue search time while maintaining scalable memory consumption. The evaluation results show that we can obtain up to 5.5x runtime speedup for applications with long list traversals. Moreover, we can gain up to 15{\%} and 45{\%} queue search time improvement for applications with short and medium list traversals, respectively.},
  author          = {Ghazimirsaeed, S. Mahdieh and Grant, Ryan E. and Afsahi, Ahmad},
  booktitle       = {Proceedings of the International Conference on Parallel Processing Companion (ICPP Comp)},
  doi             = {10.1145/3229710.3229712},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the International Conference on Parallel Processing Companion (ICPP Comp)/A Dedicated Message Matching Mechanism for Collective Communications - Ghazimirsaeed, Grant, Afsahi - Proceedings.pdf:pdf},
  isbn            = {9781450365239},
  keywords        = {Collective communications,Collectives,MPI,Message matching,Message queue,Message{\_}Matching},
  mendeley-groups = {ByPPRL},
  mendeley-tags   = {Collectives,MPI,Message{\_}Matching},
  pages           = {1--10},
  title           = {{A Dedicated Message Matching Mechanism for Collective Communications}},
  year            = {2018}
}
@article{Ghazimirsaeed2019a,
  abstract        = {The Message Passing Interface (MPI) libraries use message queues to guarantee correct message ordering between communicating processes. Message queues are in the critical path of MPI communications and thus, the performance of message queue operations can have significant impact on the performance of applications. Collective communications are widely used in MPI applications and they can have considerable impact on generating long message queues. In this paper, we propose a unified message matching mechanism that improves the message queue search time by distinguishing messages coming from point-to-point and collective communications and using a distinct message queue data structure for them. For collective operations, it dynamically profiles the impact of each collective call on message queues during the application runtime and uses this information to adapt the message queue data structure for each collective dynamically. Moreover, we use a partner/non-partner message queue data structure for the messages coming from point-to-point communications. The proposed approach can successfully reduce the queue search time while maintaining scalable memory consumption. The evaluation results show that we can obtain up to 5.5x runtime speedup for applications with long list traversals. Moreover, we can gain up to 15{\%} and 94{\%} queue search time improvement for all elements in applications with short and medium list traversals, respectively.},
  author          = {Ghazimirsaeed, S. Mahdieh and Grant, Ryan E. and Afsahi, Ahmad},
  doi             = {10.1016/j.parco.2019.102547},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Parallel Computing/A dynamic, unified design for dedicated message matching engines for collective and point-to-point communications - Ghazimirsaeed, Grant.pdf:pdf},
  issn            = {01678191},
  journal         = {Parallel Computing},
  keywords        = {Collective communications,Collectives,MPI,Message matching,Message queue,Message{\_}Matching,P2P,Point-to-point communications},
  mendeley-groups = {ByPPRL},
  mendeley-tags   = {Collectives,MPI,Message{\_}Matching,P2P},
  pages           = {1--15},
  title           = {{A dynamic, unified design for dedicated message matching engines for collective and point-to-point communications}},
  year            = {2019}
}
@inproceedings{Ghazimirsaeed2019b,
  abstract        = {Neighborhood collectives are introduced in MPI-3.0 standard to provide users with the opportunity to define their own communication patterns through the process topology interface of MPI. In this paper, we propose a collaborative communication mechanism based on common neighborhoods that might exist among groups of k processes. Such common neighborhoods are used to decrease the number of communication stages through message combining. We show how designing our desired communication pattern can be modeled as a maximum weighted matching problem in distributed hypergraphs, and propose a distributed algorithm to solve it. Moreover, we consider two design alternatives: topology-agnostic and topology-aware. The former ignores the physical topology of the system and the mapping of processes, whereas the latter takes them into account to further optimize the communication pattern. Our experimental results show that we can gain up to 8x and 5.2x improvement for various process topologies and a SpMM kernel, respectively.},
  author          = {Ghazimirsaeed, S. Mahdieh and Mirsadeghi, Seyed H. and Afsahi, Ahmad},
  booktitle       = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi             = {10.1109/IPDPS.2019.00087},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/An efficient collaborative communication mechanism for MPI neighborhood collectives - Ghazimirsaeed, Mirsadeghi.pdf:pdf},
  isbn            = {9781728112466},
  keywords        = {MPI,Neighborhood collective,Neighborhood{\_}Collectives,Topology,Topology{\_}Aware},
  mendeley-groups = {ByPPRL},
  mendeley-tags   = {MPI,Neighborhood{\_}Collectives,Topology{\_}Aware},
  pages           = {781--792},
  title           = {{An efficient collaborative communication mechanism for MPI neighborhood collectives}},
  year            = {2019}
}
@article{Ghazimirsaeed2018a,
  abstract        = {The Message Passing Interface (MPI) is the de facto standard for parallel programming in High Performance Computing (HPC). Asynchronous communications in MPI involve message matching semantics that must be satisfied by the conforming libraries. The matching performance is in the critical path of communications in MPI. However, the current message matching approaches suffer from scalability issues and/or do not consider the message queue characteristics of the applications. In this paper, we propose a new message matching mechanism for MPI that can speed up the operation by allocating dedicated queues for certain communications of an application. More specifically, we propose a design that categorizes communications into a set of partners and non-partners based on the communication frequency in the corresponding queues. We propose a static and a dynamic approach for our message matching design. While the static approach works based on the information from a profiling stage, the dynamic approach utilizes the message queue characteristics at runtime. Our experimental evaluations show that the proposed design can provide up to 28x speedup in queue search time for long list traversals without degrading the performance for short list traversals. We can also gain up to 5x speedup for the FDS application, which is highly affected by the message matching performance.},
  author          = {Ghazimirsaeed, S. Mahdieh and Mirsadeghi, Seyed Hessam and Afsahi, Ahmad},
  doi             = {10.1002/cpe.4862},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Concurrency and Computation Practice and Experience (CCPE)/Communication-aware message matching in MPI - Ghazimirsaeed, Mirsadeghi, Afsahi - Concurrency and Computation Practice and Experience (C.pdf:pdf},
  issn            = {15320634},
  journal         = {Concurrency and Computation: Practice and Experience (CCPE)},
  keywords        = {MPI,Message{\_}Matching,message matching,message queue,partner/non-partner queues},
  mendeley-groups = {UsedInComp1,ByPPRL},
  mendeley-tags   = {MPI,Message{\_}Matching},
  pages           = {1--17},
  title           = {{Communication-aware message matching in MPI}},
  year            = {2018}
}
@article{Goh2022,
  abstract        = {Machine learning and deep learning models are commonly developed using programming languages such as Python, C++, or R and deployed as web apps delivered from a back-end server or as mobile apps installed from an app store. However, recently front-end technologies and JavaScript libraries, such as TensorFlow.js, have been introduced to make machine learning more accessible to researchers and end-users. Using JavaScript, TensorFlow.js can define, train, and run new or existing, pre-trained machine learning models entirely in the browser from the client-side, which improves the user experience through interaction while preserving privacy. Deep learning models deployed on front-end browsers must be small, have fast inference, and ideally be interactive in real-time. Therefore, the emphasis on development and deployment is different. This paper aims to review the development and deployment of these deep-learning web apps to raise awareness of the recent advancements and encourage more researchers to take advantage of this technology for their own work. First, the rationale behind the deployment stack (front-end, JavaScript, and TensorFlow.js) is discussed. Then, the development approach for obtaining deep learning models that are optimized and suitable for front-end deployment is then described. The article also provides current web applications divided into seven categories to show deep learning potential on the front end. These include web apps for deep learning playground, pose detection and gesture tracking, music and art creation, expression detection and facial recognition, video segmentation, image and signal analysis, healthcare diagnosis, recognition, and identification.},
  author          = {Goh, Hock Ann and Ho, Chin Kuan and Abas, Fazly Salleh},
  doi             = {10.1007/s10489-022-04278-6},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Applied Intelligence/Front-end deep learning web apps development and deployment a review - Goh, Ho, Abas - Applied Intelligence.pdf:pdf},
  issn            = {15737497},
  journal         = {Applied Intelligence},
  keywords        = {Browser-based deep learning,Client-side deep learning,Deep learning web apps,Front-end deep learning,TensorFlow.js},
  mendeley-groups = {Web},
  publisher       = {Springer},
  title           = {{Front-end deep learning web apps development and deployment: a review}},
  year            = {2022}
}
@inproceedings{Gonthier2022,
  author        = {Gonthier, Maxime and Marchal, Loris and Thibault, Samuel},
  booktitle     = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/Memory-Aware Scheduling of Tasks Sharing Data on Multiple GPUs with Dynamic Runtime Systems - Gonthier, Marchal.pdf:pdf},
  keywords      = {GPU,Multi{\_}GPU,Scheduling},
  mendeley-tags = {GPU,Multi{\_}GPU,Scheduling},
  pages         = {1--11},
  title         = {{Memory-Aware Scheduling of Tasks Sharing Data on Multiple GPUs with Dynamic Runtime Systems}},
  url           = {https://hal.inria.fr/hal-03552243/document},
  year          = {2022}
}
@article{Grady2022,
  abstract      = {Fourier neural operators (FNOs) are a recently introduced neural network architecture for learning solution operators of partial differential equations (PDEs), which have been shown to perform significantly better than comparable approaches based on convolutional networks. Once trained, FNOs can achieve speed-ups of multiple orders of magnitude over conventional numerical PDE solvers. However, due to the high dimensionality of their input data and network weights, FNOs have so far only been applied to two-dimensional or small three-dimensional problems. To remove this limited problem-size barrier, we propose a model-parallel version of FNOs based on domain-decomposition of both the input data and network weights. We demonstrate that our model-parallel FNO is able to predict time-varying PDE solutions of over 3.2 billions variables on Summit using up to 768 GPUs and show an example of training a distributed FNO on the Azure cloud for simulating multiphase CO{\$}{\_}2{\$} dynamics in the Earth's subsurface.},
  archiveprefix = {arXiv},
  arxivid       = {2204.01205},
  author        = {Grady, Thomas J. and Khan, Rishi and Louboutin, Mathias and Yin, Ziyi and Witte, Philipp A. and Chandra, Ranveer and Hewett, Russell J. and Herrmann, Felix J.},
  eprint        = {2204.01205},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/arXiv/Towards Large-Scale Learned Solvers for Parametric PDEs with Model-Parallel Fourier Neural Operators - Grady et al. - arXiv.pdf:pdf},
  journal       = {arXiv},
  keywords      = {Deep{\_}Learning},
  mendeley-tags = {Deep{\_}Learning},
  number        = {1},
  pages         = {1--10},
  title         = {{Towards Large-Scale Learned Solvers for Parametric PDEs with Model-Parallel Fourier Neural Operators}},
  year          = {2022}
}
@inproceedings{Graham2017,
  abstract      = {Increased system size and a greater reliance on utilizing system parallelism to achieve computational needs, requires innovative system architectures to meet the simulation challenges. As a step towards a new network class of co-processors-intelligent network devices, which manipulate data traversing the data-center network, this paper describes the SHArP technology designed to offload collective operation processing to the network. This is implemented in Mellanox's SwitchIB-2 ASIC, using innetwork trees to reduce data from a group of sources, and to distribute the result. Multiple parallel jobs with several partially overlapping groups are supported each with several reduction operations in-flight. Large performance enhancements are obtained, with an improvement of a factor of 2.1 for an eight byte MPI-Allreduce() operation on 128 hosts, going from 6.01 to 2.83 microseconds. Pipelining is used for an improvement of a factor of 3.24 in the latency of a 4096 byte MPI-Allreduce() operations, declining from 46.93 to 14.48 microseconds.},
  author        = {Graham, Richard L. and Bureddy, Devendar and Lui, Pak and Rosenstock, Hal and Shainer, Gilad and Bloch, Gil and Goldenerg, Dror and Dubman, Mike and Kotchubievsky, Sasha and Koushnir, Vladimir and Levi, Lion and Margolin, Alex and Ronen, Tamir and Shpiner, Alexander and Wertheim, Oded and Zahavi, Eitan},
  booktitle     = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi           = {10.1109/COMHPC.2016.006},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Scalable Hierarchical Aggregation Protocol (SHArP) A Hardware Architecture for Efficient.pdf:pdf},
  keywords      = {Network},
  mendeley-tags = {Network},
  pages         = {1--10},
  publisher     = {IEEE},
  title         = {{Scalable Hierarchical Aggregation Protocol (SHArP): A Hardware Architecture for Efficient Data Reduction}},
  year          = {2017}
}
@inproceedings{Graham2008,
  abstract      = {With local core counts on the rise, taking advantage of shared-memory to optimize collective operations can improve performance. We study several on-host shared memory optimized algorithms for MPI{\_}Bcast, MPI{\_}Reduce, and MPI{\_}Allreduce, using tree-based, and reduce-scatter algorithms. For small data operations with relatively large synchronization costs fan-in/fan-out algorithms generally perform best. For large messages data manipulation constitute the largest cost and reduce-scatter algorithms are best for reductions. These optimization improve performance by up to a factor of three. Memory and cache sharing effect require deliberate process layout and careful radix selection for tree-based methods. {\textcopyright} 2008 Springer-Verlag Berlin Heidelberg.},
  author        = {Graham, Richard L. and Shipman, Galen},
  booktitle     = {Proceedings of the European Parallel Virtual Machine / Message Passing Interface Users' Group Meeting (EuroPVM/MPI)},
  doi           = {10.1007/978-3-540-87475-1_21},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2008/Proceedings of the European Parallel Virtual Machine Message Passing Interface Users' Group Meeting (EuroPVMMPI)/MPI support for multi-core architectures Optimized shared memory collectives - Graham, Sh.pdf:pdf},
  isbn          = {3540874747},
  issn          = {03029743},
  keywords      = {Collectives,MPI,MPI{\_}Allreduce,MPI{\_}Bcast,MPI{\_}Reduce,Shared-memory,Shared{\_}Memory},
  mendeley-tags = {Collectives,MPI,Shared{\_}Memory},
  pages         = {130--140},
  title         = {{MPI support for multi-core architectures: Optimized shared memory collectives}},
  year          = {2008}
}
@techreport{Dongarra1993,
  author          = {Grant, Ryan E.},
  booktitle       = {Message Passing Interface Forum},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Message Passing Interface Forum/Document for a standard message-passing interface Partitioned Communications - Grant - Message Passing Interface Forum.pdf:pdf},
  mendeley-groups = {Presentations {\&} Reports},
  title           = {{Document for a standard message-passing interface; Partitioned Communications}},
  year            = {2020}
}
@article{Grant2019a,
  abstract        = {The MPI multithreading model has been historically difficult to optimize; the interface that it provides for threads was designed as a process-level interface. This model has led to implementations that treat function calls as critical regions and protect them with locks to avoid race conditions. We hypothesize that an interface designed specifically for threads can provide superior performance than current approaches and even outperform single-threaded MPI. In this paper, we describe a design for partitioned communication in MPI that we call finepoints. First, we assess the existing communication models for MPI two-sided communication and then introduce finepoints as a hybrid of MPI models that has the best features of each existing MPI communication model. In addition, “partitioned communication” created with finepoints leverages new network hardware features that cannot be exploited with current MPI point-to-point semantics, making this new approach both innovative and useful both now and in the future. To demonstrate the validity of our hypothesis, we implement a finepoints library and show improvements against a state-of-the-art multithreaded optimized Open MPI implementation on a Cray XC40 with an Aries network. Our experiments demonstrate up{\^{A}} to a 12 × reduction in wait time for completion of send operations. This new model is shown working on a nuclear reactor physics neutron-transport proxy-application, providing up{\^{A}} to 26.1{\%} improvement in communication time and up{\^{A}} to 4.8{\%} improvement in runtime over the best performing MPI communication mode, single-threaded MPI.},
  author          = {Grant, Ryan E. and Dosanjh, Matthew G.F. and Levenhagen, Michael J. and Brightwell, Ron and Skjellum, Anthony},
  doi             = {10.1007/978-3-030-20656-7_17},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)/Finepoints Partitioned multithreaded MPI communication - Grant et al..pdf:pdf},
  isbn            = {9783030206550},
  issn            = {16113349},
  journal         = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  mendeley-groups = {ELEC-878},
  pages           = {330--350},
  title           = {{Finepoints: Partitioned multithreaded MPI communication}},
  volume          = {11501 LNCS},
  year            = {2019}
}
@inproceedings{Grant2019,
  abstract        = {This article focuses on an area of significant and regular capital expenditure, on-premise High Performance Computing (HPC). It examines transformational alternatives to the traditional purchase and usage model.},
  author          = {Grant, Ryan E. and Dosanjh, Matthew G.F. and Levenhagen, Michael J. and Brightwell, Ron and Skjellum, Anthony},
  booktitle       = {Proceedings of the IEEE International Conference on High Performance Computing (HiPC)},
  doi             = {10.1007/978-3-030-20656-7},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the IEEE International Conference on High Performance Computing (HiPC)/Finepoints Partitioned Multithreaded MPI Communication - Grant et al. - Proceedings of the IEEE International Confere.pdf:pdf},
  isbn            = {9783030206550},
  keywords        = {Multithreaded{\_}MPI,collaborative filtering,gpu,matrix factorization,multi-layer perceptron,performance prediction},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {Multithreaded{\_}MPI},
  number          = {May},
  pages           = {40--58},
  title           = {{Finepoints: Partitioned Multithreaded MPI Communication}},
  volume          = {2},
  year            = {2019}
}
@inproceedings{Grant2021,
  abstract      = {Remote Direct Memory Access (RDMA) capabilities have been provided by high-end networks for many years, but the network environments surrounding RDMA are evolving. RDMA performance has historically relied on using strict ordering guarantees to determine when data transfers complete, but modern adaptively-routed networks no longer provide those guarantees. RDMA also exposes low-level details about memory buffers: either all clients are required to coordinate access using a single shared buffer, or exclusive resources must be allocatable per-client for an unbounded amount of time. This makes RDMA unattractive for use in many-to-one communication models such as those found in public internet client-server situations.Remote Virtual Memory Access (RVMA) is a novel approach to data transfer which adapts and builds upon RDMA to provide better usability, resource management, and fault tolerance. RVMA provides a lightweight completion notification mechanism which addresses RDMA performance penalties imposed by adaptively-routed networks, enabling high-performance data transfer regardless of message ordering. RVMA also provides receiver-side resource management, abstracting away previously-exposed details from the sender-side and removing the RDMA requirement for exclusive/coordinated resources. RVMA requires only small hardware modifications from current designs, provides performance comparable or superior to traditional RDMA networks, and offers many new features.In this paper, we describe RVMA's receiver-managed resource approach and how it enables a variety of new data-transfer approaches on high-end networks. In particular, we demonstrate how an RVMA NIC could implement the first hardware-based fault tolerant RDMA-like solution. We present the design and validation of an RVMA simulation model in a popular simulation suite and use it to evaluate the advantages of RVMA at large scale. In addition to support for adaptive routing and easy programmability, RVMA can outperform RDMA on a 3D sweep application by 4.4X.},
  author        = {Grant, Ryan E. and Levenhagen, Michael J. and Dosanjh, Matthew G.F. and Widener, Patrick M.},
  booktitle     = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi           = {10.1109/ipdps49936.2021.00029},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/RVMA Remote Virtual Memory Access - Grant et al. - Proceedings of the IEEE International Parallel and Distribut.pdf:pdf},
  isbn          = {9781665440660},
  keywords      = {Network,RDMA},
  mendeley-tags = {Network,RDMA},
  pages         = {203--212},
  publisher     = {IEEE},
  title         = {{RVMA: Remote Virtual Memory Access}},
  year          = {2021}
}
@article{Grant2015,
  abstract      = {The overhead imposed by connection-based protocols for high-performance computing (HPC) systems can be detrimental to system resource usage and performance. This paper demonstrates for the first time a unified send/recv and Remote Direct Memory Access (RDMA) Write over datagrams design for RDMA-capable network adapters. We previously designed the first and only unreliable datagram RDMA model, RDMA Write-Record, and demonstrated its superior performance over connection-based RDMA. RDMA Write-Record can be applied to several RDMA capable networks, such as iWARP and InfiniBand (which does not support unreliable RDMA Writes). iWARP is a state-of-the-art, high-speed, connection-based RDMA networking technology for both local and wide-area Ethernet networks. iWARP is used as the platform to demonstrate our unreliable RDMA operation design for both channel and memory semantics. We previously outlined the requirements for extending iWARP to operate over datagrams. Here we extend our work on commercial datacenter applications by providing broadcast support for send/recv. In order to study the scalability of datagram-iWARP, we added Message Passing Interface support for RDMA Write-Record to investigate the scalability of HPC-based scientific applications for both send/recv and RDMA Write-Record. The results show that both models outperform their connection-based alternatives, providing superior performance and scalability in a software prototype.},
  author        = {Grant, Ryan E. and Rashti, Mohammad J. and Balaji, Pavan and Afsahi, Ahmad},
  doi           = {10.1016/j.parco.2015.03.009},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Parallel Computing/Scalable connectionless RDMA over unreliable datagrams - Grant et al. - Parallel Computing.pdf:pdf},
  issn          = {01678191},
  journal       = {Parallel Computing},
  keywords      = {Datacenter,Datagrams,Ethernet,IWARP,RDMA,Unreliable network transport,iWARP},
  mendeley-tags = {Datagrams,IWARP,RDMA},
  pages         = {15--39},
  publisher     = {Elsevier Ltd.},
  title         = {{Scalable connectionless RDMA over unreliable datagrams}},
  volume        = {48},
  year          = {2015}
}
@article{Green2021,
  abstract      = {In this article, we introduce HashGraph, a new scalable approach for building hash tables that uses concepts taken from sparse graph representations—hence, the name HashGraph. HashGraph introduces a new way to deal with hash-collisions that does not use “open-addressing” or “separate-chaining,” yet it has the benefits of both these approaches. HashGraph currently works for static inputs. Recent progress with dynamic graph data structures suggests that HashGraph might be extendable to dynamic inputs as well. We show that Hash- Graph can deal with a large number of hash values per entry without loss of performance. Last, we show a new querying algorithm for value lookups. We experimentally compare HashGraph to several state-of-the- as much as 40× when the input contains duplicates. The implementation of HashGraph in this article is for art implementations and find that it outperforms them on average 2× when the inputs are unique and by NVIDIA GPUs. HashGraph can build a hash table at a rate of 2.5 billion keys per second on a NVIDIA GV100 GPU and can query at nearly the same rate},
  author        = {Green, Oded},
  doi           = {10.1145/3460872 1},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Parallel Computing/HashGraph — Scalable Hash Tables Using a Sparse Graph - Green - Parallel Computing.pdf:pdf},
  journal       = {Parallel Computing},
  keywords      = {GPU,Hash{\_}Table},
  mendeley-tags = {GPU,Hash{\_}Table},
  pages         = {1--17},
  title         = {{HashGraph — Scalable Hash Tables Using a Sparse Graph}},
  year          = {2021}
}
@article{Grehant2013,
  abstract      = {Grids designed for computationally demanding scientific applications started experimental phases ten years ago and have been continuously delivering computing power to a wide range of applications for more than half of this time. The observation of their emergence and evolution reveals actual constraints and successful approaches to task mapping across administrative boundaries. Beyond differences in distributions, services, protocols, and standards, a common architecture is outlined. Application-agnostic infrastructures built for resource registration, identification, and access control dispatch delegation to grid sites. Efficient task mapping is managed by large, autonomous applications or collaborations that temporarily infiltrate resources for their own benefits. {\textcopyright} 2013 ACM.},
  author        = {Grehant, Xavier and Demeure, Isabelle and Jarp, Sverre},
  doi           = {10.1145/2480741.2480754},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2013/ACM Computing Surveys/A survey of task mapping on production grids - Grehant, Demeure, Jarp - ACM Computing Surveys.pdf:pdf},
  issn          = {03600300},
  journal       = {ACM Computing Surveys},
  keywords      = {Computing Grids,Grid Architecture,Late Binding,Mapping,Meta-Scheduling,Pull Model,Resource Allocation,Resource Utilization,Survey,Task Mapping,Task Scheduling},
  mendeley-tags = {Mapping,Survey},
  number        = {3},
  pages         = {1--25},
  title         = {{A survey of task mapping on production grids}},
  volume        = {45},
  year          = {2013}
}
@article{Gropp2019a,
  abstract        = {The MPI API provides support for Cartesian process topologies, including the option to reorder the processes to achieve better communication performance. But MPI implementations rarely provide anything useful for the reorder option, typically ignoring it. One argument made is that modern interconnects are fast enough that applications are less sensitive to the exact layout of processes onto the system. However, intranode communication performance is much greater than internode communication performance. In this paper, we show a simple approach that takes into account only information about which MPI processes are on the same node to provide a fast and effective implementation of the MPI Cartesian topology routine. While not optimal, this approach provides a significant improvement over all tested MPI implementations and provides an implementation that may be used as the default in any MPI implementation of MPI{\_}Cart{\_}create. We also explore the impact of taking into account the mapping of processes to processor chips or sockets, and show that this is both relatively easy to accomplish but provides only a small improvement in performance.},
  author          = {Gropp, William D.},
  doi             = {10.1016/j.parco.2019.01.001},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Parallel Computing/Using node and socket information to implement MPI Cartesian topologies - Gropp - Parallel Computing.pdf:pdf},
  isbn            = {9781450364928},
  issn            = {01678191},
  journal         = {Parallel Computing},
  keywords        = {Cartesian process topology,MPI,Message passing,Process topology,Topology{\_}Aware},
  mendeley-groups = {ELEC-873},
  mendeley-tags   = {MPI,Topology{\_}Aware},
  pages           = {98--108},
  title           = {{Using node and socket information to implement MPI Cartesian topologies}},
  volume          = {85},
  year            = {2019}
}
@article{Groth2023,
  author        = {Groth, Tobias and Groppe, Sven and Pionteck, Thilo and Valdiek, Franz and Koppehel, Martin},
  doi           = {10.1007/s10115-023-01891-w},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/Knowledge and Information Systems/Hybrid CPU GPU APU accelerated query , insert , update and erase operations in hash tables with string keys - Groth et al. - Knowledge.pdf:pdf},
  isbn          = {1011502301891},
  issn          = {0219-3116},
  journal       = {Knowledge and Information Systems},
  keywords      = {APU,GPU,Hash table,Hybrid,OneAPI,SYCL,Strings},
  mendeley-tags = {GPU,OneAPI},
  pages         = {1--19},
  publisher     = {Springer London},
  title         = {{Hybrid CPU / GPU / APU accelerated query , insert , update and erase operations in hash tables with string keys}},
  url           = {https://doi.org/10.1007/s10115-023-01891-w},
  year          = {2023}
}
@article{Groves2016,
  abstract        = {Remote Direct Memory Access (RDMA) is expected to be an integral communication mechanism for future exascale systems - enabling asynchronous data transfers, so that applications may fully utilize all CPU resources while simultaneously sharing data amongst remote nodes. We examined this network-induced memory contention (NiMC), the interactions between RDMA and the memory subsystem when applications and out-of-band services compete for memory resources, and NiMC's resulting impact on application-level performance. For a range of hardware technologies and HPC workloads, we quantified NiMC and show that NiMC's impact grows with scale resulting in up to 3X performance degradation at scales as small as 8K processes even in applications that previously have been shown to be performance resilient in the presence of noise. We also evaluated three potential techniques to reduce NiMC's performance impact, namely hardware offloading, core reservation and software-based network throttling. While all three of these solutions show promise, we provide guidelines that help select the best solution for a given environment.},
  author          = {Groves, Taylor and Grant, Ryan E. and Arnold, Dorian},
  doi             = {10.1109/IPDPS.2016.29},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/NiMC Characterizing and Eliminating Network-Induced Memory Contention - Groves, Grant, Arnold - Proceedings of.pdf:pdf},
  isbn            = {9781509021406},
  journal         = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  keywords        = {Measurement,Memory Contention,Network Contention,Networks,Performance},
  mendeley-groups = {ELEC-878},
  pages           = {253--262},
  title           = {{NiMC: Characterizing and Eliminating Network-Induced Memory Contention}},
  year            = {2016}
}
@inproceedings{Guo2019,
  abstract      = {In data management systems, query processing on GPUs or distributed clusters have proven to be an effective method for high efficiency. However, the high PCIe data transfer overhead between CPUs and GPUs, and the communication cost between nodes in distributed systems are usually bottleneck for improving system performance. Recently, GPUDirect RDMA has been developed and has received a lot of attention. It contains the features of the RDMA and GPUDirect technologies, which provides new opportunities for optimizing query processing. In this paper, we revisit the join algorithm, one of the most important operators in query processing, with GPUDirect RDMA. Specifically, we explore the performance of the hash join and sort merge join with GPUDirect RDMA. We present a new design using GPUDirect RDMA to improve the data communication in distributed join algorithms on multi-GPU clusters. We propose a series of techniques, including multi-layer data partitioning, and adaptive data communication path selection for various transmission channels. Experiments show that the proposed distributed join algorithms using GPUDirect RDMA achieve up to 1.83x performance speedup compared to the state-of-the-art distributed join algorithms. To the best of our knowledge, this is the first work for distributed GPU join algorithms. We believe that the insights and implications in this study shall shed lights on future researches using GPUDirect RDMA.},
  author        = {Guo, Chengxin and Chen, Hong and Zhang, Feng and Li, Cuiping},
  booktitle     = {Proceedings of the International Conference on Parallel Processing (ICPP)},
  doi           = {10.1145/3337821.3337862},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Conference on Parallel Processing (ICPP)/Distributed join algorithms on multi-CPU clusters with GPUDirect RDMA - Guo et al. - Proceedings of the International Conference.pdf:pdf},
  isbn          = {9781450362955},
  keywords      = {Distributed join algorithms,GPU,GPUDirect RDMA,GPUDirect{\_}RDMA,Multi-GPU cluster,Multi{\_}GPU},
  mendeley-tags = {GPU,GPUDirect{\_}RDMA,Multi{\_}GPU},
  pages         = {1--10},
  title         = {{Distributed join algorithms on multi-CPU clusters with GPUDirect RDMA}},
  year          = {2019}
}
@inproceedings{Hamidouche2017,
  abstract        = {CUDA 6.0 introduced Managed Memory feature to boost the productivity on GPU systems. It removes the explicit memory management and data movement between the host and the accelerator burden from the programmer. However, these benefits restrict the pinning of the memory and hence limits its performance by depriving the usage of performance-centric features like CUDA-IPC and GPUDirect RDMA. On another hand, CUDA-Aware MPI runtimes, have been continuously improving the performance of data movement from/to native GPU memory allocations. In this paper, to maximize the productivity and performance potentials on GPU systems, we propose a novel CUDA M3 framework. We investigate and propose efficient designs to introduce Managed Memory Awareness to CUDA-Aware MPI. To do so, we analyze the behavior of managed memory and define a locality property. We propose novel schemes to optimize intra-node and inter-node communications using CUDA-IPC and GDR features. To the best of our knowledge, this is the first work to design Managed Memory-Aware data movement schemes that exploit CUDA-IPC and GDR features. The performance evaluation, with micro-benchmark, using a CS-Storm system, shows up to 32X improvement for intra-node configuration and up to 7X for inter-node configuration. Using a real world application, our designs show up to 1.92X improvement on 96 GPUs with GPULBM application.},
  author          = {Hamidouche, Khaled and Awan, Ammar Ahmad and Venkatesh, Akshay and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the IEEE International Conference on High Performance Computing (HiPC)},
  doi             = {10.1109/HiPC.2016.016},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the IEEE International Conference on High Performance Computing (HiPC)/CUDA M3 Designing Efficient CUDA Managed Memory-Aware MPI by Exploiting GDR and IPC - Hamidouche et al. - Proceedings.pdf:pdf},
  isbn            = {9781509054114},
  keywords        = {CUDA,CUDA IPC,CUDA Managed Memory,CUDA-Aware MPI,GPU,GPU Direct RDMA,GPUDirect{\_}RDMA},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {CUDA,GPU,GPUDirect{\_}RDMA},
  pages           = {52--61},
  title           = {{CUDA M3: Designing Efficient CUDA Managed Memory-Aware MPI by Exploiting GDR and IPC}},
  year            = {2017}
}
@inproceedings{Hamidouche2020,
  abstract        = {Current state-of-the-art in GPU networking utilizes a host-centric, kernel-boundary communication model that reduces performance and increases code complexity. To address these concerns, recent works have explored performing network operations from within a GPU kernel itself. However, these approaches typically involve the CPU in the critical path, which leads to high latency and ineicient utilization of network and/or GPU resources. In this work, we introduce GPU Initiated OpenSHMEM (GIO), a new intra-kernel PGAS programming model and runtime that enables GPUs to communicate directly with a NIC without the intervention of the CPU. We accomplish this by exploring the GPU's coarse-grained memory model and correcting semantic mismatches when GPUs wish to directly interact with the network. GIO also reduces latency by relying on a novel template-based design to minimize the overhead of initiating a network operation. We illustrate that for structured applications like a Jacobi 2D stencil, GIO can improve application performance by up to 40{\%} compared to traditional kernel-boundary networking. Furthermore, we demonstrate that on irregular applications like Sparse Triangular Solve (SpTS), GIO provides up to 44{\%} improvement compared to existing intra-kernel networking schemes.},
  author          = {Hamidouche, Khaled and LeBeane, Michael},
  booktitle       = {Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPOPP)},
  doi             = {10.1145/3332466.3374544},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPOPP)/GPU initiated OpenSHMEM Correct and eicient intra-kernel networking for DGPUs - Hamidouche, LeBeane - P.pdf:pdf},
  isbn            = {9781450368186},
  keywords        = {Distributed programming models,GPU,GPUs,OpenSHMEM,RDMA,RDMA networks},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,OpenSHMEM,RDMA},
  pages           = {1--10},
  title           = {{GPU initiated OpenSHMEM: Correct and eicient intra-kernel networking for DGPUs}},
  year            = {2020}
}
@article{Hamidouche2016,
  abstract      = {GPUDirect RDMA (GDR) brings the high-performance communication capabilities of RDMA networks like InfiniBand (IB) to GPUs. It enables IB network adapters to directly write/read data to/from GPU memory. Partitioned Global Address Space (PGAS) programming models, such as OpenSHMEM, provide an attractive approach for developing scientific applications with irregular communication characteristics by providing shared memory address space abstractions, along with one-sided communication semantics. However, current approaches and designs for OpenSHMEM on GPU clusters do not take advantage of the GDR features leading to potential performance improvements being untapped. In this paper, we introduce “CUDA-Aware” concepts for OpenSHMEM that enable operations to be directly performed from/on buffers residing in GPU's memory. We propose novel and efficient designs that ensure “truly one-sided” communication for different intra-/inter-node configurations while working around the hardware limitations. We achieve 2.5 × and 7 × improvement in point-point communication for intra-node and inter-node configurations, respectively. Our proposed framework achieves 2.2$\mu$s for an intra-node 8-byte put operation from CPU to local GPU and 3.13$\mu$s for an inter-node 8-byte put operation from GPU to remote GPU. The proposed designs lead to 19{\%} reduction in the execution time of Stencil2D application kernel from the SHOC benchmark suite on Wilkes system which is composed of 64 dual-GPU nodes. Similarly, the evolution time of GPULBM application is reduced by 45{\%} on 64 GPUs. On 8 GPUs per node CS-Storm-based system, we show 50{\%} and 23{\%} improvement on 32 and 64 GPUs, respectively.},
  author        = {Hamidouche, Khaled and Venkatesh, Akshay and {Ahmad Awan}, Ammar and Subramoni, Hari and Chu, Ching Hsiang and Panda, Dhabaleswar K.},
  doi           = {10.1016/j.parco.2016.05.003},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Parallel Computing/CUDA-Aware OpenSHMEM Extensions and Designs for High Performance OpenSHMEM on GPU Clusters - Hamidouche et al. - Parallel Computing.pdf:pdf},
  issn          = {01678191},
  journal       = {Parallel Computing},
  keywords      = {CUDA,CUDA-aware,GPU,GPUDirect RDMA,OpenSHMEM,PGAS},
  mendeley-tags = {CUDA,GPU,OpenSHMEM,PGAS},
  pages         = {27--36},
  publisher     = {Elsevier B.V.},
  title         = {{CUDA-Aware OpenSHMEM: Extensions and Designs for High Performance OpenSHMEM on GPU Clusters}},
  volume        = {58},
  year          = {2016}
}
@inproceedings{Hamidouche2015,
  abstract      = {GPUDirect RDMA (GDR) brings the high-performance communication capabilities of RDMA networks like InfiniBand (IB) to GPUs (referred to as 'Device'). It enables IB network adapters to directly write/read data to/from GPU memory. Partitioned Global Address Space (PGAS) programming models, such as OpenSHMEM, provide an attractive approach for developing scientific applications with irregular communication characteristics by providing shared memory address space abstractions, along with one-sided communication semantics. However, current approaches and designs of OpenSHMEM on GPU clusters do not take advantage of the GDR features leading to inefficiencies and sub-optimal performance. In this paper, we analyze the performance of various OpenSHMEM operations with different inter-node and intra-node communication configurations (Host-to-Device, Device-to-Device, and Device-to-Host) on GPU based systems. We propose novel designs that ensure 'truly one-sided' communication for the different inter-/intra-node configurations identified above while working around the hardware limitations. To the best of our knowledge, this is the first work that investigates GDR-aware designs for OpenSHMEM communication operations. Experimental evaluations indicate 2.5X and 7X improvement in point-point communication for intra-node and inter-node, respectively. The proposed framework achieves 2.2$\mu$s for an intra-node 8 byte put operation from Host-to-Device, and 3.13$\mu$s for an inter-node 8 byte put operation from GPU to remote GPU. With Stencil2D application kernel from SHOC benchmark suite, we observe a 19{\%} reduction in execution time on 64 GPU nodes. Further, for GPULBM application, we are able to improve the performance of the evolution phase by 53{\%} and 45{\%} on 32 and 64 GPU nodes, respectively.},
  author        = {Hamidouche, Khaled and Venkatesh, Akshay and Awan, Ammar Ahmad and Subramoni, Hari and Chu, Ching Hsiang and Panda, Dhabaleswar K.},
  booktitle     = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi           = {10.1109/CLUSTER.2015.21},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/Exploiting GPUDirect RDMA in designing high performance OpenSHMEM for NVIDIA GPU clusters - Hamidouche et al. - Proceedings.pdf:pdf},
  isbn          = {9781467365987},
  issn          = {15525244},
  keywords      = {CUDA,GPU,GPU Direct RDMA,GPUDirect{\_}RDMA,OpenSHMEM,PGAS},
  mendeley-tags = {CUDA,GPU,GPUDirect{\_}RDMA,OpenSHMEM,PGAS},
  pages         = {78--87},
  publisher     = {IEEE},
  title         = {{Exploiting GPUDirect RDMA in designing high performance OpenSHMEM for NVIDIA GPU clusters}},
  volume        = {2015-Octob},
  year          = {2015}
}
@phdthesis{Han2022,
  author          = {Han, Jingoo and Lee, Dongyoon and Rafique, M Mustafa and Han, Jingoo},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Unknown/Towards a Resource Efficient Framework for Distributed Deep Learning Applications - Han et al. - Unknown.pdf:pdf},
  keywords        = {Deep{\_}Learning,GPU,Thesis,deep learning,deep learning job scheduling,federated learning,framework for distributed deep,gpu cluster,high performance computing,jingoo han,resource management,tensorflow,towards a resource efficient},
  mendeley-groups = {MustKnow,Theses},
  mendeley-tags   = {Deep{\_}Learning,GPU,Thesis},
  pages           = {1--135},
  school          = {Virginia Polytechnic Institute and State University},
  title           = {{Towards a Resource Efficient Framework for Distributed Deep Learning Applications}},
  year            = {2022}
}
@inproceedings{Han2013,
  abstract      = {Branch divergence can incur a high performance penalty on GPGPU programs. We propose a software optimization, called loop merging, that aims to reduce divergence due to varying trip-count of a loop across warp threads. This optimization merges the divergent loop with one or more outer surrounding loops into one loop. In this way, warp threads do not have to wait for each other in each outer loop iteration, thus improving execution efficiency. We implement loop merging in LLVM. Our evaluation on a Fermi GPU shows that it improves the performance of a synthetic benchmark and five application benchmarks by up to 1.6× and 4.3× respectively. Copyright 2013 ACM.},
  author        = {Han, Tianyi David and Abdelrahman, Tarek S.},
  booktitle     = {ACM International Conference Proceeding Series},
  doi           = {10.1145/2458523.2458525},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2013/ACM International Conference Proceeding Series/Reducing divergence in GPGPU programs with loop merging - Han, Abdelrahman - ACM International Conference Proceeding Series.pdf:pdf},
  isbn          = {9781450320177},
  keywords      = {Branch divergence,Compiler,GPU,LLVM,Loop optimizations,Performance evaluation},
  mendeley-tags = {Compiler,GPU,LLVM},
  pages         = {12--23},
  title         = {{Reducing divergence in GPGPU programs with loop merging}},
  year          = {2013}
}
@inproceedings{Hanawa2015,
  abstract      = {The Tightly Coupled Accelerators (TCA) architecture that we proposed in previous work enables direct ommunication between accelerators over nodes. In this paper, we present a proof-of-concept GPU cluster called the HA-PACS/TCA using the PEACH2 chip that we designed as an interconnection router chip based on the TCA architecture. Our system demonstrated 2.0 ?sec of latency on inter-node GPU-to-GPU communication with a PCIe Gen2 x8 by RDMA, reducing minimum latency to just 44{\%} of the InfiniBand-QDR and MPI using GPUDirect for RDMA. Through results of Himeno benchmark tests, we demonstrated that our TCA architecture improved performance scalability with the small-sized problem by up to 61{\%}.},
  author        = {Hanawa, Toshihiro and Fujii, Hisafumi and Fujita, Norihisa and Odajima, Tetsuya and Matsumoto, Kazuya and Kodama, Yuetsu and Boku, Taisuke},
  booktitle     = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi           = {10.1109/CLUSTER.2015.154},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/Improving strong-scaling on GPU cluster based on tightly coupled accelerators architecture - Hanawa et al. - Proceedings of.pdf:pdf},
  isbn          = {9781467365987},
  issn          = {15525244},
  keywords      = {Bandwidth,Benchmark testing,Computer architecture,Conferences,GPU,Graphics processing units,Picture archiving and communication systems,Sockets},
  mendeley-tags = {GPU},
  pages         = {88--91},
  publisher     = {IEEE},
  title         = {{Improving strong-scaling on GPU cluster based on tightly coupled accelerators architecture}},
  volume        = {2015-Octob},
  year          = {2015}
}
@article{Hanford2018,
  abstract      = {The gap is widening between the processor clock speed of end-system architectures and network throughput capabilities. It is now physically possible to provide single-flow throughput of speeds up to 100 Gbps, and 400 Gbps will soon be possible. Most current research into high-speed data networking focuses on managing expanding network capabilities within datacenter Local Area Networks (LANs) or efficiently multiplexing millions of relatively small flows through aWide Area Network (WAN). However, datacenter hyperconvergence places high-throughput networking workloads on general-purpose hardware, and distributed High-Performance Computing (HPC) applications require time-sensitive, high-throughput end-to-end flows (also referred to as "elephant flows") to occur over WANs. For these applications, the bottleneck is often the end-system and not the intervening network. Since the problem of the end-system bottleneck was uncovered, many techniques have been developed which address this mismatch with varying degrees of effectiveness. In this survey, we describe the most promising techniques, beginning with network architectures and NIC design, continuing with operating and end-system architectures, and concluding with clean-slate protocol design. C 2018 ACM.},
  author        = {Hanford, Nathan and Ahuja, Vishal and Farrens, Matthew K. and Tierney, Brian and Ghosal, Dipak},
  doi           = {10.1145/3184899},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/ACM Computing Surveys/A survey of end-system optimizations for high-speed networks - Hanford et al. - ACM Computing Surveys.pdf:pdf},
  issn          = {15577341},
  journal       = {ACM Computing Surveys},
  keywords      = {End-system bottleneck,Experimental analysis,Flow control,High-speed networks,Network,Queueing model,Rate-based protocol,Survey},
  mendeley-tags = {Network,Survey},
  number        = {3},
  title         = {{A survey of end-system optimizations for high-speed networks}},
  volume        = {51},
  year          = {2018}
}
@inproceedings{Hanford2020,
  abstract        = {GPUs are increasingly popular in HPC systems and applications. However, the communication bottleneck between GPUs, distributed across HPC nodes within a cluster, has limited achievable scalability of GPU-centric applications. Advances in inter-node GPU communication such as NVIDIA's GPUDirect have made great strides in addressing this issue. The added software development complexity has been addressed by simplified GPU programming paradigms such as Unified or Managed Memory. To understand the performance of these new features, new benchmarks were developed. Unfortunately, these benchmark efforts do not include correctness checking and certain messaging patterns used in applications. In this paper we highlight important gaps in communication benchmarks and motivate a methodology to help application developers understand the performance tradeoffs of different data movement options. Furthermore, we share systems tuning and deployment experiences across different GPU-aware MPI implementations. In particular, we demonstrate correctness testing is needed along with performance testing through modifications to an existing benchmark. In addition, we present a case study where existing benchmarks fail to characterize how data is moved within SW4, a seismic wave application, and create a benchmark to model this behavior. Finally, we motivate the need for an application-inspired benchmark methodology to assess system performance and guide application programmers on how to use the system more efficiently.},
  author          = {Hanford, Nathan and Pankajakshan, Ramesh and Leon, Edgar A. and Karlin, Ian},
  booktitle       = {Proceedings of the IEEE/ACM Workshop on Exascale MPI (ExaMPI)},
  doi             = {10.1109/ExaMPI52011.2020.00006},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the IEEEACM Workshop on Exascale MPI (ExaMPI)/Challenges of GPU-aware Communication in MPI - Hanford et al. - Proceedings of the IEEEACM Workshop on Exascale MPI (ExaMPI).pdf:pdf},
  isbn            = {9781665415613},
  keywords        = {Benchmarking tools,Computer performance,GPU,General Purpose Graphics Processing Unit (GPGPU),Heterogenous systems,High performance computing,Interconnection networks,MPI,Message Passing Interface (MPI),Protocol integrity},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {GPU,MPI},
  pages           = {1--10},
  title           = {{Challenges of GPU-aware Communication in MPI}},
  year            = {2020}
}
@article{Hasanov2017,
  abstract        = {Optimization of MPI collective communication operations has been an active research topic since the advent of MPI in 1990s. Many general and architecture-specific collective algorithms have been proposed and implemented in the state-of-the-art MPI implementations. Hierarchical topology-oblivious transformation of existing communication algorithms has been recently proposed as a new promising approach to optimization of MPI collective communication algorithms and MPI-based applications. This approach has been successfully applied to the most popular parallel matrix multiplication algorithm, SUMMA, and the state-of-the-art MPI broadcast algorithms, demonstrating significant multifold performance gains, especially for large-scale HPC systems. In this paper, we apply this approach to optimization of the MPI Reduce and Allreduce operations. Theoretical analysis and experimental results on a cluster of Grid'5000 platform are presented.},
  author          = {Hasanov, Khalid and Lastovetsky, Alexey},
  doi             = {10.1007/s11227-016-1779-7},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Journal of Supercomputing/Hierarchical redesign of classic MPI reduction algorithms - Hasanov, Lastovetsky - Journal of Supercomputing.pdf:pdf},
  journal         = {Journal of Supercomputing},
  keywords        = {Collectives,Hierarchical MPI,MPI,MPI collectives,Reduction},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {Collectives,MPI,Reduction},
  pages           = {713--725},
  title           = {{Hierarchical redesign of classic MPI reduction algorithms}},
  year            = {2017}
}
@article{Heidari2018,
  abstract      = {The world is becoming a more conjunct place and the number of data sources such as social networks, online transactions, web search engines, and mobile devices is increasing even more than had been predicted. A large percentage of this growing dataset exists in the form of linked data, more generally, graphs, and of unprecedented sizes. While today's data from social networks contain hundreds of millions of nodes connected by billions of edges, inter-connected data from globally distributed sensors that forms the Internet of Things can cause this to grow exponentially larger. Although analyzing these large graphs is critical for the companies and governments that own them, big data tools designed for text and tuple analysis such as MapReduce cannot process them efficiently. So, graph distributed processing abstractions and systems are developed to design iterative graph algorithms and process large graphs with better performance and scalability. These graph frameworks propose novel methods or extend previous methods for processing graph data. In this article, we propose a taxonomy of graph processing systems and map existing systems to this classification. This captures the diversity in programming and computation models, runtime aspects of partitioning and communication, both for in-memory and distributed frameworks. Our effort helps to highlight key distinctions in architectural approaches, and identifies gaps for future research in scalable graph systems.},
  author        = {Heidari, Safiollah and Simmhan, Yogesh and Calheiros, Rodrigo N. and Buyya, Rajkumar},
  doi           = {10.1145/3199523},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/ACM Computing Surveys/Scalable graph processing frameworks A taxonomy and open challenges - Heidari et al. - ACM Computing Surveys.pdf:pdf},
  issn          = {15577341},
  journal       = {ACM Computing Surveys},
  keywords      = {Big data,Big{\_}Data,Distributed,Distributed systems,Graph processing,Graph{\_}Processing,Large-scale graphs,Parallel processing},
  mendeley-tags = {Big{\_}Data,Distributed,Graph{\_}Processing},
  number        = {3},
  title         = {{Scalable graph processing frameworks: A taxonomy and open challenges}},
  volume        = {51},
  year          = {2018}
}
@article{Heldens2022,
  abstract      = {The GPU programming model is primarily aimed at the development of applications that run one GPU. However, this limits the scalability of GPU code to the capabilities of a single GPU in terms of compute power and memory capacity. To scale GPU applications further, a great engineering effort is typically required: work and data must be divided over multiple GPUs by hand, possibly in multiple nodes, and data must be manually spilled from GPU memory to higher-level memories. We present Lightning: a framework that follows the common GPU programming paradigm but enables scaling to large problems with ease. Lightning supports multi-GPU execution of GPU kernels, even across multiple nodes, and seamlessly spills data to higher-level memories (main memory and disk). Existing CUDA kernels can easily be adapted for use in Lightning, with data access annotations on these kernels allowing Lightning to infer their data requirements and the dependencies between subsequent kernel launches. Lightning efficiently distributes the work/data across GPUs and maximizes efficiency by overlapping scheduling, data movement, and kernel execution when possible. We present the design and implementation of Lightning, as well as experimental results on up to 32 GPUs for eight benchmarks and one real-world application. Evaluation shows excellent performance and scalability, such as a speedup of 57.2x over the CPU using Lighting with 16 GPUs over 4 nodes and 80 GB of data, far beyond the memory capacity of one GPU.},
  archiveprefix = {arXiv},
  arxivid       = {2202.05549},
  author        = {Heldens, Stijn and Hijma, Pieter and van Werkhoven, Ben and Maassen, Jason and van Nieuwpoort, Rob. V.},
  eprint        = {2202.05549},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/arXiv/Lightning Scaling the GPU Programming Model Beyond a Single GPU - Heldens et al. - arXiv.pdf:pdf},
  journal       = {arXiv},
  keywords      = {CUDA,GPU,Multi{\_}GPU},
  mendeley-tags = {CUDA,GPU,Multi{\_}GPU},
  pages         = {1--27},
  title         = {{Lightning: Scaling the GPU Programming Model Beyond a Single GPU}},
  url           = {http://arxiv.org/abs/2202.05549},
  year          = {2022}
}
@article{Heldens2020,
  abstract      = {The next generation of supercomputers will break the exascale barrier. Soon we will have systems capable of at least one quintillion (billion billion) floating-point operations per second (10 18 FLOPS). Tremendous amounts of work have been invested into identifying and overcoming the challenges of the exascale era. In this work, we present an overview of these efforts and provide insight into the important trends, developments , and exciting research opportunities in exascale computing. We use a three-stage approach in which we (1) discuss various exascale landmark studies, (2) use data-driven techniques to analyze the large collection of related literature, and (3) discuss eight research areas in depth based on influential articles. Overall, we observe that great advancements have been made in tackling the two primary exascale challenges: energy efficiency and fault tolerance. However, as we look forward, we still foresee two major concerns: the lack of suitable programming tools and the growing gap between processor performance and data bandwidth (i.e., memory, storage, networks). Although we will certainly reach exascale soon, without additional research, these issues could potentially limit the applicability of exascale computing. 23:2 S. Heldens et al. 1 INTRODUCTION The massive computational power of supercomputers plays a major role in the advancement of many scientific disciplines. The performance of these systems, measured in floating-point operations per second (FLOPS), has increased substantially over the last decades. Since the early 1990s, the TOP500 [4] has kept track of the fastest supercomputers in the world based on the LINPACK benchmark [56]. The TOP500 reveals exponential growth from several gigaflops (10 9 FLOPS) in 1993 to hundreds of petaflops (10 15 FLOPS) in 2018. The high-performance computing (HPC) community is working towards the next major milestone: a computer system capable of at least one exaflop (10 18 FLOPS). The race towards these exascale systems is reaching its conclusion: The United States announced the exascale supercomputer Aurora to be operational by end of 2021 [9] and the 1.5 exaflops supercomputer Frontier a year later [2], the European Union aims to build an exascale system in 2022/2023 [7], and China is targeting 2020 for the Tianhe-3 [1]. However, over the past decade, it has frequently been acknowledged that building and programming such systems would be highly challenging [54, 66, 75, 103, 115, 126, 151]. Tremendous amounts of research have been invested into overcoming the challenges of exascale computing. With this work, we aim to acquire a better understanding of these research efforts by analyzing the major trends. The topic of exascale computing is broad and touches upon nearly all aspects of HPC, each worth a literature survey of their own. Therefore, we do not aim for an exhaustive review of all available literature, but instead, provide a high-level overview of the entire exascale computing landscape. We devised a three-stage methodology that incorporates data-driven techniques alongside manual analysis.},
  author        = {Heldens, Stijn and Hijma, Pieter and Werkhoven, Ben Van and Maassen, Jason and Belloum, Adam S. Z. and {Van Nieuwpoort}, Rob V.},
  doi           = {10.1145/3372390},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/ACM Computing Surveys/The Landscape of Exascale Research - Heldens et al. - ACM Computing Surveys.pdf:pdf},
  issn          = {0360-0300},
  journal       = {ACM Computing Surveys},
  keywords      = {Exascale,MPI,Survey},
  mendeley-tags = {Exascale,MPI,Survey},
  number        = {2},
  pages         = {1--43},
  title         = {{The Landscape of Exascale Research}},
  volume        = {53},
  year          = {2020}
}
@article{Hewett2021,
  author        = {Hewett, Russell J and Ii, Thomas J Grady and Merizian, Jacob},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/IEEE Transactions on Parallel and Distributed Systems/Parallel Primitives for Domain Decomposition in Neural Networks - Hewett, Ii, Merizian - IEEE Transactions on Parallel and Distributed S.pdf:pdf},
  journal       = {IEEE Transactions on Parallel and Distributed Systems},
  keywords      = {Deep{\_}Learning},
  mendeley-tags = {Deep{\_}Learning},
  pages         = {1--15},
  title         = {{Parallel Primitives for Domain Decomposition in Neural Networks}},
  year          = {2021}
}
@inproceedings{Hjelm2018,
  abstract      = {One-sided communication is crucial to enabling communication concurrency. As core counts have increased, particularly with many-core architectures, one-sided (RMA) communication has been proposed to address the ever increasing contention at the network interface. The difficulty in using one-sided (RMA) communication with MPI is that the performance of MPI implementations using RMA with multiple concurrent threads is not well understood. Past studies have been done using MPI RMA in combination with multi-threading (RMA-MT) but they have been performed on older MPI implementations lacking RMA-MT optimizations. In addition prior work has only been done at smaller scale ({\textless}=512 cores). In this paper, we describe a new RMA implementation for Open MPI. The implementation targets scalability and multi-threaded performance. We describe the design and implementation of our RMA improvements and offer an evaluation that demonstrates scaling to 524,288 cores, the full size of a leading supercomputer installation. In contrast, the previous implementation failed to scale past approximately 4,096 cores. To evaluate this approach, we then compare against a vendor optimized MPI RMA-MT implementation with microbenchmarks, a mini-application, and a full astrophysics code at large scale on a many-core architecture. This is the first time that an evaluation at large scale on many-core architectures has been done for MPI RMA-MT (524,288 cores) and the first large scale application performance comparison between two different RMA-MT optimized MPI implementations. The results show a 8.6{\%} benefit to our optimized open source MPI for a full application code running on 512K cores.},
  author        = {Hjelm, Nathan and Dosanjh, Matthew G.F. and Grant, Ryan E. and Groves, Taylor and Bridges, Patrick and Arnold, Dorian},
  booktitle     = {ACM International Conference Proceeding Series},
  doi           = {10.1145/3225058.3225114},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/ACM International Conference Proceeding Series/Improving MPI multi-threaded RMA communication performance - Hjelm et al. - ACM International Conference Proceeding Series.pdf:pdf},
  isbn          = {9781450365109},
  keywords      = {MPI,Multithreaded{\_}MPI,RMA},
  mendeley-tags = {MPI,Multithreaded{\_}MPI,RMA},
  pages         = {1--10},
  title         = {{Improving MPI multi-threaded RMA communication performance}},
  year          = {2018}
}
@techreport{Hoefler2018,
  author          = {Hoefler, Torsten},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Unknown/Twelve ways to fool the masses when reporting performance of deep learning workloads ! ( not to be taken too seriously ) Deep learning a.pdf:pdf},
  keywords        = {Benchmark,Deep{\_}Learning},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {Benchmark,Deep{\_}Learning},
  number          = {November},
  title           = {{Twelve ways to fool the masses when reporting performance of deep learning workloads ! ( not to be taken too seriously ) Deep learning and HPC}},
  url             = {https://spcl.inf.ethz.ch/Publications/.pdf/twelve{\_}ways{\_}ipam.pdf},
  year            = {2018}
}
@article{Hoefler2022,
  author          = {Hoefler, Torsten},
  doi             = {10.1109/MC.2022.3152681},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Computer/Benchmarking Data Science 12 Ways to Lie With Statistics and Performance on Parallel Computers - Hoefler - Computer.pdf:pdf},
  issn            = {15580814},
  journal         = {Computer},
  mendeley-groups = {MustKnow},
  pages           = {49--56},
  publisher       = {IEEE Computer Society},
  title           = {{Benchmarking Data Science: 12 Ways to Lie With Statistics and Performance on Parallel Computers}},
  year            = {2022}
}
@article{Hoefler2013,
  abstract        = {Hybrid parallel programming with the message passing interface (MPI) for internode communication in conjunction with a shared-memory programming model to manage intranode parallelism has become a dominant approach to scalable parallel programming. While this model provides a great deal of flexibility and performance potential, it saddles programmers with the complexity of utilizing two parallel programming systems in the same application. We introduce an MPI-integrated shared-memory programming model that is incorporated into MPI through a small extension to the one-sided communication interface. We discuss the integration of this interface with the MPI 3.0 one-sided semantics and describe solutions for providing portable and efficient data sharing, atomic operations, and memory consistency. We describe an implementation of the new interface in the MPICH2 and Open MPI implementations and demonstrate an average performance improvement of 40 {\%} to the communication component of a five-point stencil solver. {\textcopyright} 2013 Springer-Verlag Wien.},
  author          = {Hoefler, Torsten and Dinan, James and Buntinas, Darius and Balaji, Pavan and Barrett, Brian and Brightwell, Ron and Gropp, William and Kale, Vivek and Thakur, Rajeev},
  doi             = {10.1007/s00607-013-0324-2},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2013/Computing/MPI MPI A new hybrid approach to parallel programming with MPI plus shared memory - Hoefler et al. - Computing.pdf:pdf},
  issn            = {0010485X},
  journal         = {Computing},
  keywords        = {Hybrid parallel programming,Hybrid{\_}MPI,MPI-3.0,Shared memory,Shared{\_}Memory},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {Hybrid{\_}MPI,Shared{\_}Memory},
  number          = {12},
  pages           = {1121--1136},
  title           = {{MPI + MPI: A new hybrid approach to parallel programming with MPI plus shared memory}},
  volume          = {95},
  year            = {2013}
}
@article{Hoefler2017,
  abstract        = {Optimizing communication performance is imperative for largescale computing because communication overheads limit the strong scalability of parallel applications. Today's network cards contain rather powerful processors optimized for data movement. However, these devices are limited to fixed functions, such as remote direct memory access. We develop sPIN, a portable programming model to offload simple packet processing functions to the network card. To demonstrate the potential of the model, we design a cycle-accurate simulation environment by combining the network simulator LogGOPSim and the CPU simulator gem5. We implement offloaded message matching, datatype processing, and collective communications and demonstrate transparent full-application speedups. Furthermore, we show how sPIN can be used to accelerate redundant in-memory filesystems and several other use cases. Our work investigates a portable packet-processing network acceleration model similar to compute acceleration with CUDA or OpenCL. We show how such network acceleration enables an eco-system that can significantly speed up applications and system services.},
  annote          = {Paper's contribution:
                     - They have designed an acceleration system for NIC offload.
                     
                     Differences between sPIN and Active Messages:
                     - Both are independent of process scheduling at the host OS and can be defined independently of the target hardware. 
                     
                     - sPIN is more similar to packet processing framework
                     
                     Types of handlers:
                     1. Header handler
                     2. Payload handler
                     3. Completion handler
                     
                     Some background info:
                     1. DMA should be used scarcely as it is expensive and its performance is non-deterministic
                     2. Portals 4 specifies logical and physical addressing mode, and offers matched or unmatched operation
                     3. Portals Memory descriptors (MDs) form an abstraction of memory to be sent
                     4. Portals Matching entries (MEs) identify receive memory
                     
                     - sPIN prototype implementations:
                     1. A discrete network card (dis) using PCIe to connect to the CPU
                     2. An integrated network card and attaced via a fast signaling protocol such as Advanced eXtensible Interface (AXI)
                     
                     Questions:
                     1. PingPong messages on Figure 3.a. Should Ping be delivered completey before starting Pong?
                     2. In section 4.4.2, why sPIN decides no to cache atomic operations to hide the DMA latency by relaxing memory coherency?},
  archiveprefix   = {arXiv},
  arxivid         = {1709.05483},
  author          = {Hoefler, Torsten and Girolamo, Salvatore Di and Taranov, Konstantin and Grant, Ryan E. and Brightwell, Ron},
  doi             = {10.1145/3126908.3126970},
  eprint          = {1709.05483},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/International Conference for High Performance Computing, Networking, Storage and Analysis, SC/sPIN High-performance streaming Processing in the Network - Hoefler et al. - International Conference for Hig.pdf:pdf},
  isbn            = {9781450351140},
  issn            = {21674337},
  journal         = {International Conference for High Performance Computing, Networking, Storage and Analysis, SC},
  mendeley-groups = {ELEC-878},
  title           = {{sPIN: High-performance streaming Processing in the Network}},
  volume          = {2017-Novem},
  year            = {2017}
}
@inproceedings{Hoefler2008,
  abstract        = {Message progression schemes that enable communication and computation to be overlapped have the potential to improve the performance of parallel applications. With currently available high-performance networks there are several options for making progress: manual progression, use of a progress thread, and communication offload. In this paper we analyze threaded progression approaches, comparing the effects of using shared or dedicated CPU cores for progression. To perform these comparisons, we propose time-based and work-based benchmark schemes. As expected, threaded progression performs well when a spare core is available to be dedicated to communication progression, but a number of operating system effects prevent the same benefits from being obtained when communication progress must share a core with computation. We show that some limited performance improvement can be obtained in the shared-core case by real-time scheduling of the progress thread. {\textcopyright} 2008 IEEE.},
  author          = {Hoefler, Torsten and Lumsdaine, Andrew},
  booktitle       = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi             = {10.1109/CLUSTR.2008.4663774},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2008/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/Message progression in parallel computing - To thread or not to thread - Hoefler, Lumsdaine - Proceedings of the IEEE Inter.pdf:pdf},
  isbn            = {9781424426409},
  issn            = {15525244},
  keywords        = {MPI,Multithreaded{\_}MPI},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Multithreaded{\_}MPI},
  pages           = {213--222},
  title           = {{Message progression in parallel computing - To thread or not to thread?}},
  year            = {2008}
}
@inproceedings{Hoefler2009,
  abstract      = {Point-to-point metrics, such as latency and bandwidth, are often used to characterize network performance with the consequent assumption that optimizing for these metrics is sufficient to improve parallel application performance. However, these metrics can only provide limited insight into application behavior because they do not fully account for effects, such as network congestion, that significantly influence overall network performance. Because many high-performance networks use deterministic oblivious routing, one such effect is the choice of routing algorithm. In this paper, we analyze and compare practical and theoretical aspects of different routing algorithms that are used in today's large-scale networks. We show that widely-used theoretical metrics, such as edge-forwarding index or bisection bandwidth, are not accurate predictors for average network bandwidth. Instead, we introduce an intuitive metric, which we call "effective bisection bandwidth" to characterize quality of different routing algorithms. We present a simple algorithm that globally balances routes and therefore improves the effective bandwidth of the network. Compared to the best algorithm in use today, our new algorithm shows an improvement in effective bisection bandwidth of 40{\%} on a 724-endpoint InfiniBand cluster. {\textcopyright} 2009 IEEE.},
  author        = {Hoefler, Torsten and Schneider, Timo and Lumsdaine, Andrew},
  booktitle     = {Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)},
  doi           = {10.1109/HOTI.2009.9},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2009/Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)/Optimized routing for large-scale InfiniBand networks - Hoefler, Schneider, Lumsdaine - Proceedings of the IEEE Symposium on Hig.pdf:pdf},
  isbn          = {9780769538471},
  issn          = {15504794},
  keywords      = {InfiniBand,Interconnect},
  mendeley-tags = {InfiniBand,Interconnect},
  number        = {Lmc},
  pages         = {103--111},
  title         = {{Optimized routing for large-scale InfiniBand networks}},
  year          = {2009}
}
@article{Hoefler2010,
  abstract        = {This paper presents an in-depth analysis of the impact of system noise on large-scale parallel application performance in realistic settings. Our analytical model shows that not only collective operations but also point-to-point communications influence the application's sensitivity to noise. We present a simulation toolchain that injects noise delays from traces gathered on common large-scale architectures into a LogGPS simulation and allows new insights into the scaling of applications in noisy environments. We investigate collective operations with up to 1 million processes and three applications (Sweep3D, AMG, and POP) with up to 32,000 processes.We show that the scale at which noise becomes a bottleneck is system-specific and depends on the structure of the noise. Simulations with different network speeds show that a 10x faster network does not improve application scalability. We quantify noise and conclude that our tools can be utilized to tune the noise signatures of a specific system. {\textcopyright}2010 IEEE.},
  author          = {Hoefler, Torsten and Schneider, Timo and Lumsdaine, Andrew},
  doi             = {10.1109/SC.2010.12},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2010/2010 ACMIEEE International Conference for High Performance Computing, Networking, Storage and Analysis, SC 2010/Characterizing the influence of system noise on large-scale applications by simulation - Ho.pdf:pdf},
  isbn            = {9781424475575},
  journal         = {2010 ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis, SC 2010},
  mendeley-groups = {ELEC-878},
  number          = {November},
  title           = {{Characterizing the influence of system noise on large-scale applications by simulation}},
  year            = {2010}
}
@inproceedings{Holmes2016,
  abstract      = {MPI includes all processes in MPI COMM WORLD; this is untenable for reasons of scale, resiliency, and overhead. This paper offers a new approach, extending MPI with a new concept called Sessions, which makes two key contributions: a tighter integration with the underlying runtime system; and a scalable route to communication groups. This is a fundamental change in how we organise and address MPI processes that removes well-known scalability barriers by no longer requiring the global communicator MPI COMM - WORLD.},
  author        = {Holmes, Daniel J. and Mohror, Kathryn and Grant, Ryan E. and Skjellum, Anthony and Schulz, Martin and Bland, Wesley and Squyres, Jeffrey M.},
  booktitle     = {Proceedings of the European MPI Users' Group Meeting (EuroMPI)},
  doi           = {10.1145/2966884.2966915},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the European MPI Users' Group Meeting (EuroMPI)/MPI Sessions Leveraging runtime infrastructure to increase scalability of applications at exascale - Holmes et al. - Proceedings of the.pdf:pdf},
  isbn          = {9781450342346},
  keywords      = {Exascale,MPI{\_}Sessions,Message passing interface,Scalable programming model},
  mendeley-tags = {Exascale,MPI{\_}Sessions},
  pages         = {121--129},
  title         = {{MPI Sessions: Leveraging runtime infrastructure to increase scalability of applications at exascale}},
  volume        = {25-28-Sept},
  year          = {2016}
}
@article{Holmes2019,
  abstract      = {Advantages of nonblocking collective communication in MPI have been established over the past quarter century, even predating MPI-1. For regular computations with fixed communication patterns, significant additional optimizations can be revealed through the use of persistence (planned transfers) not currently available in the MPI-3 API except for a limited form of point-to-point persistence (aka half-channels) standardized since MPI-1. This paper covers the design, prototype implementation of LibPNBC (based on LibNBC), and MPI-4 standardization status of persistent nonblocking collective operations. We provide early performance results, using a modified version of NBCBench and an example application (based on 3D conjugate gradient) illustrating the potential performance enhancements for such operations. Persistent operations enable MPI implementations to make intelligent choices about algorithm and resource utilization once and amortize this decision cost across many uses in a long-running program. Evidence that this approach is of value is provided. As with non-persistent, nonblocking collective operations, the requirement for strong progress and blocking completion notification are jointly needed to maximize the benefit of such operations (e.g., to support overlap of communication with computation and/or other communication). Further enhancement of the current reference implementation, as well as additional opportunities to enhance performance through the application of these new APIs, comprise future work.},
  author        = {Holmes, Daniel J. and Morgan, Bradley and Skjellum, Anthony and Bangalore, Purushotham and Sridharan, Srinivas},
  doi           = {10.1016/j.parco.2018.08.001},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Parallel Computing/Planning for performance Enhancing achievable performance for MPI through persistent collective operations - Holmes et al. - Parallel Co.pdf:pdf},
  issn          = {01678191},
  journal       = {Parallel Computing},
  keywords      = {Collective communication,Collectives,MPI,Nonblocking,Optimized algorithm,Persistence,Persistent},
  mendeley-tags = {Collectives,MPI,Persistent},
  pages         = {32--57},
  title         = {{Planning for performance: Enhancing achievable performance for MPI through persistent collective operations}},
  year          = {2019}
}
@inproceedings{Holmes2021,
  author        = {Holmes, Daniel J. and Skjellum, Anthony and Jaeger, Julien and Grant, Ryan E. and Bangalore, Purushotham V. and Dosanjh, Matthew G.F. and Bienz, Amanda and Schafer, Derek},
  booktitle     = {Proceedings of the IEEE/ACM Workshop on Exascale MPI (ExaMPI)},
  doi           = {10.1109/exampi54564.2021.00007},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the IEEEACM Workshop on Exascale MPI (ExaMPI)/Partitioned Collective Communication - Holmes et al. - Proceedings of the IEEEACM Workshop on Exascale MPI (ExaMPI).pdf:pdf},
  isbn          = {9781665411080},
  keywords      = {MPI,Partitioned},
  mendeley-tags = {MPI,Partitioned},
  pages         = {9--17},
  publisher     = {IEEE},
  title         = {{Partitioned Collective Communication}},
  year          = {2021}
}
@article{Hori2021,
  abstract      = {The Message Passing Interface (MPI) plays a crucial part in the parallel computing ecosystem, a driving force behind many of the high-performance computing (HPC) successes. To maintain its relevance to the user community—and in particular to the growing HPC community at large—the MPI standard needs to identify and understand the MPI users' concerns and expectations, and adapt accordingly to continue to efficiently bridge the gap between users and hardware. This questionnaire survey was conducted using two online questionnaire frameworks and has gathered more than 850 answers from 42 countries since February 2019. Some of preceding surveys of MPI uses are questionnaire surveys like ours, while others are conducted either by analyzing MPI programs to reveal static behavior or by using profiling tools to analyze the dynamic runtime behavior of MPI jobs. Our survey is different from other questionnaire surveys in terms of its larger number of participants and wide geographic spread. As a result, it is possible to illustrate the current status of MPI users more accurately and with a wider geographical distribution. In this report, we will show some interesting findings, compare the results with preceding studies when possible, and provide some recommendations for MPI Forum based on the findings.},
  author        = {Hori, Atsushi and Jeannot, Emmanuel and Bosilca, George and Ogura, Takahiro and Gerofi, Balazs and Yin, Jie and Ishikawa, Yutaka},
  doi           = {10.1016/j.parco.2021.102853},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Parallel Computing/An international survey on MPI users - Hori et al. - Parallel Computing.pdf:pdf},
  issn          = {01678191},
  journal       = {Parallel Computing},
  keywords      = {MPI,Message Passing Interface (MPI),Survey},
  mendeley-tags = {MPI,Survey},
  pages         = {1--13},
  title         = {{An international survey on MPI users}},
  url           = {https://doi.org/10.1016/j.parco.2021.102853},
  year          = {2021}
}
@inproceedings{Hori2018,
  author          = {Hori, Atsushi and Si, Min and Gerofi, Balazs and Takagi, Masamichi and Dayal, Jai and Balaji, Pavan and Ishikawa, Yutaka},
  booktitle       = {Proceedings of the International Symposium on High-Performance Parallel and Distributed Computing (HPDC)},
  doi             = {10.1145/3208040.3208045},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the International Symposium on High-Performance Parallel and Distributed Computing (HPDC)/Process-in-process Techniques for Practical Address-Space Sharing - Hori et al. - Proceedings of t.pdf:pdf},
  isbn            = {9781450357852},
  keywords        = {In-situ,Intra-Node Communication,Intra{\_}node,MPI,Parallel Execution Model,Shared{\_}Memory,acm reference format,atsushi hori,balazs gerofi,in-situ,intra-node communication,jai dayal,masamichi takagi,min si,mpi,parallel execution model,pavan},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {Intra{\_}node,MPI,Shared{\_}Memory},
  pages           = {131--143},
  title           = {{Process-in-process: Techniques for Practical Address-Space Sharing}},
  year            = {2018}
}
@techreport{Horowitz2023,
  author          = {Horowitz, Daniel},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/Unknown/Optimizing at Scale Investigating Hidden Bottlenecks in Multi-Node Workloads - Horowitz - Unknown.pdf:pdf},
  mendeley-groups = {Presentations {\&} Reports},
  title           = {{Optimizing at Scale : Investigating Hidden Bottlenecks in Multi-Node Workloads}},
  year            = {2023}
}
@article{Hu2016,
  abstract      = {The lack of detailed white box illustration leaves a gap in the field of GPGPU (General-Purpose Computing on the Graphic Processing Unit), thus hindering users and researchers from exploring hardware potential while improving application performance. This article bridges the gap by demystifying the micro-architecture and operating mechanism of GPGPU. We propose a descriptive model that addresses key issues of most concerns, including task organization, hardware structure, scheduling mechanism, execution mechanism, and memory access. We also validate the effectiveness of our model by interpreting the software/hardware cooperation of CUDA.},
  author        = {Hu, Liang and Che, Xilong and Zheng, Si Qing},
  doi           = {10.1145/2873053},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/ACM Computing Surveys/A closer look at GPGPU - Hu, Che, Zheng - ACM Computing Surveys.pdf:pdf},
  issn          = {15577341},
  journal       = {ACM Computing Surveys},
  keywords      = {Conceptual model,GPGPU,GPU,Micro-architecture,Parallel computing,SIMD,Survey},
  mendeley-tags = {GPU,Survey},
  number        = {4},
  title         = {{A closer look at GPGPU}},
  volume        = {48},
  year          = {2016}
}
@inproceedings{Hu2021,
  author          = {Hu, Qinghao and Sun, Peng and Yan, Shengen and Wen, Yonggang},
  booktitle       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Characterization and Prediction of Deep Learning Workloads in Large-Scale GPU Datacenters.pdf:pdf},
  isbn            = {9781450384421},
  keywords        = {Deep{\_}Learning,GPU,MPI,Multi{\_}GPU,cluster management system,cluster statistical analysis,conservation,deep learning train-,energy,gpu datacenter,ing,time-series prediction,workload scheduling},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Deep{\_}Learning,GPU,MPI,Multi{\_}GPU},
  pages           = {1--15},
  title           = {{Characterization and Prediction of Deep Learning Workloads in Large-Scale GPU Datacenters}},
  year            = {2021}
}
@article{Huang2023,
  abstract      = {With the ever-increasing computing power of supercomputers and the growing scale of scientific applications, the efficiency of MPI collective communications turns out to be a critical bottleneck in large-scale distributed and parallel processing. Large message size in MPI collectives is a particularly big concern because it may significantly delay the overall parallel performance. To address this issue, prior research simply applies the off-the-shelf fix-rate lossy compressors in the MPI collectives, leading to suboptimal performance, limited generalizability, and unbounded errors. In this paper, we propose a novel solution, called C-Coll, which leverages error-bounded lossy compression to significantly reduce the message size, resulting in a substantial reduction in communication cost. The key contributions are three-fold. (1) We develop two general, optimized lossy-compression-based frameworks for both types of MPI collectives (collective data movement as well as collective computation), based on their particular characteristics. Our framework not only reduces communication cost but also preserves data accuracy. (2) We customize an optimized version based on SZx, an ultra-fast error-bounded lossy compressor, which can meet the specific needs of collective communication. (3) We integrate C-Coll into multiple collectives, such as MPI{\_}Allreduce, MPI{\_}Scatter, and MPI{\_}Bcast, and perform a comprehensive evaluation based on real-world scientific datasets. Experiments show that our solution outperforms the original MPI collectives as well as multiple baselines and related efforts by 3.5-9.7X.},
  archiveprefix = {arXiv},
  arxivid       = {2304.03890},
  author        = {Huang, Jiajun and Di, Sheng and Yu, Xiaodong and Zhai, Yujia and Liu, Jinyang and Raffenetti, Ken and Zhou, Hui and Zhao, Kai and Chen, Zizhong and Cappello, Franck and Guo, Yanfei and Thakur, Rajeev},
  eprint        = {2304.03890},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/arXiv/C-Coll Introducing Error-bounded Lossy Compression into MPI Collectives - Huang et al. - arXiv.pdf:pdf},
  journal       = {arXiv},
  keywords      = {Collectives,Compression,MPI},
  mendeley-tags = {Collectives,Compression,MPI},
  pages         = {1--14},
  title         = {{C-Coll: Introducing Error-bounded Lossy Compression into MPI Collectives}},
  url           = {http://arxiv.org/abs/2304.03890},
  year          = {2023}
}
@article{Huang2021,
  abstract        = {Taskflow aims to streamline the building of parallel and heterogeneous applications using a lightweight task graph-based approach. Taskflow introduces an expressive task graph programming model to assist developers in the implementation of parallel and heterogeneous decomposition strategies on a heterogeneous computing platform. Our programming model distinguishes itself as a very general class of task graph parallelism with in-graph control flow to enable end-to-end parallel optimization. To support our model with high performance, we design an efficient system runtime that solves many of the new scheduling challenges arising out of our models and optimizes the performance across latency, energy efficiency, and throughput. We have demonstrated the promising performance of Taskflow in real-world applications. As an example, Taskflow solves a large-scale machine learning workload up to 29{\%} faster, 1.5× less memory, and 1.9× higher throughput than the industrial system, oneTBB, on a machine of 40 CPUs and 4 GPUs. We have opened the source of Taskflow and deployed it to large numbers of users in the open-source community.},
  author          = {Huang, Tsung Wei and Lin, Dian Lun and Lin, Chun Xun and Lin, Yibo},
  doi             = {10.1109/TPDS.2021.3104255},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/IEEE Transactions on Parallel and Distributed Systems/Taskflow A Lightweight Parallel and Heterogeneous Task Graph Computing System - Huang et al. - IEEE Transactions on Parallel and Distrib.pdf:pdf},
  issn            = {15582183},
  journal         = {IEEE Transactions on Parallel and Distributed Systems},
  keywords        = {CUDA{\_}Graphs,GPU,Parallel programming,high-performance computing,modern C++ programming,task parallelism},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {CUDA{\_}Graphs,GPU},
  pages           = {1303--1320},
  publisher       = {IEEE},
  title           = {{Taskflow: A Lightweight Parallel and Heterogeneous Task Graph Computing System}},
  year            = {2021}
}
@article{Huang2019,
  abstract      = {Scaling up deep neural network capacity has been known as an effective approach to improving model quality for several different machine learning tasks. In many cases, increasing model capacity beyond the memory limit of a single accelerator has required developing special algorithms or infrastructure. These solutions are often architecture-specific and do not transfer to other tasks. To address the need for efficient and task-independent model parallelism, we introduce GPipe, a pipeline parallelism library that allows scaling any network that can be expressed as a sequence of layers. By pipelining different sub-sequences of layers on separate accelerators, GPipe provides the flexibility of scaling a variety of different networks to gigantic sizes efficiently. Moreover, GPipe utilizes a novel batch-splitting pipelining algorithm, resulting in almost linear speedup when a model is partitioned across multiple accelerators. We demonstrate the advantages of GPipe by training large-scale neural networks on two different tasks with distinct network architectures: (i) Image Classification: We train a 557-million-parameter AmoebaNet model and attain a top-1 accuracy of 84.4{\%} on ImageNet-2012, (ii) Multilingual Neural Machine Translation: We train a single 6-billion-parameter, 128-layer Transformer model on a corpus spanning over 100 languages and achieve better quality than all bilingual models.},
  archiveprefix = {arXiv},
  arxivid       = {1811.06965},
  author        = {Huang, Yanping and Cheng, Youlong and Bapna, Ankur and Firat, Orhan and Chen, Mia Xu and Chen, Dehao and Lee, Hyouk Joong and Ngiam, Jiquan and Le, Quoc V. and Wu, Yonghui and Chen, Zhifeng},
  eprint        = {1811.06965},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Advances in Neural Information Processing Systems/GPipe Efficient training of giant neural networks using pipeline parallelism - Huang et al. - Advances in Neural Information Processing.pdf:pdf},
  issn          = {10495258},
  journal       = {Advances in Neural Information Processing Systems},
  keywords      = {GPU,Pipeline,TPU},
  mendeley-tags = {GPU,Pipeline,TPU},
  pages         = {1--10},
  title         = {{GPipe: Efficient training of giant neural networks using pipeline parallelism}},
  year          = {2019}
}
@inproceedings{Huber2022,
  abstract      = {Open MP is the preferred choice for CPU parallelism in High-Performance-Computing (HPC) applications written in C, C++, or Fortran. As HPC systems became heterogeneous, OpenMP introduced support for accelerator offloading via the target directive. This allowed porting existing (CPU) code onto GPUs, including well established CPU parallelism paradigms. However, there are architectural differences between CPU and GPU execution which make common patterns, like forking and joining threads, single threaded execution, or sharing of local (stack) variables, in general costly on the latter. So far it was left to the user to identify and avoid non-efficient code patterns, most commonly by writing their OpenMP offloading codes in a kernel-language style which resembles CUDA more than it does traditional OpenMP.In this work we present OpenMP-Aware program analyses and optimizations that allow efficient execution of the generic, CPU-centric parallelism model provided by OpenMP on GPUs. Our implementation in LLVM/Clang maps various common OpenMP patterns found in real world applications efficiently to the GPU. As static analysis is inherently limited we provide actionable and informative feedback to the user about the performed and missed optimizations, together with ways for the user to annotate the program for better results. Our extensive evaluation using several HPC proxy applications shows significantly improved GPU kernel times and reduction in resources requirements, such as GPU registers.},
  author        = {Huber, Joseph and Cornelius, Melanie and Georgakoudis, Giorgis and Tian, Shilei and Diaz, Jose M Monsalve and Dinel, Kuter and Chapman, Barbara and Doerfert, Johannes},
  booktitle     = {Proceedings of the International Symposium on Code Generation and Optimization (CGO)},
  doi           = {10.1109/cgo53902.2022.9741290},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the International Symposium on Code Generation and Optimization (CGO)/Efficient Execution of OpenMP on GPUs - Huber et al. - Proceedings of the International Symposium on Code Generation a.pdf:pdf},
  isbn          = {9781665405843},
  keywords      = {Compiler,GPU,OpenMP},
  mendeley-tags = {Compiler,GPU,OpenMP},
  pages         = {41--52},
  title         = {{Efficient Execution of OpenMP on GPUs}},
  year          = {2022}
}
@inproceedings{Hunold2020,
  abstract        = {The Message Passing Interface (MPI) defines the semantics of data communication operations, while the implementing libraries provide several parameterized algorithms for each operation. Each algorithm of an MPI collective operation may work best on a particular system and may be dependent on the specific communication problem. Internally, MPI libraries employ heuristics to select the best algorithm for a given communication problem when being called by an MPI application. The majority of MPI libraries allow users to override the default algorithm selection, enabling the tuning of this selection process. The problem then becomes how to select the best possible algorithm for a specific case automatically. In this paper, we address the algorithm selection problem for MPI collective communication operations. To solve this problem, we propose an auto-tuning framework for collective MPI operations based on machine-learning techniques. First, we execute a set of benchmarks of an MPI library and its entire set of collective algorithms. Second, for each algorithm, we fit a performance model by applying regression learners. Last, we use the regression models to predict the best possible (fastest) algorithm for an unseen communication problem. We evaluate our approach for different MPI libraries and several parallel machines. The experimental results show that our approach outperforms the standard algorithm selection heuristics, which are hard-coded into the MPI libraries, by a significant margin.},
  author          = {Hunold, Sascha and Bhatele, Abhinav and Bosilca, George and Knees, Peter},
  booktitle       = {Proceedings of IEEE International Conference on Cluster Computing, ICCC},
  doi             = {10.1109/CLUSTER49012.2020.00036},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of IEEE International Conference on Cluster Computing, ICCC/Predicting MPI Collective Communication Performance Using Machine Learning - Hunold et al. - Proceedings of IEEE International Conf.pdf:pdf},
  isbn            = {9781728166773},
  issn            = {15525244},
  keywords        = {Auto-tuning,Auto{\_}Tune,Collectives,GAM,KNN,MPI,Machine Learning,Message Passing Interface,Performance Prediction,XGBoost},
  mendeley-groups = {Auto-Tuning},
  mendeley-tags   = {Auto{\_}Tune,Collectives,MPI},
  pages           = {259--269},
  title           = {{Predicting MPI Collective Communication Performance Using Machine Learning}},
  year            = {2020}
}
@inproceedings{Hunold2018,
  abstract        = {MPI collective operations provide a standardized interface for performing data movements within agroup ofprocesses. The efficiency of collective communication operations depends on the actual algorithm, its implementation, and the specific communication problem (type of communication, message size, and number of processes). Many MPI libraries provide numerous algorithms for specific collective operations. The strategy for selecting an efficient algorithm is often times predefined (hard-coded) in MPI libraries, but some of them, such as Open MPI, allow users to change the algorithm manually. Finding the best algorithm for each case is a hard problem, and several approaches to tune these algorithmic parameters have been proposed. We use an orthogonal approach to the parameter-tuning of MPI collectives, that is, instead of testing individual algorithmic choices provided by an MPI library, we compare the latency of a specific MPI collective operation to the latency of semantically equivalent functions, which we call the mock-up implementations. The structure of the mock-up implementations is defined by self-consistent performance guidelines. The advantage of this approach is that tuning using mock-up implementations is always possible, whether or not an MPI library allows users to select a specific algorithm at run-time. We implement this concept in a library called PGMPITuneLib, which is layered between the user code and the actual MPI implementation. This library selects the best-performing algorithmic pattern of an MPI collective by intercepting MPI calls and redirecting them to our mock-up implementations. Experimental results show that PGMPITuneLib can significantly reduce the latency of MPI collectives, and also equally important, that it can help identifying the tuning potential of MPI libraries.},
  author          = {Hunold, Sascha and Carpen-Amarie, Alexandra},
  booktitle       = {Proceedings of the International Conference on High Performance Computing},
  doi             = {10.1145/3149457.3149461},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the International Conference on High Performance Computing/Autotuning MPI collectives using performance guidelines - Hunold, Carpen-Amarie - Proceedings of the International Conference on.pdf:pdf},
  isbn            = {9781450353724},
  keywords        = {Auto{\_}Tune,Autotuning,Collective operations,Collectives,MPI,Performance guidelines},
  mendeley-groups = {Auto-Tuning},
  mendeley-tags   = {Auto{\_}Tune,Collectives,MPI},
  pages           = {64--74},
  title           = {{Autotuning MPI collectives using performance guidelines}},
  year            = {2018}
}
@inproceedings{Hunold2018a,
  abstract        = {"Held in conjunction with SC18: The International Conference for High Performance Computing, Networking, Storage and Analysis, Dallas, Texas, November 11-16, 2018." "BMS Part Number CFP18J43-ART"--PDF copyright page},
  author          = {Hunold, Sascha and Carpen-Amarie, Alexandra},
  booktitle       = {Proceedings of IEEE/ACM International Workshop on Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)},
  doi             = {10.1109/PMBS.2018.8641622},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of IEEEACM International Workshop on Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMB./Algorithm Selection of MPI Collectives using Machine Learning.pdf:pdf},
  keywords        = {Auto{\_}Tune,Collectives,MPI},
  mendeley-groups = {Auto-Tuning},
  mendeley-tags   = {Auto{\_}Tune,Collectives,MPI},
  pages           = {1--6},
  title           = {{Algorithm Selection of MPI Collectives using Machine Learning Techniques}},
  year            = {2018}
}
@inproceedings{Hunold2019,
  abstract        = {Autotuning is a well established method to improve software performance for a given system, and it is especially important in High Performance Computing. The goal of autotuning is to find the best possible algorithm and its best parameter settings for a given instance. Autotuning can also be applied to MPI libraries, such as Open MPI or Intel MPI. These MPI libraries provide numerous parameters that allow users to adapt them to a given system. Some of these tunable parameters enable users to select a specific algorithm that should be used internally by an MPI collective operation. For the purpose of automatically tuning MPI collectives on a given system, the Intel MPI library is shipped with mpitune. The drawback of tools like mpitune is that results can only be applied to cases (e.g., number of processes, message size) for which the tool has performed the optimization. To overcome this limitation, we present a first step towards tuning MPI libraries also for unseen instances by applying machine learning techniques. Our goal is to create a classifier that takes the collective operation, the message size and communicator characteristics (number of compute nodes, number of processes per node) as an input and gives the predicted best algorithm for this problem as an output. We show how such a model can be constructed and what pitfalls should be avoided. We demonstrate by thorough experimentation that our proposed prediction model is able to outperform the default configuration of Intel MPI or Open MPI on recent computer clusters.},
  author          = {Hunold, Sascha and Carpen-Amarie, Alexandra},
  booktitle       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi             = {10.1109/PMBS.2018.8641622},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Algorithm Selection of MPI Collectives Using Machine Learning Techniques - Hunold, Carpen.pdf:pdf},
  isbn            = {9781728101828},
  keywords        = {Auto{\_}Tune,Collectives,Intel mpitune,MPI,MPI benchmarks,Machine{\_}Learning,autotuning,collective communication operations,machine learning,performance prediction},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Auto{\_}Tune,Collectives,MPI,Machine{\_}Learning},
  pages           = {45--50},
  publisher       = {IEEE},
  title           = {{Algorithm Selection of MPI Collectives Using Machine Learning Techniques}},
  year            = {2019}
}
@inproceedings{Hunold2022,
  abstract        = {Collective communication operations, such as Broadcast or Reduce, are fundamental cornerstones in many high-performance applications. Most collective operations can be implemented using different algorithms, each of which has advantages and disadvantages. For that reason, MPI libraries typically implement a selection logic that attempts to make good algorithmic choices for specific problem instances. It has been shown in the literature that the hard-coded algorithm selection logic found in MPI libraries can be improved by tuning the collectives in a separate, offline micro-benchmarking run.In the present paper, we go a fundamentally different way of improving the algorithm selection for MPI collectives. We integrate the probing of different algorithms directly into the MPI library. Whenever an MPI application is started with a given process configuration, i.e., the number of nodes and the processes per node, the tuner, instead of the default selection logic, finds the next algorithm to complete an issued MPI collective call. The tuner records the runtime of this MPI call for a subset of processes. With the recorded performance data, the tuner is able to build a performance model that allows selecting an efficient algorithm for a given collective problem. Subsequently recorded performance results are then used to update the performance model, where the probabilities for selecting an algorithm are adapted by the tuner, such that slow algorithms get a smaller chance of being selected. We show in a case study, using the ECP proxy application miniAMR, that our approach can effectively tune the performance of Allreduce.},
  author          = {Hunold, Sascha and Steiner, Sebastian},
  booktitle       = {Proceedings of IEEE/ACM International Workshop on Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMBS)},
  doi             = {10.1109/PMBS56514.2022.00016},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of IEEEACM International Workshop on Performance Modeling, Benchmarking and Simulation of High Performance Computer Systems (PMB./OMPICollTune Autotuning MPI Collectives by Incremental Online.pdf:pdf},
  isbn            = {9781665451857},
  keywords        = {Auto{\_}Tune,Collectives,HPC,MPI,algorithm selection,autotuning,collective communication,machine learning},
  mendeley-groups = {Auto-Tuning},
  mendeley-tags   = {Auto{\_}Tune,Collectives,MPI},
  pages           = {123--128},
  title           = {{OMPICollTune: Autotuning MPI Collectives by Incremental Online Learning}},
  year            = {2022}
}
@inproceedings{Pershin2021,
  author          = {Ilya, Pershin and Levchenko, Vadim and Perepelkina, Anastasia},
  booktitle       = {Proceedings of the Russian Supercomputing Days (RuSCDays)},
  doi             = {10.1007/978-3-030-92864-3},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the Russian Supercomputing Days (RuSCDays)/Qualitative and Quantitative Study of Modern GPU Synchronization Approaches - Ilya, Levchenko, Perepelkina - Proceedings of the Russian.pdf:pdf},
  isbn            = {9783030928643},
  keywords        = {CUDA,Cooperative groups,Domain decomposition,GPU,Latency hiding,Roofline model,cooperative groups,cuda,decomposition,domain,latency hiding,roofline model},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {GPU},
  pages           = {376--390},
  publisher       = {Springer International Publishing},
  title           = {{Qualitative and Quantitative Study of Modern GPU Synchronization Approaches}},
  year            = {2021}
}
@inproceedings{Inozemtsev2012,
  abstract      = {Collective communication operations in the Message Passing Interface (MPI) consume a significant amount of time at scale, degrading the performance of scientific applications. Optimizing collectives is key to application performance and scalability. This paper focuses on hiding the latency of the all gather collective by efficiently offloading it to the networking hardware. We have investigated the use of Mellanox CORE-Direct offloading technology for independent progression of communication within the collective in order to achieve high communication/computation overlap. This study evaluates several design options for the nonblocking all gather collective and discusses implementations of offloaded Standard Exchange, Ring and Bruck algorithms in flat and hierarchical communicators under single-port and k-port modelling. We have applied our findings to improving the performance of the redesigned Radix Sort application kernel. Performance results suggest that our offloaded nonblocking all gather compares favourably to the blocking variant (with improvements of up to 68{\%} for medium messages in a hierarchical collective) while providing high overlap capability. Multiport modelling is shown to be beneficial, especially in a flat communicator. Radix Sort enjoys up to 40{\%} improvement in its runtime. {\textcopyright} 2012 IEEE.},
  author        = {Inozemtsev, Grigori and Afsahi, Ahmad},
  booktitle     = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi           = {10.1109/CLUSTER.2012.75},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2012/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/Designing an offloaded nonblocking MPI-Allgather collective using CORE-Direct - Inozemtsev, Afsahi - Proceedings of the IEE.pdf:pdf},
  isbn          = {9780768548074},
  keywords      = {Collectives,MPI,Message{\_}Passing,Offloading,allgather,collective communication,coredirect,message passing,offloading},
  mendeley-tags = {Collectives,MPI,Message{\_}Passing,Offloading},
  pages         = {477--485},
  publisher     = {IEEE},
  title         = {{Designing an offloaded nonblocking MPI-Allgather collective using CORE-Direct}},
  year          = {2012}
}
@article{Iwasaki2019,
  abstract      = {A performance vs. practicality trade-off exists between user-level threading techniques. The community has settled mostly on a black-and-white perspective; fully fledged threads assume that suspension is imminent and incur overheads when suspension does not take place, and run-to-completion threads are more lightweight but less practical since they cannot suspend. Gray areas exist, however, whereby threads can start with minimal capabilities and then can be dynamically promoted to acquire additional capabilities when needed. This paper investigates the full spectrum of threading techniques from a performance vs. practicality trade-off perspective on modern multicore and many-core systems. Our results indicate that achieving the best trade-off highly depends on the suspension likelihood; dynamic promotion is more appropriate when suspension is unlikely and represents a solid replacement for run to completion, thanks to its lower programming constraints, while fully fledged threads remain the technique of choice when suspension likelihood is high.},
  author        = {Iwasaki, Shintaro and Amer, Abdelhalim and Taura, Kenjiro and Balaji, Pavan},
  doi           = {10.1109/SC.2018.00026},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Lessons learned from analyzing dynamic promotion for user-level threading - Iwasaki et al.pdf:pdf},
  isbn          = {9781538683842},
  journal       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  keywords      = {Multithread},
  mendeley-tags = {Multithread},
  pages         = {293--304},
  publisher     = {IEEE},
  title         = {{Lessons learned from analyzing dynamic promotion for user-level threading}},
  year          = {2019}
}
@article{Iwasaki2020,
  abstract      = {User-level threads have been widely adopted as a means of achieving lightweight concurrent execution without the costs of OS-level threads. Nevertheless, the costs of managing user-level threads represent a performance barrier that dictates how fine grained the concurrency exposed by an application can be without incurring significant overheads; this in turn may translate into insufficient parallelism to exploit highly parallel systems. This article is a deep dive into the fundamental costs in implementing user-level threads. We first identify that one of the highest sources of fork-join overheads stems from deviations, events that incur context switching during the execution of a thread and disrupt a run-to-completion execution. We then conduct an in-depth investigation of a wide spectrum of methods with respect to how they handle deviations while covering both parent-and child-first scheduling policies. Our methodology involves a comprehensive instruction-and cache-level analysis of all methods on several modern CPU architectures. The primary finding of our evaluation is that dynamic promotion methods that assume the absence of deviation and dynamically provide context-switching support offer the best trade-off between performance and capability when the likelihood of deviation is low.},
  author        = {Iwasaki, Shintaro and Amer, Abdelhalim and Taura, Kenjiro and Balaji, Pavan},
  doi           = {10.1109/TPDS.2020.2976057},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/IEEE Transactions on Parallel and Distributed Systems/Analyzing the Performance Trade-Off in Implementing User-Level Threads - Iwasaki et al. - IEEE Transactions on Parallel and Distributed.pdf:pdf},
  issn          = {15582183},
  journal       = {IEEE Transactions on Parallel and Distributed Systems},
  keywords      = {Multithreading,Shared{\_}Memory,context switch,multitasking,scheduling,task parallelism,user-level threads},
  mendeley-tags = {Shared{\_}Memory},
  number        = {8},
  pages         = {1859--1877},
  publisher     = {IEEE},
  title         = {{Analyzing the Performance Trade-Off in Implementing User-Level Threads}},
  volume        = {31},
  year          = {2020}
}
@inproceedings{Jain2019,
  abstract        = {Collective operations are used in MPI programs to express common communication patterns, collective computations, or synchronization. In many collectives, such as MPI-Allreduce, the intra-node component of the collective lies on the critical path, as the inter-node communication cannot start until the intra-node component has completed. With increasing number of core counts in each node, intra-node optimizations that leverage shared memory become more important. In this paper, we focus on the performance benefit of optimizing intra-node collectives using POSIX shared memory for synchronization and data sharing. We implement several collectives using basic primitives or steps as building blocks. Key components of our implementation include a dedicated intra- node collectives layer, careful layout of the data structures, as well as optimizations to exploit the memory hierarchy to balance parallelism and latencies of data movement. A comparison of our implementation on top of MPICH shows significant performance speedups with respect to the original MPICH implementation, MVAPICH, and OpenMPI.},
  author          = {Jain, Surabhi and Kaleem, Rashid and Balmana, Marc Gamell and Langer, Akhil and Durnov, Dmitry and Sannikov, Alexander and Garzaran, Maria},
  booktitle       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi             = {10.1109/SC.2018.00032},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Framework for scalable intra-node collective operations using shared memory - Jain et al..pdf:pdf},
  isbn            = {9781538683842},
  keywords        = {Collectives,Intra{\_}node,Shared{\_}Memory},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {Collectives,Intra{\_}node,Shared{\_}Memory},
  pages           = {374--385},
  title           = {{Framework for scalable intra-node collective operations using shared memory}},
  year            = {2018}
}
@article{Jenkins2012,
  abstract        = {Lack of efficient and transparent interaction with GPU data in hybrid MPI+GPU environments challenges GPU acceleration of large-scale scientific computations. A particular challenge is the transfer of noncontiguous data to and from GPU memory. MPI implementations currently do not provide an efficient means of utilizing data types for noncontiguous communication of data in GPU memory. To address this gap, we present an MPI data type-processing system capable of efficiently processing arbitrary data types directly on the GPU. We present a means for converting conventional data type representations into a GPU-amenable format. Fine-grained, element-level parallelism is then utilized by a GPU kernel to perform in-device packing and unpacking of noncontiguous elements. We demonstrate a several-fold performance improvement for noncontiguous column vectors, 3D array slices, and 4D array sub volumes over CUDA-based alternatives. Compared with optimized, layout-specific implementations, our approach incurs low overhead, while enabling the packing of data types that do not have a direct CUDA equivalent. These improvements are demonstrated to translate to significant improvements in end-to-end, GPU-to-GPU communication time. In addition, we identify and evaluate communication patterns that may cause resource contention with packing operations, providing a baseline for adaptively selecting data-processing strategies. {\textcopyright} 2012 IEEE.},
  author          = {Jenkins, John and Dinan, James and Balaji, Pavan and Samatova, Nagiza F. and Thakur, Rajeev},
  doi             = {10.1109/CLUSTER.2012.72},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2012/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/Enabling fast, noncontiguous GPU data movement in hybrid MPIGPU environments - Jenkins et al. - Proceedings of the IEEE Int.pdf:pdf},
  journal         = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  keywords        = {Datatype,GPU,MPI},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Datatype,GPU,MPI},
  pages           = {468--476},
  publisher       = {IEEE},
  title           = {{Enabling fast, noncontiguous GPU data movement in hybrid MPI+GPU environments}},
  year            = {2012}
}
@inproceedings{Jeong2023,
  author        = {Jeong, Jinwoo and Baek, Seungsu and Ahn, Jeongseob},
  booktitle     = {Proceedings of the European Conference on Computer Systems (Eurosys)},
  doi           = {10.1145/3552326.3567508},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/Proceedings of the European Conference on Computer Systems (Eurosys)/Fast and Efficient Model Serving Using Multi-GPUs with Direct-Host-Access - Jeong, Baek, Ahn - Proceedings of the European Conference.pdf:pdf},
  isbn          = {9781450394871},
  keywords      = {Deep{\_}Learning,GPU},
  mendeley-tags = {Deep{\_}Learning,GPU},
  pages         = {249--265},
  publisher     = {ACM},
  title         = {{Fast and Efficient Model Serving Using Multi-GPUs with Direct-Host-Access}},
  year          = {2023}
}
@inproceedings{Ji2012a,
  abstract        = {Current implementations of MPI are unaware of accelerator memory (i.e., GPU device memory) and require programmers to explicitly move data between memory spaces. This approach is inefficient, especially for intranode communication where it can result in several extra copy operations. In this work, we integrate GPU-awareness into a popular MPI runtime system and develop techniques to significantly reduce the cost of intranode communication involving one or more GPUs. Experiment results show an up to 2x increase in bandwidth, resulting in an average of 4.3{\%} improvement to the total execution time of a halo exchange benchmark. {\textcopyright} 2012 IEEE.},
  author          = {Ji, Feng and Aji, Ashwin M. and Dinan, James and Buntinas, Darius and Balaji, Pavan and Feng, Wu Chun and Ma, Xiaosong},
  booktitle       = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
  doi             = {10.1109/IPDPSW.2012.227},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2012/Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)/Efficient intranode communication in GPU-accelerated systems - Ji et al. - Proceedings of the IEEE I.pdf:pdf},
  isbn            = {9780769546766},
  keywords        = {CUDA,GPU,Intra{\_}node,Intranode communication,MPI,MPICH2,Nemesis},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {CUDA,GPU,Intra{\_}node,MPI},
  pages           = {1838--1847},
  title           = {{Efficient intranode communication in GPU-accelerated systems}},
  year            = {2012}
}
@article{Ji2012,
  abstract        = {Accelerator awareness has become a pressing issue in data movement models, such as MPI, because of the rapid deployment of systems that utilize accelerators. In our previous work, we developed techniques to enhance MPI with accelerator awareness, thus allowing applications to easily and efficiently communicate data between accelerator memories. In this paper, we extend this work with techniques to perform efficient data movement between accelerators within the same node using a DMA-assisted, peer-to-peer intranode communication technique that was recently introduced for NVIDIA GPUs. We present a detailed design of our new approach to intranode communication and evaluate its improvement to communication and application performance using micro-kernel benchmarks and a 2D stencil application kernel. {\textcopyright} 2012 IEEE.},
  author          = {Ji, Feng and Aji, Ashwin M. and Dinan, James and Buntinas, Darius and Balaji, Pavan and Thakur, Rajeev and Feng, Wu Chun and Ma, Xiaosong},
  doi             = {10.1109/HPCC.2012.69},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2012/Proceedings of the IEEE International Conference on High Performance Computing and Communications (HPCC)/DMA-assisted, intranode communication in GPU accelerated systems - Ji et al. - Proceedings of the.pdf:pdf},
  isbn            = {9780769547497},
  journal         = {Proceedings of the IEEE International Conference on High Performance Computing and Communications (HPCC)},
  keywords        = {DMA,GPU,Intra{\_}node,Intranode communication,MPI},
  mendeley-groups = {MustKnow,UsedInComp1,UsedInComp2},
  mendeley-tags   = {DMA,GPU,Intra{\_}node,MPI},
  pages           = {461--468},
  title           = {{DMA-assisted, intranode communication in GPU accelerated systems}},
  year            = {2012}
}
@article{Jocksch2021,
  abstract      = {Collective communication, namely the pattern allreduce in message-passing systems, is optimised based on measurements at the installation time of the library. The algorithms used are set up in an initialisation phase of the communication, as so-called persistent collective communication, introduced in the message-passing interface (MPI) standard. Part of our allreduce algorithms are the patterns reduce{\_}scatter and allgatherv which are also considered standalone. For the allreduce pattern for short messages the existing cyclic shift algorithm (Bruck's algorithm) is applied with a prefix operation. For allreduce and long messages our algorithm is based on reduce{\_}scatter and allgatherv, where the cyclic shift algorithm is applied with a flexible number of communication ports per node. The algorithms for equal message sizes are used with non-equal message sizes together with a heuristic for rank reordering. Medium message sizes are communicated with an incomplete reduce{\_}scatter followed by allgatherv. Furthermore, an optional recursive application of the cyclic shift algorithm is applied. All algorithms are applied at the node level. The data is gathered and scattered by the cores within the node and the communication algorithms are applied across the nodes. In general, our approach outperforms the non-persistent counterpart in established MPI libraries by up to one order of magnitude or shows equal performance, with a few exceptions of number of nodes and message sizes.},
  author        = {Jocksch, Andreas and Ohana, No{\'{e}} and Lanti, Emmanuel and Koutsaniti, Eirini and Karakasis, Vasileios and Villard, Laurent},
  doi           = {10.1016/j.parco.2021.102812},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Parallel Computing/An optimisation of allreduce communication in message-passing systems - Jocksch et al. - Parallel Computing.pdf:pdf},
  issn          = {01678191},
  journal       = {Parallel Computing},
  keywords      = {Allgatherv,Allreduce,Collective communication,Collectives,MPI,Reduce{\_}scatter},
  mendeley-tags = {Collectives,MPI},
  pages         = {1--13},
  title         = {{An optimisation of allreduce communication in message-passing systems}},
  url           = {https://doi.org/10.1016/j.parco.2021.102812},
  year          = {2021}
}
@inproceedings{Junger2018,
  abstract      = {Hash maps are among the most versatile data structures in computer science because of their compact data layout and expected constant time complexity for insertion and querying. However, associated memory access patterns during the probing phase are highly irregular resulting in strongly memory-bound implementations. Massively parallel accelerators such as CUDA-enabled GPUs may overcome this limitation by virtue of their fast video memory featuring almost one TB/s bandwidth in comparison to main memory modules of state-of-The-Art CPUs with less than 100 GB/s. Unfortunately, the size of hash maps supported by existing single-GPU hashing implementations is restricted by the limited amount of available video RAM. Hence, hash map construction and querying that scales across multiple GPUs is urgently needed in order to support structured storage of bigger datasets at high speeds. In this paper, we introduce WarpDrive-a scalable, distributed single-node multi-GPU implementation for the construction and querying of billions of key-value pairs. We propose a novel subwarp-based probing scheme featuring coalesced memory access over consecutive memory regions in order to mitigate the high latency of irregular access patterns. Our implementation achieves 1.4 billion insertions per second in single-GPU mode for a load factor of 0.95 thereby outperforming the GPU-cuckoo implementation of the CUDPP library by a factor of 2.8 on a P100. Furthermore, we present transparent scaling to multiple GPUs within the same node with up to 4.3 billion operations per second for high load factors on four P100 GPUs connected by NVLink technology. WarpDrive is free software and can be downloaded at https://github.com/sleeepyjack/warpdrive.},
  author        = {Junger, Daniel and Hundt, Christian and Schmidt, Bertil},
  booktitle     = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi           = {10.1109/IPDPS.2018.00054},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/WarpDrive Massively parallel hashing on multi-GPU nodes - Junger, Hundt, Schmidt - Proceedings of the IEEE Inte.pdf:pdf},
  isbn          = {9781538643686},
  keywords      = {CUDA,Distributed,GPU,Hash table,Hash{\_}Table,NVLINK},
  mendeley-tags = {GPU,Hash{\_}Table},
  pages         = {441--450},
  title         = {{WarpDrive: Massively parallel hashing on multi-GPU nodes}},
  year          = {2018}
}
@inproceedings{Junger2020,
  abstract      = {Hash tables are ubiquitous. Properties such as an amortized constant time complexity for insertion and querying as well as a compact memory layout make them versatile associative data structures with manifold applications. The rapidly growing amount of data emerging in many fields motivated the need for accelerated hash tables designed for modern parallel architectures. In this work, we exploit the fast memory interface of modern GPUs together with a parallel hashing scheme tailored to improve global memory access patterns, to design WarpCore - a versatile library of hash table data structures. Unique device-sided operations allow for building high performance data processing pipelines entirely on the GPU. Our implementation achieves up to 1.6 billion inserts and up to 4.3 billion retrievals per second on a single GV100 GPU thereby outperforming the state-of-the-art solutions cuDPP, SlabHash, and NVIDIA RAPIDS cuDF. This performance advantage becomes even more pronounced for high load factors of over 90{\%}. To overcome the memory limitation of a single GPU, we scale our approach over a dense NVLink topology which gives us close-to-optimal weak scaling on DGX servers. We further show how WarpCore can be used for accelerating a real world bioinformatics application (metagenomic classification) with speedups of over two orders-of-magnitude against state-of-the-art CPU-based solutions. WarpCore is open source software written in C++/CUDA-C and can be downloaded at https://github.com/sleeepyjack/warpcore.},
  author        = {Junger, Daniel and Kobus, Robin and Muller, Andre and Hundt, Christian and Xu, Kai and Liu, Weiguo and Schmidt, Bertil},
  booktitle     = {Proceedings of the IEEE International Conference on High Performance Computing (HiPC)},
  doi           = {10.1109/HiPC50609.2020.00015},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the IEEE International Conference on High Performance Computing (HiPC)/WarpCore A Library for fast Hash Tables on GPUs - Junger et al. - Proceedings of the IEEE International Conference on.pdf:pdf},
  keywords      = {GPU,GPUs,Hash{\_}Table,bioinformatics,hash tables},
  mendeley-tags = {GPU,Hash{\_}Table},
  pages         = {11--20},
  title         = {{WarpCore: A Library for fast Hash Tables on GPUs}},
  year          = {2020}
}
@article{Kaas2022,
  archiveprefix   = {arXiv},
  arxivid         = {arXiv:2209.06018v1},
  author          = {Kaas, Anders Friis and Paleykov, Stilyan Petrov and Robroek, Ties and Tozun, Pinar},
  eprint          = {arXiv:2209.06018v1},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/arXiv/Deep Learning Training on Multi-Instance GPUs - Kaas et al. - arXiv.pdf:pdf},
  journal         = {arXiv},
  keywords        = {Deep{\_}Learning,GPU,MIG,MPI},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Deep{\_}Learning,GPU,MIG,MPI},
  pages           = {1--13},
  publisher       = {Association for Computing Machinery},
  title           = {{Deep Learning Training on Multi-Instance GPUs}},
  year            = {2022}
}
@inproceedings{Kamil2005,
  abstract      = {As thermal constraints reduce the pace of CPU performance improvements, the cost and scalability of future HPC architectures will be increasingly dominated by the interconnect. In this work we perform an in-depth study of the communication requirements across a broad spectrum of important scientific applications, whose computational methods include: finite-difference, lattice-bolzmann, particle in cell, sparse linear algebra, particle mesh ewald, and FFT-based solvers. We use the IPM (integrated Performance Monitoring) profiling framework to collect detailed statistics on communication topology and message volume with minimal impact to code performance. By characterizing the parallelism and communication requirements of such a diverse set of applications, we hope to guide architectural choices for the design and implementation of interconnects for future HPC systems. {\textcopyright} 2005 IEEE.},
  author        = {Kamil, Shoaib and Shalf, John and Oliker, Leonid and Skinner, David},
  booktitle     = {Proceedings of the IEEE International Symposium on Workload Characterization, (IISWC)},
  doi           = {10.1109/IISWC.2005.1526015},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2005/Proceedings of the IEEE International Symposium on Workload Characterization, (IISWC)/Understanding ultra-scale application communication requirements - Kamil et al. - Proceedings of the IEEE Internation.pdf:pdf},
  isbn          = {0780394615},
  keywords      = {Network,Survey},
  mendeley-tags = {Network,Survey},
  pages         = {178--187},
  title         = {{Understanding ultra-scale application communication requirements}},
  year          = {2005}
}
@inproceedings{Kandalla2012,
  abstract      = {Graph-based computations are commonly used across various data intensive computing domains ranging from social networks to biological systems. On distributed memory systems, graph algorithms involve explicit communication between processes and often exhibit sparse, irregular behavior. Minimizing these communication overheads is critical to cater to the graph-theoretic analyses demands of emerging {\&}{\#}x00E2;bigdata{\&}{\#}x00E2; applications. In this paper, we explore the challenges associated with reducing the communication overheads of a popular 2D Breadth First Search (BFS) implementation in the CombBLAS library. This BFS algorithm relies on two common MPI collectives, MPI Alltoallv and MPI Allgathervto exchange data between processes and they account for more than 20{\%} of the overall run time. Re-designing parallel applications to take advantage of MPI-3 non-blocking collectives to achieve latency hiding is an active area of research. However, the 2D BFS algorithm in CombBLAS is not directly amenable for such a re-design through common overlap techniques such as, double-buffering. In this paper, we propose to re-design the BFS algorithm to leverage MPI-3 no blocking, neighborhood collective communication operations to achieve fine-grained computation/communication overlap. We also leverage the CORE-Direct network offload feature in theConnectX-2 InfiniBand adapter from Mellanox to design highly efficient and scalable non-blocking, neighborhood Alltoallv and Allgatherv collective operations. Our experimental evaluations show that we can improve the communication overheads of the2D BFS algorithm by up to 70{\%}, with 1,936 processes. {\textcopyright} 2012 IEEE.},
  author        = {Kandalla, K. and Buluc, A. and Subramoni, H. and Tomko, K. and Vienne, J. and Oliker, L. and Panda, D. K.},
  booktitle     = {Proceedings of the IEEE International Conference on Cluster Computing Workshops},
  doi           = {10.1109/ClusterW.2012.40},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2012/Proceedings of the IEEE International Conference on Cluster Computing Workshops/Can network-offload based non-blocking neighborhood MPI collectives improve communication overheads of irregular graph algo.pdf:pdf},
  isbn          = {9780768548449},
  keywords      = {2D BFS Algorithms,Collective Offload and InfiniBand,MPI,MPI-3 non-blocking collectives,Neighborhood{\_}Collectives,Offloading},
  mendeley-tags = {MPI,Neighborhood{\_}Collectives,Offloading},
  pages         = {222--230},
  publisher     = {IEEE},
  title         = {{Can network-offload based non-blocking neighborhood MPI collectives improve communication overheads of irregular graph algorithms?}},
  year          = {2012}
}
@inproceedings{Keller2010,
  abstract        = {High Performance Computing systems are used on a regular basis to run a myriad of application codes, yet a surprising dearth of information exists with respect to communications characteristics. Even less information is available on the low-level communication libraries, such as the length of MPI Unexpected Message Queues (UMQs) and the length of time such messages spend in these queues. Such information is vital to developing appropriate strategies for handling such data at the library and system level. In this paper we present data on the communication characteristics of three applications GTC, LSMS, and S3D. We present data on the size of their UMQ, the time spend searching the UMQ and the length of time such messages spend in these queues. We find that for the particular inputs used, these applications have widely varying characteristics with regard to UMQ length and show patterns for specific applications which persist over various scales. {\textcopyright} 2010 Springer-Verlag.},
  author          = {Keller, Rainer and Graham, Richard L.},
  booktitle       = {Proceedings of the European MPI Users' Group Meeting (EuroMPI)},
  doi             = {10.1007/978-3-642-15646-5_19},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2010/Proceedings of the European MPI Users' Group Meeting (EuroMPI)/Characteristics of the unexpected message queue of MPI applications - Keller, Graham - Proceedings of the European MPI Users' Group Meet.pdf:pdf},
  isbn            = {3642156452},
  issn            = {03029743},
  keywords        = {MPI,Message{\_}Matching},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Message{\_}Matching},
  pages           = {179--188},
  title           = {{Characteristics of the unexpected message queue of MPI applications}},
  year            = {2010}
}
@inproceedings{Khorassani2021,
  abstract        = {In recent years, GPU-enhanced clusters have become more prevalent in High-Performance Computing (HPC), leading to a demand for more efficient multi-GPU communication. This makes it increasingly important to explore performance enhancements that can be attained through the communication middleware such as MPI, in order to fully take advantage of the GPUs available on these systems. In this paper, we propose locality-aware and adaptive schemes for hierarchical All-to-all collective communication on large-scale dense GPU systems. The proposed algorithms utilize the high bandwidth made available through the NVLink interconnect between GPUs in order to overlap communication latency. We focus on personalized and non-personalized all-to-all collective communication. These are components of modern scientific computing applications that utilize matrix transpose and three-dimensional Fast Fourier Transforms (FFT) and becoming more relevant for Deep Learning workloads with model and hybrid parallelisms. The performance evaluation with an application kernel performing three-dimensional FFT indicates that the proposed schemes for personalized all-to-all can lead to up to 15-25{\%} lower execution time on 256 GPUs on the Lassen system. We demonstrate approximately 8{\%} enhancement in training time for distributed K-FAC used in Deep Learning training on up to 128 GPUs. We also demonstrate approximately 22{\%} and 30{\%} improvement in the performance of non-personalized and personalized all-to-all benchmarks, respectively, compared to the state-of-the-art MPI libraries on the Summit and Lassen systems.},
  annote          = {Does:
                     - Single Process (leader) handles the intra-node communications.
                     
                     Problems:
                     - Using Isend/Irecv to gather data to the leader
                     -},
  author          = {Khorassani, Kawthar Shafie and Chu, Ching Hsiang and Anthony, Quentin G. and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)},
  doi             = {10.1109/CCGrid51090.2021.00021},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the IEEEACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)/Adaptive and hierarchical large message all-to-all communication algorithms for large-scale dense GPU sys.pdf:pdf},
  isbn            = {9781728195865},
  keywords        = {Adaptive,All-to-all,Allgather,GPU,Hierarchical,MPI,NVLink},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Adaptive,GPU,Hierarchical,MPI},
  pages           = {113--122},
  publisher       = {IEEE},
  title           = {{Adaptive and hierarchical large message all-to-all communication algorithms for large-scale dense GPU systems}},
  year            = {2021}
}
@inproceedings{Khorassani2021a,
  abstract        = {In recent years, GPU-enhanced clusters have become more prevalent in High-Performance Computing (HPC), leading to a demand for more efficient multi-GPU communication. This makes it increasingly important to explore performance enhancements that can be attained through the communication middleware such as MPI, in order to fully take advantage of the GPUs available on these systems. In this paper, we propose locality-aware and adaptive schemes for hierarchical All-to-all collective communication on large-scale dense GPU systems. The proposed algorithms utilize the high bandwidth made available through the NVLink interconnect between GPUs in order to overlap communication latency. We focus on personalized and non-personalized all-to-all collective communication. These are components of modern scientific computing applications that utilize matrix transpose and three-dimensional Fast Fourier Transforms (FFT) and becoming more relevant for Deep Learning workloads with model and hybrid parallelisms. The performance evaluation with an application kernel performing three-dimensional FFT indicates that the proposed schemes for personalized all-to-all can lead to up to 15-25{\%} lower execution time on 256 GPUs on the Lassen system. We demonstrate approximately 8{\%} enhancement in training time for distributed K-FAC used in Deep Learning training on up to 128 GPUs. We also demonstrate approximately 22{\%} and 30{\%} improvement in the performance of non-personalized and personalized all-to-all benchmarks, respectively, compared to the state-of-the-art MPI libraries on the Summit and Lassen systems.},
  author          = {Khorassani, Kawthar Shafie and Chu, Ching Hsiang and Anthony, Quentin G. and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)},
  doi             = {10.1109/CCGrid51090.2021.00021},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the IEEEACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)/Adaptive and hierarchical large message all-to-all communication algorithms for large-scale dense GPU (2).pdf:pdf},
  isbn            = {9781728195865},
  keywords        = {All-to-all,All{\_}to{\_}All,Allgather,GPU,MPI,NVLink},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {All{\_}to{\_}All,GPU,MPI},
  pages           = {1--10},
  publisher       = {IEEE},
  title           = {{Adaptive and hierarchical large message all-to-all communication algorithms for large-scale dense GPU systems}},
  year            = {2021}
}
@inproceedings{Khorassani2019,
  abstract        = {The advent of Graphics Processing Unit (GPU)-enabled OpenPOWER architectures are empowering the advancement of various High-Performance Computing (HPC) applications from dynamic modular simulation to deep learning training. GPU-aware Message Passing Interface (MPI) is one of the most efficient libraries used to exploit the computing power on GPU-enabled HPC systems at scale. However, there is a lack of thorough performance evaluations for GPU-aware MPI libraries to provide insights into the varying costs and benefits of using each one on GPU-enabled OpenPOWER systems. In this paper, we provide a detailed performance evaluation and analysis of point-to-point communication using various GPU-aware MPI libraries including SpectrumMPI, OpenMPI+UCX, and MVAPICH2-GDR on OpenPOWER GPU-enabled systems. We demonstrate that all three MPI libraries deliver approximately 95{\%} of achievable bandwidth for NVLink communication between two GPUs on the same socket. For inter-node communication where the InfiniBand network dominates the peak bandwidth, MVAPICH2-GDR and SpectrumMPI attain approximately 99{\%} achievable bandwidth, while OpenMPI delivers close to 95{\%}. This evaluation is useful to determine which MPI library can provide the highest performance enhancement.},
  author          = {Khorassani, Kawthar Shafie and Chu, Ching Hsiang and Subramoni, Hari and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the IEEE International Conference on High Performance Computing (HiPC)},
  doi             = {10.1007/978-3-030-34356-9_28},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the IEEE International Conference on High Performance Computing (HiPC)/Performance Evaluation of MPI Libraries on GPU-Enabled OpenPOWER Architectures Early Experiences - Khorassani et al..pdf:pdf},
  isbn            = {9783030343552},
  issn            = {16113349},
  keywords        = {GPU,MPI,NVLink,OpenPOWER,RDMA},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {GPU,MPI,NVLink,RDMA},
  pages           = {361--378},
  title           = {{Performance Evaluation of MPI Libraries on GPU-Enabled OpenPOWER Architectures: Early Experiences}},
  year            = {2019}
}
@inproceedings{Kim2015,
  abstract      = {Many studies have been performed to realize a high-performance computing environment based on GPU-based clusters. With GPU-based clusters, efficient data transfer is very important because it affects the performance of GPU-based cluster computing systems. GPUDirect RDMA technology is introduced to improve the data transfer efficiency between two nodes. In this paper, we describe a case study of the optimization of the data transfer efficiency of GPUDirect RDMA for GPU- and InfiniBand-based clusters. Based on experimental results, the data transfer latency can be improved by as much as 50{\%} compared to a non-optimized system.},
  author        = {Kim, Bongjae and Jung, Hyedong},
  booktitle     = {Proceedings of Research in Adaptive and Convergent Systems (RACS)},
  doi           = {10.1145/2811411.2811468},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Proceedings of Research in Adaptive and Convergent Systems (RACS)/A case study of data transfer efficiency optimization for GPU- and InfiniBand-based clusters - Kim, Jung - Proceedings of Research in Ad.pdf:pdf},
  isbn          = {9781450337380},
  keywords      = {GPU,GPUDirect RDMA,GPUDirect{\_}RDMA,High performance computing,InfiniBand},
  mendeley-tags = {GPU,GPUDirect{\_}RDMA,InfiniBand},
  pages         = {247--250},
  title         = {{A case study of data transfer efficiency optimization for GPU- and InfiniBand-based clusters}},
  year          = {2015}
}
@inproceedings{Kim2017,
  abstract      = {GPU-based computations are widely used in various computing areas because GPU provides very high computing performance when compared to typical CPU. In this paper, we evaluate and analyze the computing performance of multiple GPUs based on MPI environments. We examine the performance of sparse matric-vector multiply (SpMV). SpMV is one of the most heavily used components in many scientific applications. Based on the performance evaluation results, generally, the execution time of SpMV is decreased as the number of GPUs increase. In some case, the performance was reduced according to the computation overhead, the memory copy overhead among GPUs, and the characteristics of sparse matrices.},
  author        = {Kim, Bongjae and Jung, Jinmang and Min, Hong and Heo, Junyoung and Jung, Hyedong},
  booktitle     = {Proceedings of the Research in Adaptive and Convergent Systems (RACS)},
  doi           = {10.1145/3129676.3129716},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the Research in Adaptive and Convergent Systems (RACS)/Performance evaluations of multiple GPUs based on MPI Environments - Kim et al. - Proceedings of the Research in Adaptive and Converg.pdf:pdf},
  isbn          = {9781450350273},
  keywords      = {Cluster Computing,GPU,GPUs,High Performance Computing,MPI,Message Passing Interface},
  mendeley-tags = {GPU,MPI},
  pages         = {303--304},
  title         = {{Performance evaluations of multiple GPUs based on MPI Environments}},
  volume        = {2017-Janua},
  year          = {2017}
}
@article{Kim2008,
  abstract        = {Evolving technology and increasing pin-bandwidth motivate the use of high-radix routers to reduce the diameter, latency, and cost of interconnection networks. High-radix networks, however, require longer cables than their low-radix counterparts. Because cables dominate network cost, the number of cables, and particularly the number of long, global cables should be minimized to realize an efficient network. In this paper, we introduce the dragonfly topology which uses a group of high-radix routers as a virtual router to increase the effective radix of the network. With this organization, each minimally routed packet traverses at most one global channel. By reducing global channels, a dragonfly reduces cost by 20{\%} compared to a flattened butterfly and by 52{\%} compared to a folded Clos network in configurations with ≥ 16K nodes.We also introduce two new variants of global adaptive routing that enable load-balanced routing in the dragonfly. Each router in a dragonfly must make an adaptive routing decision based on the state of a global channel connected to a different router. Because of the indirect nature of this routing decision, conventional adaptive routing algorithms give degraded performance. We introduce the use of selective virtual-channel discrimination and the use of credit round-trip latency to both sense and signal channel congestion. The combination of these two methods gives throughput and latency that approaches that of an ideal adaptive routing algorithm.},
  author          = {Kim, John and Dally, Wiliam J. and Scott, Steve and Abts, Dennis},
  doi             = {10.1145/1394608.1382129},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2008/ACM SIGARCH Computer Architecture News/Technology-Driven, Highly-Scalable Dragonfly Topology - Kim et al. - ACM SIGARCH Computer Architecture News.pdf:pdf},
  issn            = {0163-5964},
  journal         = {ACM SIGARCH Computer Architecture News},
  mendeley-groups = {ELEC-878},
  number          = {3},
  pages           = {77--88},
  title           = {{Technology-Driven, Highly-Scalable Dragonfly Topology}},
  volume          = {36},
  year            = {2008}
}
@article{Kim2020,
  author          = {Kim, Youngrang and Choi, Hye},
  doi             = {10.1007/s10586-020-03144-9},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Cluster Computing/Towards an optimized distributed deep learning framework for a heterogeneous multi-GPU cluster - Kim, Choi - Cluster Computing.pdf:pdf},
  isbn            = {0123456789},
  journal         = {Cluster Computing},
  keywords        = {Deep{\_}Learning,GPU,MPI,Multi{\_}GPU},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Deep{\_}Learning,GPU,MPI,Multi{\_}GPU},
  pages           = {1--14},
  title           = {{Towards an optimized distributed deep learning framework for a heterogeneous multi-GPU cluster}},
  year            = {2020}
}
@article{Kim2019,
  abstract        = {This paper presents a comprehensive suite of techniques for optimized memory management in multi-GPU systems to accelerate deep learning application execution. We employ a hybrid utilization of GPU and CPU memories in a multi-GPU environment by effectively addressing contention issues in the shared interconnect (e.g., PCIe, NVLink). In addition, we designed and implemented an intelligent prefetching algorithm (from CPU memory to GPU) that achieves the highest processing throughput while sustaining a large mini-batch size. We successfully implemented our optimization techniques on TensorFlow, and performed extensive experiments in various multi-GPU environments including traditional PCIe and the latest high-bandwidth interconnect, NVLink. Evaluation results show that our proposed scheme actually improves computing performance by decreasing the I/O bottleneck, and effectively increasing the mini-batch size without sacrificing overall training throughput.},
  author          = {Kim, Youngrang and Lee, Jaehwan and Kim, Jik Soo and Jei, Hyunseung and Roh, Hongchan},
  doi             = {10.1007/s10586-019-02974-6},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Cluster Computing/Comprehensive techniques of multi-GPU memory optimization for deep learning acceleration - Kim et al. - Cluster Computing.pdf:pdf},
  isbn            = {0123456789},
  issn            = {15737543},
  journal         = {Cluster Computing},
  keywords        = {Convolutional neural network,Deep{\_}Learning,GPGPU,GPU,Mini-batch,Multi-GPU,Multi{\_}GPU},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Deep{\_}Learning,GPU,Multi{\_}GPU},
  pages           = {1--12},
  title           = {{Comprehensive techniques of multi-GPU memory optimization for deep learning acceleration}},
  year            = {2019}
}
@inproceedings{Klenk2017,
  abstract        = {Accelerators, such as GPUs, have proven to be highly successful in reducing execution time and power consumption of compute-intensive applications. Even though they are already used pervasively, they are typically supervised by general-purpose CPUs, which results in frequent control flow switches and data transfers as CPUs are handling all communication tasks. However, we observe that accelerators are recently being augmented with peer-to-peer communication capabilities that allow for autonomous traffic sourcing and sinking. While appropriate hardware support is becoming available, it seems that the right communication semantics are yet to be identified. Maintaining the semantics of existing communication models, such as the Message Passing Interface (MPI), seems problematic as they have been designed for the CPU's execution model, which inherently differs from such specialized processors. In this paper, we analyze the compatibility of traditional message passing with massively parallel Single Instruction Multiple Thread (SIMT) architectures, as represented by GPUs, and focus on the message matching problem. We begin with a fully MPI-compliant set of guarantees, including tag and source wildcards and message ordering. Based on an analysis of exascale proxy applications, we start relaxing these guarantees to adapt message passing to the GPU's execution model. We present suitable algorithms for message matching on GPUs that can yield matching rates of 60M and 500M matches/s, depending on the constraints that are being relaxed. We discuss our experiments and create an understanding of the mismatch of current message passing protocols and the architecture and execution model of SIMT processors.},
  author          = {Klenk, Benjamin and Froening, Holger and Eberle, Hans and Dennison, Larry},
  booktitle       = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi             = {10.1109/IPDPS.2017.94},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/Relaxations for High-Performance Message Passing on Massively Parallel SIMT Processors - Klenk et al. - Proceed.pdf:pdf},
  isbn            = {9781538639146},
  keywords        = {Communication Models,GPU,GPU Computing,Heterogeneous systems,Message Passing,Message{\_}Matching},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {GPU,Message{\_}Matching},
  pages           = {855--865},
  title           = {{Relaxations for High-Performance Message Passing on Massively Parallel SIMT Processors}},
  year            = {2017}
}
@inproceedings{Kousha2021,
  abstract      = {Understanding the full-stack performance trade-offs and interplay among HPC applications, MPI libraries, the communication fabric, and the job scheduler is a challenging endeavor. Unfortunately, existing profiling tools are disjoint and only focus on profiling one or a few levels of the HPC stack limiting the insights they can provide. In this paper, we propose a standardized approach to facilitate near real-time, low overhead performance characterization, profiling, and evaluation of communication of high-performance communication middleware as well as scientific applications using a cross-stack approach by INAM the profiling capabilities are supported in two modes of with and without modifications to the application depending on the scope of the profiling session. We design and implement our designs using an MPI{\_}T-based standardized method to obtain near real-time insights for MPI applications at scales of up to 4,096 processes with less than 5{\%} overhead. Through experimental evaluations of increasing batch size for DL training, we demonstrate novel benefits of INAM for cross-stack communication analysis in real-time to detect bottlenecks and resolve them, achieving up to 3.6x improvements for the use-case study the proposed solutions have been publicly released with the latest version of INAM and currently being used in production at various HPC supercomputers.},
  author        = {Kousha, Pouya and {Sankarapandian Dayala Ganesh Ram}, Kamal Raj and Kedia, Mansa and Subramoni, Hari and Jain, Arpan and Shafi, Aamir and Panda, Dhabaleswar and Dockendorf, Trey and Na, Heechang and Tomko, Karen},
  booktitle     = {Proceedings of Practice and Experience in Advanced Research Computing (PEARC)},
  doi           = {10.1145/3437359.3465582},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of Practice and Experience in Advanced Research Computing (PEARC)/INAM Cross-stack Profiling and Analysis of Communication in MPI-based Applications - Kousha et al. - Proceedings of Practice.pdf:pdf},
  keywords      = {MPI,Profile},
  mendeley-tags = {MPI,Profile},
  pages         = {1--11},
  title         = {{INAM: Cross-stack Profiling and Analysis of Communication in MPI-based Applications}},
  year          = {2021}
}
@techreport{Kraus2018,
  author          = {Kraus, Jiri},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Unknown/Multi-GPU Programming - Kraus - Unknown.pdf:pdf},
  keywords        = {CUDA,GPU,Multi{\_}GPU},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {CUDA,GPU,Multi{\_}GPU},
  title           = {{Multi-GPU Programming}},
  year            = {2018}
}
@techreport{Kraus2021,
  author          = {Kraus, Jiri},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Unknown/Multi-GPU Programming Models - Kraus - Unknown.pdf:pdf},
  keywords        = {CUDA,GPU,GTC,Multi{\_}GPU},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {CUDA,GPU,Multi{\_}GPU},
  title           = {{Multi-GPU Programming Models}},
  url             = {https://github.com/NVIDIA/multi-gpu-programming-models},
  year            = {2021}
}
@article{Krishnan2020,
  abstract        = {Modern FPGAs are more than just 'gate arrays'-they offer hardware acceleration capabilities and advanced features that include High Bandwidth Memory (HBM), Cache/Memory coherent/IO interconnect (CXL/PCIe), high speed transceivers, and embedded processors. Unfortunately, lack of a standardized hardware/software infrastructure has relegated FPGAs to being second-class citizens under the control of a host platform rather than being compute/network accelerator nodes with SmartNIC capabilities. This stands in the way of broader deployment of FPGAs in a wide variety of distributed/heterogenous platforms.Intel's COnfigurable Network Protocol Accelerator (COPA) addresses this challenge and provides a customizable framework that integrates communication with computation on an FPGA platform. The FPGA incorporates SmartNIC capabilities and functions as an 'autonomous' node that attaches to the network. In this paper, we provide an overview of COPA architecture and the acceleration modes that it supports. The hardware component provides the necessary networking/accelerator infrastructure while the software component of COPA abstracts the underlying FPGA from the application or middleware. The API is based on an open standard network API (OFI) that has been extended for COPA to expose the various acceleration modes to software. Given the lack of a standard API for SmartNICs, the extended OFI can also potentially serve that purpose and efforts are underway to upstream the changes.COPA has been implemented on different variants of Stratix10 FPGAs. Multiple COPA FPGAs can autonomously connect to a standard 100GigE switching network with the ability to mix-and-match FPGA variants to this network. Both inline and lookaside accelerator functions are also supported. The framework has been validated by microbenchmarks as well as proxy benchmarks that mimic the behavior of client/server flows-and achieves bandwidths close to 100Gbps when acceleration is enabled.},
  author          = {Krishnan, Venkata and Serres, Olivier and Blocksome, Michael},
  doi             = {10.1109/HOTI51249.2020.00018},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)/Configurable network protocol accelerator (COPA) An integrated networkingaccelerator hardwaresoftware framework - Krishnan, Serr.pdf:pdf},
  isbn            = {9781728195896},
  issn            = {15504794},
  journal         = {Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)},
  mendeley-groups = {ELEC-878},
  pages           = {17--24},
  title           = {{Configurable network protocol accelerator (COPA): An integrated networking/accelerator hardware/software framework}},
  volume          = {2020-Augus},
  year            = {2020}
}
@inproceedings{Kumar2016,
  abstract      = {We present scalability and performance enhancements to MPI libraries on POWER8 InfiniBand clusters. We explore optimizations in the Parallel Active Messaging Interface (PAMI) libraries. We bypass IB VERBS via low level inline calls resulting in low latencies and high message rates. MPI is enabled on POWER8 by extension of both MPICH and Open MPI to call PAMI libraries. The IBM POWER8 nodes have GPU accelerators to optimize floating throughput of the node. We explore optimized algorithms for GPU-to-GPU communication with minimal processor involvement. We achieve a peak MPI message rate of 186 million messages per second. We also present scalable performance in the QBOX and AMG applications.},
  author        = {Kumar, Sameer and Mamidala, Amith and Blackmore, Robert and Sharkawi, Sameh and {Nysal Jan}, K. A. and Ward, T. J.Chris},
  booktitle     = {ACM International Conference Proceeding Series},
  doi           = {10.1145/2966884.2966909},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/ACM International Conference Proceeding Series/Optimization of message passing services on POWER8 infiniband clusters - Kumar et al. - ACM International Conference Proceeding Series.pdf:pdf},
  isbn          = {9781450342346},
  keywords      = {GPU direct,InfiniBand,InfiniBand VERBS,MPI,MPI point-to-point communication,P2P,PAMI},
  mendeley-tags = {InfiniBand,MPI,P2P},
  pages         = {158--166},
  title         = {{Optimization of message passing services on POWER8 infiniband clusters}},
  year          = {2016}
}
@article{Laguna2019,
  abstract        = {Understanding the state-of-the-practice in MPI usage is paramount for many aspects of supercomputing, including optimizing the communication of HPC applications and informing standardization bodies and HPC systems procurements regarding the most important MPI features. Unfortunately, no previous study has characterized the use of MPI on applications at a significant scale; previous surveys focus either on small data samples or on MPI jobs of specific HPC centers. This paper presents the first comprehensive study of MPI usage in applications. We survey more than one hundred distinct MPI programs covering a significantly large space of the population of MPI applications. We focus on understanding the characteristics of MPI usage with respect to the most used features, code complexity, and programming models and languages. Our study corroborates certain findings previously reported on smaller data samples and presents a number of interesting, previously un-reported insights.},
  author          = {Laguna, Ignacio and Marshall, Ryan and Mohror, Kathryn and Ruefenacht, Martin and Skjellum, Anthony and Sultana, Nawrin},
  doi             = {10.1145/3295500.3356176},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/A large-scale study of MPI usage in open-source HPC applications - Laguna et al. - Procee.pdf:pdf},
  isbn            = {9781450362290},
  issn            = {21674337},
  journal         = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  keywords        = {Applications survey,MPI,Program analysis,Survey},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {MPI,Survey},
  pages           = {1--14},
  title           = {{A large-scale study of MPI usage in open-source HPC applications}},
  year            = {2019}
}
@techreport{Langer2023,
  author          = {Langer, Akhil and Howell, Seth and Dinan, Jim and Spring, Nvidia G T C},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/Unknown/How to Streamline Shared Memory Space With the NVSHMEM Communication Library CPU-INITIATED COMMUICATION - Langer et al. - Unknown.pdf:pdf},
  mendeley-groups = {Presentations {\&} Reports},
  title           = {{How to Streamline Shared Memory Space With the NVSHMEM Communication Library CPU-INITIATED COMMUICATION}},
  year            = {2023}
}
@inproceedings{Lebeane2017,
  author          = {Lebeane, Michael and Benton, Brad and Breternitz, Mauricio and Reinhardt, Steven K and John, Lizy K},
  booktitle       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi             = {10.1145/3126908.3126950},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/GPU Triggered Networking for Intra-Kernel Communications - Lebeane et al. - Proceedings o.pdf:pdf},
  keywords        = {","-  Computer systems organization  -{\textgreater}  Heterogeneo,-  Hardware  -{\textgreater}  Networking hardware,GPU,Network,acm reference format,brad benton,gpus,khaled hamidouche,mauricio breternitz,michael lebeane,nic hardware,rdma networks},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,Network},
  pages           = {1--12},
  title           = {{GPU Triggered Networking for Intra-Kernel Communications}},
  year            = {2017}
}
@inproceedings{LeBeane2018,
  abstract      = {Current state-of-the-art in GPU networking advocates a host centric model that reduces performance and increases code complexity. Recently, researchers have explored several techniques for networking within a GPU kernel itself. These approaches, however, suffer from high latency, waste energy on the host, and are not scalable with larger/more GPUs on a node. In this work, we introduce Command Processor Networking (ComP-Net), which leverages the availability of scalar cores integrated on the GPU itself to provide high performance intra-kernel networking. ComP-Net enables efficient synchronization between the Command Processors and Compute Units on the GPU through a line locking scheme implemented in the GPU's shared last-level cache. We illustrate that ComP-Net can improve application performance by up to 20{\%} and provide up to 50{\%} reduction in energy consumption vs. competing networking techniques across a Jacobi stencil, all reduce collective, and machine learning applications.},
  author        = {LeBeane, Michael and Hamidouche, Khaled and Benton, Brad and Breternitz, Mauricio and Reinhardt, Steven K. and John, Lizy K.},
  booktitle     = {Proceedings of the International Conference on Parallel Architectures and Compilation Techniques (PACT)},
  doi           = {10.1145/3243176.3243179},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the International Conference on Parallel Architectures and Compilation Techniques (PACT)/ComP-Net Command Processor Networking for Efficient Intra-kernel Communications on GPUs - LeBeane e.pdf:pdf},
  isbn          = {9781450359863},
  issn          = {1089795X},
  keywords      = {GPU,GPUs,Programming Models,RDMA,RDMA networks},
  mendeley-tags = {GPU,RDMA},
  pages         = {1--13},
  title         = {{ComP-Net: Command Processor Networking for Efficient Intra-kernel Communications on GPUs}},
  year          = {2018}
}
@article{Lessley2020,
  abstract      = {Hash tables are a fundamental data structure for effectively storing and accessing sparse data, with widespread usage in domains ranging from computer graphics to machine learning. This study surveys the state-of-the-art research on data-parallel hashing techniques for emerging massively-parallel, many-core GPU architectures. This survey identifies key factors affecting the performance of different techniques and suggests directions for further research.},
  author        = {Lessley, Brenton and Childs, Hank},
  doi           = {10.1109/TPDS.2019.2929768},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/IEEE Transactions on Parallel and Distributed Systems/Data-Parallel Hashing Techniques for GPU Architectures - Lessley, Childs - IEEE Transactions on Parallel and Distributed Systems.pdf:pdf},
  issn          = {15582183},
  journal       = {IEEE Transactions on Parallel and Distributed Systems},
  keywords      = {GPU,Graphics processors,Hash{\_}Table,hash tables,parallel algorithms,search problems},
  mendeley-tags = {GPU,Hash{\_}Table},
  number        = {1},
  pages         = {237--250},
  publisher     = {IEEE},
  title         = {{Data-Parallel Hashing Techniques for GPU Architectures}},
  volume        = {31},
  year          = {2020}
}
@article{Levy2019,
  abstract        = {Attaining high performance with MPI applications requires efficient message matching to minimize message processing overheads and the latency these overheads introduce into application communication. In this paper, we use a validated simulation-based approach to examine the relationship between MPI message matching performance and application time-to-solution. Specifically, we examine how the performance of several important HPC workloads is affected by the time required for matching. Our analysis yields several important contributions: (i) the performance of current workloads is unlikely to be significantly affected by MPI matching unless match queue operations get much slower or match queues get much longer; (ii) match queue designs that provide sublinear performance as a function of queue length are unlikely to yield much benefit unless match queue lengths increase dramatically; and (iii) we provide guidance on how long the mean time per match attempt may be without significantly affecting application performance. The results and analysis in this paper provide valuable guidance on the design and development of MPI message match queues.},
  author          = {Levy, Scott and Ferreira, Kurt B. and Schonbein, Whit and Grant, Ryan E. and Dosanjh, Matthew G.F.},
  doi             = {10.1016/j.parco.2019.02.008},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Parallel Computing/Using simulation to examine the effect of MPI message matching costs on application performance - Levy et al. - Parallel Computing.pdf:pdf},
  isbn            = {9781450364928},
  issn            = {01678191},
  journal         = {Parallel Computing},
  keywords        = {MPI,Message passing interface,Message processing,Message{\_}Matching,Multithreading,Performance},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Message{\_}Matching},
  pages           = {63--74},
  title           = {{Using simulation to examine the effect of MPI message matching costs on application performance}},
  volume          = {84},
  year            = {2019}
}
@article{Li2020,
  abstract        = {High performance multi-GPU computing becomes an inevitable trend due to the ever-increasing demand on computation capability in emerging domains such as deep learning, big data and planet-scale simulations. However, the lack of deep understanding on how modern GPUs can be connected and the real impact of state-of-the-art interconnect technology on multi-GPU application performance become a hurdle. In this paper, we fill the gap by conducting a thorough evaluation on five latest types of modern GPU interconnects: PCIe, NVLink-V1, NVLink-V2, NVLink-SLI and NVSwitch, from six high-end servers and HPC platforms: NVIDIA P100-DGX-1, V100-DGX-1, DGX-2, OLCF's SummitDev and Summit supercomputers, as well as an SLI-linked system with two NVIDIA Turing RTX-2080 GPUs. Based on the empirical evaluation, we have observed four new types of GPU communication network NUMA effects: three are triggered by NVLink's topology, connectivity and routing, while one is caused by PCIe chipset design issue. These observations indicate that, for an application running in a multi-GPU node, choosing the right GPU combination can impose considerable impact on GPU communication efficiency, as well as the application's overall performance. Our evaluation can be leveraged in building practical multi-GPU performance models, which are vital for GPU task allocation, scheduling and migration in a shared environment (e.g., AI cloud and HPC centers), as well as communication-oriented performance tuning.},
  author          = {Li, Ang and Song, Shuaiwen Leon and Chen, Jieyang and Li, Jiajia and Liu, Xu and Tallent, Nathan R. and Barker, Kevin},
  doi             = {10.1109/TPDS.2019.2928289},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/IEEE Transactions on Parallel and Distributed Systems/Evaluating Modern GPU Interconnect PCIe, NVLink, NV-SLI, NVSwitch and GPUDirect - Li et al. - IEEE Transactions on Parallel and Distribu.pdf:pdf},
  issn            = {15582183},
  journal         = {IEEE Transactions on Parallel and Distributed Systems},
  keywords        = {GPU,GPUDirect,GPUDirect{\_}RDMA,Interconnect,NCCL,NUMA,NVLink,NVSwitch,PCI{\_}E,PCIe,Performance evaluation,RDMA,SLI,interconnect},
  mendeley-groups = {MustKnow,UsedInComp1,UsedInComp2},
  mendeley-tags   = {GPU,GPUDirect{\_}RDMA,Interconnect,NUMA,NVLink,NVSwitch,PCI{\_}E},
  number          = {1},
  pages           = {94--110},
  title           = {{Evaluating Modern GPU Interconnect: PCIe, NVLink, NV-SLI, NVSwitch and GPUDirect}},
  volume          = {31},
  year            = {2020}
}
@inproceedings{Li2018,
  abstract      = {High performance multi-GPU computing becomes an inevitable trend due to the ever-increasing demand on computation capability in emerging domains such as deep learning, big data and planet-scale applications. However, the lack of deep understanding on how modern GPUs can be connected and the actual impact of state-of-the-art interconnect on multiGPU application performance becomes a hurdle. Additionally, the absence of a practical multi-GPU benchmark suite poses further obstacles for conducting research in multi-GPU era. In this paper, we fill the gap by proposing a multi-GPU benchmark suite named Tartan, which contains microbenchmarks, scale-up and scale-out applications. We then apply Tartan to evaluate the four latest types of modern GPU interconnects, i.e., PCI-e, NVLink-V1, NVLink-V2 and InfiniBand with GPUDirect-RDMA from two recently released NVIDIA super AI platforms as well as ORNL's exascale prototype system. Based on empirical evaluation, we observe four new types of NUMA effects: three types are triggered by NVLink's topology, connectivity and routing, while one type is caused by PCI-e (i.e., anti-locality). They are very important for performance tuning in multi-GPU environment. Our evaluation results show that, unless the current CPU-GPU master-slave programming model can be replaced, it is difficult for scale-up multi-GPU applications to really benefit from faster intra-node interconnects such as NVLinks; while for inter-node scale-out applications, although interconnect is more crucial to the overall performance, GPUDirect-RDMA appears to be not always the optimal choice. The Tartan benchmark suite including the microbenchmarks are opensource and available athttp://github.com/uuudown/Tartan.},
  author        = {Li, Ang and Song, Shuaiwen Leon and Chen, Jieyang and Liu, Xu and Tallent, Nathan and Barker, Kevin},
  booktitle     = {Proceedings of the IEEE International Symposium on Workload Characterization (IISWC)},
  doi           = {10.1109/IISWC.2018.8573483},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the IEEE International Symposium on Workload Characterization (IISWC)/Tartan Evaluating Modern GPU Interconnect via a Multi-GPU Benchmark Suite - Li et al. - Proceedings of the IEEE Intern.pdf:pdf},
  isbn          = {9781538667804},
  keywords      = {Benchmark,GPU,Interconnect,Multi{\_}GPU},
  mendeley-tags = {Benchmark,GPU,Interconnect,Multi{\_}GPU},
  number        = {i},
  pages         = {191--202},
  publisher     = {IEEE},
  title         = {{Tartan: Evaluating Modern GPU Interconnect via a Multi-GPU Benchmark Suite}},
  year          = {2018}
}
@inproceedings{Li2018a,
  abstract      = {Intel Knights Landing (KNL) and IBM POWER architectures are becoming widely deployed on modern supercomputing systems due to its powerful components. MPI Remote Memory Access (RMA) model that provides one-sided communication semantics has been seen as an attractive approach for developing High-Performance Data Analytics (HPDA) applications such as graph processing with irregular communication characteristics. To take advantage of a large number of hardware threads offered by KNL and POWER, HPDA applications and MPI RMA runtime need to be re-designed to get optimal performance. In this paper, we propose multi-threading and lock-free designs in the MPI runtime as well as Graph500 application on KNL and POWER architectures. At the micro-bench level, our proposed runtime-level designs are able to reduce the latency of uni-directional MPI{\_}Put and MPI{\_}Get by up to 3X compared to IntelMPI and Spectrum MPI. At the application level, with 1,024 processes on 32 KNL nodes, our proposed design could outperform IntelMPI library by 32{\%}. With 512 processes on eight POWER nodes, our proposed design could outperform Spectrum MPI library by 19{\%}. To the best of our knowledge, this is the first paper to design and evaluate MPI RMA-based graph processing applications on KNL and POWER architectures.},
  author        = {Li, Mingzhe and Subramoni, Hari and Lu, Xiaoyi and Panda, Dhabaleswar K.},
  booktitle     = {ACM International Conference Proceeding Series},
  doi           = {10.1145/3236367.3236371},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/ACM International Conference Proceeding Series/Multi-threading and lock-free MPI RMA based graph processing on KNL and power architectures - Li et al. - ACM International Conference P.pdf:pdf},
  isbn          = {9781450364928},
  keywords      = {Graph500,Graph{\_}Processing,HPC,KNL,MPI,MPI RMA,Multithreaded{\_}MPI,POWER,RMA},
  mendeley-tags = {Graph{\_}Processing,MPI,Multithreaded{\_}MPI,RMA},
  pages         = {1--10},
  title         = {{Multi-threading and lock-free MPI RMA based graph processing on KNL and power architectures}},
  year          = {2018}
}
@article{Li2020a,
  abstract      = {Load imbalance pervasively exists in distributed deep learning training systems, either caused by the inherent imbalance in learned tasks or by the system itself. Traditional synchronous Stochastic Gradient Descent (SGD) achieves good accuracy for a wide variety of tasks, but relies on global synchronization to accumulate the gradients at every training step. In this paper, we propose eager-SGD, which relaxes the global synchronization for decentralized accumulation. To implement eager-SGD, we propose to use two partial collectives: solo and majority. With solo allreduce, the faster processes contribute their gradients eagerly without waiting for the slower processes, whereas with majority allreduce, at least half of the participants must contribute gradients before continuing, all without using a central parameter server. We theoretically prove the convergence of the algorithms and describe the partial collectives in detail. Experiments are conducted on a variety of neural networks and datasets. The results on load-imbalanced environments show that eager-SGD achieves 2.64 × speedup (ResNet-50 on ImageNet) over the asynchronous centralized SGD, and achieves 1.29 × speedup (ResNet-50 on ImageNet) and 1.27× speedup (LSTM on UCF101) over the state-of-the-art synchronous decentralized SGDs, without losing accuracy.},
  author        = {Li, Shigang and Ben-Nun, Tal and Girolamo, Salvatore Di and Alistarh, Dan and Hoefler, Torsten},
  doi           = {10.1145/3332466.3374528},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPOPP)/A Taming unbalanced training workloads in deep learning with partial collective operations - Li et al..pdf:pdf},
  isbn          = {9781450368186},
  journal       = {Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPOPP)},
  keywords      = {Collective operations,Deep{\_}Learning,Distributed deep learning,Eager-SGD,PAP,Stochastic gradient descent,Workload imbalance},
  mendeley-tags = {Deep{\_}Learning,PAP},
  pages         = {45--61},
  title         = {{A Taming unbalanced training workloads in deep learning with partial collective operations}},
  year          = {2020}
}
@article{Li2014,
  abstract        = {As the number of cores per node keeps increasing, it becomes increasingly important for MPI to leverage shared memory for intranode communication. This paper investigates the design and optimization of MPI collectives for clusters of NUMA nodes. We develop performance models for collective communication using shared memory and we demonstrate several algorithms for various collectives. Experiments are conducted on both Xeon X5650 and Opteron 6100 InfiniBand clusters. The measurements agree with the model and indicate that different algorithms dominate for short vectors and long vectors. We compare our shared-memory allreduce with several MPI implementations—Open MPI, MPICH2, and MVAPICH2—that utilize system shared memory to facilitate interprocess communication. On a 16-node Xeon cluster and 8-node Opteron cluster, our implementation achieves on geometric average 2.3X and 2.1X speedup over the best MPI implementation, respectively. Our techniques enable an efficient implementation of collective operations on future multi- and manycore systems.},
  author          = {Li, Shigang and Hoefler, Torsten and Hu, Chungjin and Snir, Marc},
  doi             = {10.1007/s10586-014-0361-4},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Cluster Computing/Improved MPI collectives for MPI processes in shared address spaces - Li et al. - Cluster Computing.pdf:pdf},
  issn            = {15737543},
  journal         = {Cluster Computing},
  keywords        = {Collective communication,Collectives,MPI,MPI{\_}Allreduce,Multithreaded{\_}MPI,Multithreading,NUMA,Shared{\_}Memory},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Collectives,MPI,MPI{\_}Allreduce,Multithreaded{\_}MPI,NUMA,Shared{\_}Memory},
  number          = {4},
  pages           = {1139--1155},
  title           = {{Improved MPI collectives for MPI processes in shared address spaces}},
  volume          = {17},
  year            = {2014}
}
@inproceedings{Li2013,
  abstract      = {As the number of cores per node keeps increasing, it becomes increasingly important for MPI to leverage shared memory for intranode communication. This paper investigates the design and optimizations of MPI collectives for clusters of NUMA nodes. We develop performance models for collective communication using shared memory, and we develop several algorithms for various collectives. Experiments are conducted on both Xeon X5650 and Opteron 6100 InfiniBand clusters. The measurements agree with the model and indicate that different algorithms dominate for short vectors and long vectors. We compare our shared-memory allreduce with several traditional MPI implementations - Open MPI, MPICH2, and MVAPICH2 - that utilize system shared memory to facilitate interprocess communication. On a 16-node Xeon cluster and 8-node Opteron cluster, our implementation achieves on average 2.5X and 2.3X speedup over MVAPICH2, respectively. Our techniques enable an efficient implementation of collective operations on future multi- and manycore systems. {\textcopyright} 2013 ACM.},
  author        = {Li, Shigang and Hoefler, Torsten and Snir, Marc},
  booktitle     = {Proceedings of the ACM International Symposium on High-Performance Parallel and Distributed Computing (HPDC)},
  doi           = {10.1145/2462902.2462903},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2013/Proceedings of the ACM International Symposium on High-Performance Parallel and Distributed Computing (HPDC)/NUMA-aware shared-memory collective communication for MPI - Li, Hoefler, Snir - Proceedings of.pdf:pdf},
  isbn          = {9781450319102},
  keywords      = {Collectives,MPI,MPI-allreduce,MPI{\_}Allreduce,Multithreaded{\_}MPI,NUMA,collective communication,multithreading},
  mendeley-tags = {Collectives,MPI,MPI{\_}Allreduce,Multithreaded{\_}MPI,NUMA},
  pages         = {85--96},
  title         = {{NUMA-aware shared-memory collective communication for MPI}},
  year          = {2013}
}
@inproceedings{Li2021,
  abstract      = {The hash table is a fundamental structure that has been implemented on graphics processing units (GPUs) to accelerate a wide range of analytics workloads. Most existing works have focused on static scenarios and occupy large GPU memory to maximize the insertion efficiency. In many cases, data stored in hash tables get updated dynamically, and existing approaches use unnecessarily large memory resources. One na{\"{i}}ve solution is to rebuild a hash table (known as rehashing) whenever it is either filled or mostly empty. However, this approach renders significant overheads for rehashing. In this paper, we propose a novel dynamic cuckoo hash table technique on GPUs, known as DyCuckoo. We devise a resizing strategy for dynamic scenarios without rehashing the entire table that ensures a guaranteed filled factor. The strategy trades search performance with resizing efficiency, and this tradeoff can be configured by users. To further improve efficiency, we propose a 2-in-d cuckoo hashing scheme that ensures a maximum of two lookups for find and delete operations, while retaining similar performance for insertions as a general cuckoo hash. Extensive experiments have validated the proposed design's effectiveness over several state-of-the-art hash table implementations on GPUs. DyCuckoo achieves superior efficiency while enables fine-grained memory control, which is not available in existing GPU hash table approaches.},
  author        = {Li, Yuchen and Zhu, Qiwei and Lyu, Zheng and Huang, Zhongdong and Sun, Jianling},
  booktitle     = {Proceedings of the International Conference on Data Engineering (ICDE)},
  doi           = {10.1109/ICDE51399.2021.00070},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the International Conference on Data Engineering (ICDE)/DyCuckoo Dynamic hash tables on GPUs - Li et al. - Proceedings of the International Conference on Data Engineering (ICDE).pdf:pdf},
  isbn          = {9781728191843},
  issn          = {10844627},
  keywords      = {GPU,Hash{\_}Table},
  mendeley-tags = {GPU,Hash{\_}Table},
  pages         = {744--755},
  publisher     = {IEEE},
  title         = {{DyCuckoo: Dynamic hash tables on GPUs}},
  year          = {2021}
}
@article{Li2022,
  author          = {Li, Yuke and Qi, Hao and Lu, Gang and Jin, Feng and Guo, Yanfei and Lu, Xiaoyi},
  doi             = {10.1016/j.tbench.2022.100074},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/BenchCouncil Transactions on Benchmarks, Standards and Evaluations/Understanding hot interconnects with an extensive benchmark survey - Li et al. - BenchCouncil Transactions on Benchmarks, Standards and.pdf:pdf},
  issn            = {27724859},
  journal         = {BenchCouncil Transactions on Benchmarks, Standards and Evaluations},
  keywords        = {Benchmark,Interconnect,Survey},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Benchmark,Interconnect,Survey},
  pages           = {1--13},
  publisher       = {Elsevier B.V.},
  title           = {{Understanding hot interconnects with an extensive benchmark survey}},
  year            = {2022}
}
@article{Li2020b,
  abstract      = {Nowadays, GPUs have achieved high throughput computing by running plenty of threads. However, owing to disjoint memory spaces of discrete CPU-GPU systems, exploiting CPU and GPU within a data processing pipeline is a non-trivial issue, which can only be resolved by the coarse-grained workflow of 'copy-kernel-copy' or its variants in essence. There is an underlying bottleneck caused by frequent inter-processor invocations for fine-grained batch sizes. This article presents XeFlow that enables streamlined execution by leveraging hardware mechanisms inside new generation GPUs. XeFlow significantly reduces costly explicit copy and kernel launching within existing fashions. As an alternative, XeFlow introduces persistent operators that continuously process data through shared topics, which establish efficient inter-processor data channels via hardware page faults. Compared with the default 'copy-kernel-copy' method, XeFlow shows up to 2.4times sim 3.1times2.4×∼3.1× performance advantages in both coarse-grained and fine-grained pipeline execution. To demonstrate its potentials, this article also evaluates two GPU-accelerated applications, including data encoding and OLAP query.},
  author        = {Li, Zhifang and Peng, Beicheng and Weng, Chuliang},
  doi           = {10.1109/TC.2020.2968302},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/IEEE Transactions on Computers/XeFlow Streamlining Inter-Processor Pipeline Execution for the Discrete CPU-GPU Platform - Li, Peng, Weng - IEEE Transactions on Compute.pdf:pdf},
  issn          = {15579956},
  journal       = {IEEE Transactions on Computers},
  keywords      = {CPU-GPU programming,GPU,GPU scheduling,Multi{\_}GPU,heterogeneous memory system},
  mendeley-tags = {GPU,Multi{\_}GPU},
  pages         = {819--831},
  publisher     = {IEEE},
  title         = {{XeFlow: Streamlining Inter-Processor Pipeline Execution for the Discrete CPU-GPU Platform}},
  year          = {2020}
}
@inproceedings{Lian2022,
  abstract        = {For data isolated islands and privacy issues, federated learning has been extensively invoking much interest since it allows clients to collaborate on training a global model using their local data without sharing any with a third party. However, the existing federated learning frameworks always need sophisticated condition configurations (e.g., sophisticated driver configuration of standalone graphics card like NVIDIA, compile environment) that bring much inconvenience for large-scale development and deployment. To facilitate the deployment of federated learning and the implementation of related applications, we innovatively propose WebFed, a novel browser-based federated learning framework that takes advantage of the browser's features (e.g., Cross-platform, JavaScript Programming Features) and enhances the privacy protection by applying local differential privacy. Finally, We conduct experiments on heterogeneous devices to evaluate the performance of the proposed WebFed framework.},
  archiveprefix   = {arXiv},
  arxivid         = {2110.11646},
  author          = {Lian, Zhuotao and Yang, Qinglin and Zeng, Qingkui and Su, Chunhua},
  booktitle       = {IEEE International Conference on Communications},
  doi             = {10.1109/ICC45855.2022.9838421},
  eprint          = {2110.11646},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/IEEE International Conference on Communications/WebFed Cross-platform Federated Learning Framework Based on Web Browser with Local Differential Privacy - Lian et al. - IEEE Internation.pdf:pdf},
  isbn            = {9781538683477},
  issn            = {15503607},
  keywords        = {TensorFlow.js,distributed machine learning,federated learning,local differential privacy,web browser},
  mendeley-groups = {Web},
  pages           = {2071--2076},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  title           = {{WebFed: Cross-platform Federated Learning Framework Based on Web Browser with Local Differential Privacy}},
  volume          = {2022-May},
  year            = {2022}
}
@inproceedings{Lin2021,
  abstract        = {Recently, CUDA introduces a new task graph programming model, CUDA graph, to enable efficient launch and execution of GPU work. Users describe a GPU workload in a task graph rather than aggregated GPU operations, allowing the CUDA runtime to perform whole-graph optimization and significantly reduce the kernel call overheads. However, programming CUDA graphs is extremely challenging. Users need to explicitly construct a graph with verbose parameter settings or implicitly capture a graph that requires complex dependency and concurrency managements using streams and events. To overcome this challenge, we introduce a lightweight task graph programming framework to enable efficient GPU computation using CUDA graph. Users can focus on high-level development of dependent GPU operations, while leaving all the intricate managements of stream concurrency and event dependency to our optimization algorithm. We have evaluated our framework and demonstrated its promising performance on both micro-benchmarks and a large-scale machine learning workload. The result also shows that our optimization algorithm achieves very comparable performance to an optimally-constructed graph and consumes much less GPU resource.},
  author          = {Lin, Dian Lun and Huang, Tsung Wei},
  booktitle       = {Proceedings of the European Conference on Parallel Processing (Euro-Par)},
  doi             = {10.1007/978-3-030-85665-6_27},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the European Conference on Parallel Processing (Euro-Par)/Efficient GPU Computation Using Task Graph Parallelism - Lin, Huang - Proceedings of the European Conference on Parallel Processin.pdf:pdf},
  isbn            = {9783030856649},
  issn            = {16113349},
  keywords        = {CUDA,CUDA{\_}Graphs,GPU},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {CUDA,CUDA{\_}Graphs,GPU},
  pages           = {435--450},
  publisher       = {Springer International Publishing},
  title           = {{Efficient GPU Computation Using Task Graph Parallelism}},
  year            = {2021}
}
@article{Liu2021,
  abstract        = {High-performance computing (HPC) researchers have long envisioned scenarios where application workflows could be improved through the use of programmable processing elements embedded in the network fabric. Recently, vendors have introduced programmable Smart Network Interface Cards (SmartNICs) that enable computations to be offloaded to the edge of the network. There is great interest in both the HPC and high-performance data analytics communities in understanding the roles these devices may play in the data paths of upcoming systems. This paper focuses on characterizing both the networking and computing aspects of NVIDIA's new BlueField-2 SmartNIC when used in an Ethernet environment. For the networking evaluation we conducted multiple transfer experiments between processors located at the host, the SmartNIC, and a remote host. These tests illuminate how much processing headroom is available on the SmartNIC during transfers. For the computing evaluation we used the stress-ng benchmark to compare the BlueField-2 to other servers and place realistic bounds on the types of offload operations that are appropriate for the hardware. Our findings from this work indicate that while the BlueField-2 provides a flexible means of processing data at the network's edge, great care must be taken to not overwhelm the hardware. While the host can easily saturate the network link, the SmartNIC's embedded processors may not have enough computing resources to sustain more than half the expected bandwidth when using kernel-space packet processing. From a computational perspective, encryption operations, memory operations under contention, and on-card IPC operations on the SmartNIC perform significantly better than the general-purpose servers used for comparisons in our experiments. Therefore, applications that mainly focus on these operations may be good candidates for offloading to the SmartNIC.},
  archiveprefix   = {arXiv},
  arxivid         = {2105.06619},
  author          = {Liu, Jianshen and Maltzahn, Carlos and Ulmer, Craig and Curry, Matthew Leon},
  eprint          = {2105.06619},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Unknown/Performance Characteristics of the BlueField-2 SmartNIC - Liu et al. - Unknown.pdf:pdf},
  mendeley-groups = {ELEC-878},
  title           = {{Performance Characteristics of the BlueField-2 SmartNIC}},
  url             = {http://arxiv.org/abs/2105.06619},
  year            = {2021}
}
@inproceedings{Liu2022,
  author        = {Liu, Ting and Miao, Tianhao and Wu, Qinghua and Li, Zhenyu and He, Guangxin and Wu, Jiaoren and Zhang, Shengzhuo and Yang, Xingwu and Tyson, Gareth and Xie, Gaogang},
  booktitle     = {Proceedings of the ACM Web Conference (WWW)},
  doi           = {10.1145/3485447.3511981},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the ACM Web Conference (WWW)/Modeling and Optimizing the Scaling Performance in Distributed Deep Learning Training - Liu et al. - Proceedings of the ACM Web Conferen.pdf:pdf},
  isbn          = {9781450390965},
  keywords      = {Deep{\_}Learning,Modeling,acm reference format,distributed deep learning,eling,performance mod-,scaling performance,tensor fusion},
  mendeley-tags = {Deep{\_}Learning,Modeling},
  pages         = {1--10},
  title         = {{Modeling and Optimizing the Scaling Performance in Distributed Deep Learning Training}},
  year          = {2022}
}
@article{Lo2022,
  abstract      = {Federated learning is an emerging machine learning paradigm where clients train models locally and formulate a global model based on the local model updates. To identify the state-of-the-art in federated learning and explore how to develop federated learning systems, we perform a systematic literature review from a software engineering perspective, based on 231 primary studies. Our data synthesis covers the lifecycle of federated learning system development that includes background understanding, requirement analysis, architecture design, implementation, and evaluation. We highlight and summarise the findings from the results and identify future trends to encourage researchers to advance their current work.},
  author        = {Lo, Sin Kit and Lu, Qinghua and Wang, Chen and Paik, Hye-Young and Zhu, Liming},
  doi           = {10.1145/3450288},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/ACM Computing Surveys/A Systematic Literature Review on Federated Machine Learning - Lo et al. - ACM Computing Surveys.pdf:pdf},
  issn          = {0360-0300},
  journal       = {ACM Computing Surveys},
  keywords      = {Deep{\_}Learning,Edge{\_}Computing,Survey,artificial intelligence,distributed,edge intelligence,fog intelligence,machine learning},
  mendeley-tags = {Deep{\_}Learning,Edge{\_}Computing,Survey},
  pages         = {1--39},
  title         = {{A Systematic Literature Review on Federated Machine Learning}},
  year          = {2022}
}
@inproceedings{Loch2021,
  abstract        = {The collective operations are considered critical for improving the performance of exascale-ready and highperformance computing applications. On this paper we focus on the Message-Passing Interface (MPI) Allgather many to many collective, which is amongst the most called and time-consuming operations. Each MPI algorithm for this call suffers from different operational and performance limitations, that might include only working for restricted cases, requiring linear amounts of communication steps with the growth in number of processes, memory copies and shifts to assure correct data organization, and non-local data exchange patterns, most of which negatively contribute to the total operation time. All these characteristics create an environment where there is no algorithm which is the best for all cases and this consequently implies that careful choices of alternatives must be made to execute the call. Considering such aspects, we propose the Stripe Parallel Binomial Trees (Sparbit) algorithm, which has optimal latency and bandwidth time costs with no usage restrictions. It also maintains a much more local communication pattern that minimizes the delays due to long range exchanges, allowing the extraction of more performance from current systems when compared with asymptotically equivalent alternatives. On its best scenario, Sparbit surpassed the traditional MPI algorithms on 46.43{\%} of test cases with mean (median) improvements of 34.7{\%} (26.16{\%}) and highest reaching 84.16{\%}.},
  archiveprefix   = {arXiv},
  arxivid         = {2109.08751},
  author          = {Loch, Wilton Jaciel and Koslovski, Guilherme Piegas},
  booktitle       = {Proceedings of the International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)},
  doi             = {10.1109/SBAC-PAD53543.2021.00028},
  eprint          = {2109.08751},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)/Sparbit A new logarithmic-cost and data locality-aware MPI Allgather algorithm - Loch, Koslov.pdf:pdf},
  isbn            = {9781665443012},
  issn            = {15506533},
  keywords        = {Allgather,Collective Algorithms,Collective Communication,Collectives,MPI,Message-Passing},
  mendeley-groups = {Auto-Tuning},
  mendeley-tags   = {Collectives,MPI},
  pages           = {167--176},
  title           = {{Sparbit: A new logarithmic-cost and data locality-aware MPI Allgather algorithm}},
  year            = {2021}
}
@inproceedings{Lu2015,
  abstract        = {As the core density of future processors keeps increasing, MPI+Threads is becoming a promising programming model for large scale SMP clusters. Generally speaking, hybrid MPI+Threads runtime can largely improve intra-node parallelism and data sharing on shared-memory architectures. However, it does not help much on inter-node communication due to the inefficient integration of existing communication and threading libraries. More specifically, existing MPI+Threads runtime systems use coarse-grained locks to protect their thread safety, which leads to heavy lock contention and limit the scalability of the runtime. While kernel threads are efficient for intra-node parallelism, we found that they are too heavy for computation/communication overlap in an MPI+Threads runtime system. In this paper we propose a new way for asynchronous MPI communication with user-level threads (MPI+ULT). By enabling ULT context switching inside MPI, MPI communication in one ULT can overlap with computation or communication in other ULTs. MPI+ULT can be used for communication hiding in various scenarios, including MPI point-to-point, collective and one-sided calls. We use MPI+ULT in two applications, a high-performance conjugate gradient benchmark and a genome assembly application, to show how MPI+ULT can help effectively hide communication and reduce runtime overhead. Experiments show that our method helps improve the performance of these applications significantly.},
  author          = {Lu, Huiwei and Seo, Sangmin and Balaji, Pavan},
  booktitle       = {Proceedings of the IEEE International Conference on High Performance Computing and Communications (HPCC)},
  doi             = {10.1109/HPCC-CSS-ICESS.2015.82},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Proceedings of the IEEE International Conference on High Performance Computing and Communications (HPCC)/MPIULT Overlapping communication and computation with user-level threads - Lu, Seo, Balaji - Proce.pdf:pdf},
  isbn            = {9781479989362},
  keywords        = {MPI,MPI+X,Message Passing Interface,Multithreaded{\_}MPI,Overlapping Communication and Computation,User-Level Thread},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Multithreaded{\_}MPI},
  pages           = {444--454},
  title           = {{MPI+ULT: Overlapping communication and computation with user-level threads}},
  year            = {2015}
}
@inproceedings{Lu2017,
  abstract      = {Deep Learning over Big Data (DLoBD) is becoming one of the most important research paradigms to mine value from the massive amount of gathered data. Many emerging deep learning frameworks start running over Big Data stacks, such as Hadoop and Spark. With the convergence of HPC, Big Data, and Deep Learning, these DLoBD stacks are taking advantage of RDMA and multi-/many-core based CPUs/GPUS. Even though a lot of activities are happening in the field, there is a lack of systematic studies on analyzing the impact of RDMA-capable networks and CPU/GPU on DLoBD stacks. To fill this gap, we propose a systematical characterization methodology and conduct extensive performance evaluations on three representative DLoBD stacks (i.e., CaffeOnSpark, TensorFlowOnSpark, and BigDL) to expose the interesting trends regarding performance, scalability, accuracy, and resource utilization. Our observations show that RDMA-based design for DLoBD stacks can achieve up to 2.7x speedup compared to the IPoIB based scheme. The RDMA scheme can also scale better and utilize resources more efficiently than the IPoIB scheme over InfiniBand clusters. For most cases, GPU-based deep learning can outperform CPU-based designs, but not always. We see that for LeNet on MNIST, CPU + MKL can achieve better performance than GPU and GPU + cuDNN on 16 nodes. Through our evaluation, we see that there are large rooms to improve the designs of current generation DLoBD stacks further.},
  author        = {Lu, Xiaoyi and Shi, Haiyang and Javed, M. Haseeb and Biswas, Rajarshi and Panda, Dhabaleswar K.},
  booktitle     = {Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)},
  doi           = {10.1109/HOTI.2017.24},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)/Characterizing Deep Learning over Big Data (DLoBD) Stacks on RDMA-Capable Networks - Lu et al. - Proceedings of the IEEE Symposi.pdf:pdf},
  isbn          = {9781538610138},
  keywords      = {Big Data,DLoBD,Deep Learning,Deep{\_}Learning,InfiniBand,RDMA},
  mendeley-tags = {Deep{\_}Learning,InfiniBand,RDMA},
  pages         = {87--94},
  title         = {{Characterizing Deep Learning over Big Data (DLoBD) Stacks on RDMA-Capable Networks}},
  year          = {2017}
}
@techreport{Luitjens2014,
  abstract        = {Using streams in CUDA is a fundamental optimization that many programmers overlook. This tutorial will teach you how to use streams in your application and cover the many mistakes that people make when using streams. After attending this talk you will be equipped with the necessary knowledge to use streams within your application. Whether you're a CUDA developer who has never heard of streams or you use them regularly, this talk is for you.},
  author          = {Luitjens, Justin},
  booktitle       = {GPU Technology Conference},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/GPU Technology Conference/CUDA Streams Best Practices and Common Pitfalls - Luitjens - GPU Technology Conference.pdf:pdf},
  keywords        = {CUDA,CUDA{\_}Features,GPU,Performance Optimization,Programming Languages {\&} Compilers,Streams},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {CUDA,CUDA{\_}Features,GPU,Streams},
  title           = {{CUDA Streams: Best Practices and Common Pitfalls}},
  url             = {http://on-demand.gputechconf.com/gtc/2014/presentations/S4158-cuda-streams-best-practices-common-pitfalls.pdf},
  year            = {2014}
}
@inproceedings{Luo2014,
  abstract      = {State-of-the-art MPI libraries rely on locks to guarantee thread-safety. This discourages application developers from using multiple threads to perform MPI operations. In this paper, we propose a high performance, lock-free multiendpoint MPI runtime, which can achieve up to 40{\%} improvement for point-to-point operation and one representative collective operation with minimum or no modifications to the existing applications.},
  author        = {Luo, Miao and Lu, Xiaoyi and Hamidouche, Khaled and Kandalla, Krishna and Panda, Dhabaleswar K.},
  booktitle     = {Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPOPP)},
  doi           = {10.1145/2555243.2555287},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Proceedings of the ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPOPP)/Initial study of multi-endpoint runtime for MPIOpenMP hybrid programming model on multi-core systems -.pdf:pdf},
  isbn          = {9781450326568},
  issn          = {15232867},
  keywords      = {Endpoints,Hybrid{\_}MPI,OpenMP},
  mendeley-tags = {Endpoints,Hybrid{\_}MPI,OpenMP},
  number        = {8},
  pages         = {395--396},
  title         = {{Initial study of multi-endpoint runtime for MPI+OpenMP hybrid programming model on multi-core systems}},
  volume        = {49},
  year          = {2014}
}
@phdthesis{Luo2020,
  author          = {Luo, Xi},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Unknown/TRACE Tennessee Research and Creative Exchange Optimization of MPI Collective Communication Operations - Luo - Unknown.pdf:pdf},
  keywords        = {Collectives,MPI,Thesis},
  mendeley-groups = {MustKnow,Theses},
  mendeley-tags   = {Collectives,MPI,Thesis},
  title           = {{TRACE : Tennessee Research and Creative Exchange Optimization of MPI Collective Communication Operations}},
  year            = {2020}
}
@inproceedings{Lustig2013,
  abstract      = {GPUs are seeing increasingly widespread use for general purpose computation due to their excellent performance for highly-parallel, throughput-oriented applications. For many workloads, however, the performance benefits of offloading are hindered by the large and unpredictable overheads of launching GPU kernels and of transferring data between CPU and GPU. {\textcopyright} 2013 IEEE.},
  author        = {Lustig, Daniel and Martonosi, Margaret},
  booktitle     = {Proceedings of the IEEE International Symposium on High-Performance Computer Architecture (HPCA)},
  doi           = {10.1109/HPCA.2013.6522332},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2013/Proceedings of the IEEE International Symposium on High-Performance Computer Architecture (HPCA)/Reducing GPU offload latency via fine-grained CPU-GPU synchronization - Lustig, Martonosi - Proceedings of.pdf:pdf},
  isbn          = {9781467355858},
  issn          = {15300897},
  keywords      = {GPU},
  mendeley-tags = {GPU},
  pages         = {354--365},
  publisher     = {IEEE},
  title         = {{Reducing GPU offload latency via fine-grained CPU-GPU synchronization}},
  year          = {2013}
}
@inproceedings{Lutz2020,
  abstract        = {GPUs have long been discussed as accelerators for database query processing because of their high processing power and memory bandwidth. However, two main challenges limit the utility of GPUs for large-scale data processing: (1) the on-board memory capacity is too small to store large data sets, yet (2) the interconnect bandwidth to CPU main-memory is insufficient for ad hoc data transfers. As a result, GPU-based systems and algorithms run into a transfer bottleneck and do not scale to large data sets. In practice, CPUs process large-scale data faster than GPUs with current technology. In this paper, we investigate how a fast interconnect can resolve these scalability limitations using the example of NVLink 2.0. NVLink 2.0 is a new interconnect technology that links dedicated GPUs to a CPU. The high bandwidth of NVLink 2.0 enables us to overcome the transfer bottleneck and to efficiently process large data sets stored in main-memory on GPUs. We perform an in-depth analysis of NVLink 2.0 and show how we can scale a no-partitioning hash join beyond the limits of GPU memory. Our evaluation shows speed-ups of up to 18x over PCI-e 3.0 and up to 7.3x over an optimized CPU implementation. Fast GPU interconnects thus enable GPUs to efficiently accelerate query processing.},
  author          = {Lutz, Clemens and Bre{\ss}, Sebastian and Zeuch, Steffen and Rabl, Tilmann and Markl, Volker},
  booktitle       = {Proceedings of the International Conference on Management of Data (SIGMOD)},
  doi             = {10.1145/3318464.3389705},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the International Conference on Management of Data (SIGMOD)/Pump Up the Volume Processing Large Data on GPUs with Fast Interconnects - Lutz et al. - Proceedings of the International Confer.pdf:pdf},
  isbn            = {9781450367356},
  issn            = {07308078},
  keywords        = {GPU,Interconnect,Multi{\_}GPU},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,Interconnect,Multi{\_}GPU},
  pages           = {1633--1649},
  title           = {{Pump Up the Volume: Processing Large Data on GPUs with Fast Interconnects}},
  year            = {2020}
}
@inproceedings{Ma2011,
  abstract      = {Message Passing Interface (MPI) implementations provide a great flexibility to allow users to arbitrarily bind processes to computing cores to fully exploit clusters of multicore/ many-core nodes. An intelligent process placement can optimize application performance according to underlying hardware architecture and the application's communication pattern. However, such static process placement optimization can't help MPI collective communication, whose topology is dynamic with members in each communicator. Conversely, a mismatch between the collective communication topology, the underlying hardware architecture and the process placement often happens due to the MPI's limited capabilities of dealing with complex environments. This paper proposes an adaptive collective communication framework by combining process distance, underlying hardware topologies, and runtime communicator together. Based on this information, an optimal communication topology will be generated to guarantee maximum bandwidth for each MPI collective operation regardless of process placement. Based on this framework, two distance-aware adaptive intra-node collective operations (Broadcast and All gather) are implemented as examples inside Open MPI's KNEM collective component. The awareness of process distance helps these two operations construct optimal runtime topologies and balance memory accesses across memory nodes. The experiments show these two distance-aware collective operations provide better and more stable performance than current collectives in Open MPI regardless of process placement. {\textcopyright} 2011 IEEE.},
  author        = {Ma, Teng and Herault, Thomas and Bosilca, George and Dongarra, Jack J.},
  booktitle     = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi           = {10.1109/CLUSTER.2011.30},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2011/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/Process distance-aware adaptive MPI collective communications - Ma et al. - Proceedings of the IEEE International Conferenc.pdf:pdf},
  isbn          = {9780769545165},
  issn          = {15525244},
  keywords      = {Collective Communication,Collectives,Hierarchical,Hierarchical Algorithm,MPI,Process Distance,Ring Algorithm},
  mendeley-tags = {Collectives,Hierarchical,MPI},
  pages         = {196--204},
  publisher     = {IEEE},
  title         = {{Process distance-aware adaptive MPI collective communications}},
  year          = {2011}
}
@article{Ma2019b,
  abstract        = {X-RDMA is a communication middleware deployed and heavily used in Alibaba's large-scale cluster hosting cloud storage and database systems. Unlike recent research projects which purely focus on squeezing out the raw hardware performance, it puts emphasis on robustness, scalability and maintainability of large-scale production clusters. X-RDMA integrates necessary features, not available in current RDMA ecosystem, to release the developers from complex and imperfect details. X-RDMA simplifies the programming model, extends RDMA protocols for application awareness, and proposes mechanisms for resource management with thousands of connections per machine. It also reduces the work for administration and performance tuning with built-in tracing, tuning and monitoring tools.X-RDMA has been deployed in several large-scale clusters with over 4000 servers in Alibaba cloud since 2016. It can save at least 70{\%} development and maintenance time over RDMA, effectively improve performance and reduce network jitter especially when production servers are under pressure. It also helped locate over 30 issues in different layers of productions with over 5000 connections for each server on average.},
  author          = {Ma, Teng and Ma, Tao and Song, Zhuo and Li, Jingxuan and Chang, Huaixin and Chen, Kang and Jiang, Hai and Wu, Yongwei},
  doi             = {10.1109/CLUSTER.2019.8891004},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/X-RDMA Effective RDMA Middleware in Large-scale Production Environments - Ma et al. - Proceedings of the IEEE International.pdf:pdf},
  isbn            = {9781728147345},
  issn            = {15525244},
  journal         = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  keywords        = {RDMA,large-scale deployment,middleware},
  mendeley-groups = {ELEC-878},
  publisher       = {IEEE},
  title           = {{X-RDMA: Effective RDMA Middleware in Large-scale Production Environments}},
  volume          = {2019-Septe},
  year            = {2019}
}
@inproceedings{Ma2019,
  abstract        = {Recently, several JavaScript-based deep learning frameworks have emerged, making it possible to perform deep learning tasks directly in browsers. However, little is known on what and how well we can do with these frameworks for deep learning in browsers. To bridge the knowledge gap, in this paper, we conduct the first empirical study of deep learning in browsers. We survey 7 most popular JavaScript-based deep learning frameworks, investigating to what extent deep learning tasks have been supported in browsers so far. Then we measure the performance of different frameworks when running different deep learning tasks. Finally, we dig out the performance gap between deep learning in browsers and on native platforms by comparing the performance of TensorFlow.js and TensorFlow in Python. Our findings could help application developers, deep-learning framework vendors and browser vendors to improve the efficiency of deep learning in browsers.},
  archiveprefix   = {arXiv},
  arxivid         = {1901.09388},
  author          = {Ma, Yun and Xiang, Dongwei and Zheng, Shuyu and Tian, Deyu and Liu, Xuanzhe},
  booktitle       = {The Web Conference 2019 - Proceedings of the World Wide Web Conference, WWW 2019},
  doi             = {10.1145/3308558.3313639},
  eprint          = {1901.09388},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/The Web Conference 2019 - Proceedings of the World Wide Web Conference, WWW 2019/Moving deep learning into web browser How far can we go - Ma et al. - The Web Conference 2019 - Proceedings of the World W.pdf:pdf},
  isbn            = {9781450366748},
  keywords        = {Deep learning,Measurement,Web applications,Web browser},
  mendeley-groups = {Web},
  month           = {may},
  pages           = {1234--1244},
  publisher       = {Association for Computing Machinery, Inc},
  title           = {{Moving deep learning into web browser: How far can we go?}},
  year            = {2019}
}
@article{MacArthur2017,
  abstract        = {This tutorial presents the details of the interconnection network utilized in many high performance computing (HPC) systems today. 'InfiniBand' is the hardware interconnect utilized by over 35{\%} of the top 500 supercomputers in the world as of June, 2017. 'Verbs' is the term used for both the semantic description of the interface in the InfiniBand architecture specifications, and the name used for the functions defined in the widely used OpenFabrics alliance implementation of the software interface to InfiniBand. 'Message passing interface' is the primary software library by which HPC applications portably pass messages between processes across a wide range of interconnects including InfiniBand. Our goal is to explain how these three components are designed and how they interact to provide a powerful, efficient interconnect for HPC applications. We provide a succinct look into the inner technical workings of each component that should be instructive to both novices to HPC applications as well as to those who may be familiar with one component, but not necessarily the others, in the design and functioning of the total interconnect. A supercomputer interconnect is not a monolithic structure, and this tutorial aims to give non-experts a 'big-picture' overview of its substructure with an appreciation of how and why features in one component influence those in others. We believe this is one of the first tutorials to discuss these three major components as one integrated whole. In addition, we give detailed examples of practical experience and typical algorithms used within each component in order to give insights into what issues and trade-offs are important.},
  author          = {MacArthur, Patrick and Liu, Qian and Russell, Robert D. and Mizero, Fabrice and Veeraraghavan, Malathi and Dennis, John M.},
  doi             = {10.1109/COMST.2017.2746083},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/IEEE Communications Surveys and Tutorials/An Integrated Tutorial on InfiniBand, Verbs, and MPI - MacArthur et al. - IEEE Communications Surveys and Tutorials.pdf:pdf},
  issn            = {1553877X},
  journal         = {IEEE Communications Surveys and Tutorials},
  keywords        = {Collectives,InfiniBand,MPI,Survey,channel semantics,collective operations,completion handling,congestion control,flow-control,memory semantics,point-to-point operations,verbs,virtual lanes},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,InfiniBand,MPI,Survey},
  number          = {4},
  pages           = {2894--2926},
  title           = {{An Integrated Tutorial on InfiniBand, Verbs, and MPI}},
  volume          = {19},
  year            = {2017}
}
@inproceedings{Maltenberger2022,
  author          = {Maltenberger, Tobias and Ilic, Ivan and Tolovski, Ilin and Rabl, Tilmann},
  booktitle       = {Proceedings of the International Conference on Management of Data (SIGMOD)},
  doi             = {10.1145/3514221.3517842},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the International Conference on Management of Data (SIGMOD)/Evaluating Multi-GPU Sorting with Modern Interconnects - Maltenberger et al. - Proceedings of the International Conference on Ma.pdf:pdf},
  isbn            = {9781450392495},
  keywords        = {2022,GPU,Interconnect,acm reference format,database acceleration,evaluating,high-speed interconnects,ilin tolovski,ivan ilic,multi-gpu sorting,tilmann rabl,tobias maltenberger},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,Interconnect},
  pages           = {1--15},
  title           = {{Evaluating Multi-GPU Sorting with Modern Interconnects}},
  year            = {2022}
}
@inproceedings{Manian2019,
  abstract        = {The CUDA Unified Memory (UM) interface enables a significantly simpler programming paradigm and has the potential to fundamentally change the way programmers write CUDA applications in the future. Although UM leads to high productivity in programming using CUDA by simplifying the programmer's view of CPU and GPU memory spaces, initial support for UM in the Kepler series of GPUs lacked in performance necessitating several UM-aware designs in state-of-the-art MPI runtimes such as MVAPICH2-GDR. This has enabled end MPI applications to take advantage of the high productivity promised by UM along with high performance. However, as CUDA runtimes and GPU architectures advance, the performance offered by UM has also improved significantly. Thus, there is a need to re-evaluate the performance characteristics of UM in light of these changes to understand how the UM-aware designs in state-of-the-art MPI runtimes must be adapted. We take up this broad challenge and characterize the performance of UM-aware MPI operations and to gain insights on how MPI runtimes need to deal with UM-based data residing on GPU and CPU for different generations of GPU architectures. Our characterization studies show that UM designs conceived during the Kepler GPU era still stands valid and provide valuable performance improvement on the latest Pascal and Volta GPUs. Furthermore, performance evaluation of optimized UM designs show that they outperform naive designs on MVAPICH2-GDR and Open MPI by 4.2× and 2.8× respectively for Intel systems. Additionally, the DD experiments for pure device transfers also show that MVAPICH2-GDR is up to 12.6× better than OpenMPI (w/ UCX).},
  author          = {Manian, K. V. and Awan, Ammar Ahmad and Ruhela, A. and Chu, C. H. and Subramoni, H. and Panda, D. K.},
  booktitle       = {Proceedings of the Workshop on General Purpose Processing using GPUs (GPGPU)},
  doi             = {10.1145/3300053.3319419},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the Workshop on General Purpose Processing using GPUs (GPGPU)/Characterizing CUDA unified memory (UM)-aware MPI designs on modern GPU architectures - Manian et al. - Proceedings of the Wor.pdf:pdf},
  isbn            = {9781450362559},
  keywords        = {CUDA,GPU,HPC,MPI,Unfied{\_}Memory,Unified Memory},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {CUDA,GPU,MPI,Unfied{\_}Memory},
  pages           = {43--52},
  title           = {{Characterizing CUDA unified memory (UM)-aware MPI designs on modern GPU architectures}},
  year            = {2019}
}
@article{Marendic2016,
  abstract        = {Reduction algorithms are optimized only under the assumption that all processes commence the reduction simultaneously. Research on process arrival times has shown that this is rarely the case. Thus, all benchmarking methodologies that take into account only balanced arrival times might not portray a true picture of real-world algorithm performance. In this paper, we select a subset of four reduction algorithms frequently used by library implementations and evaluate their performance for both balanced and imbalanced process arrival times. The main contribution of this paper is a novel imbalance robust algorithm that uses pre-knowledge of process arrival times to construct reduction schedules. The performance of selected algorithms was empirically evaluated on a 128 node subset of the Partnership for Advanced Computing in Europe CURIE supercomputer. The reported results show that the new imbalance robust algorithm universally outperforms all the selected algorithms, whenever the reduction schedule is precomputed. We find that when the cost of schedule construction is included in the total runtime, the new algorithm outperforms the selected algorithms for problem sizes greater than 1 MiB.},
  author          = {Marendic, P. and Lemeire, J. and Vucinic, D. and Schelkens, P.},
  doi             = {10.1007/s11227-016-1707-x},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Journal of Supercomputing/A novel MPI reduction algorithm resilient to imbalances in process arrival times - Marendic et al. - Journal of Supercomputing.pdf:pdf},
  issn            = {15730484},
  journal         = {Journal of Supercomputing},
  keywords        = {Collective operations,Collectives,Load imbalance,MPI,PAP,Process arrival time,Reduction,System noise},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {Collectives,MPI,PAP},
  pages           = {1--41},
  publisher       = {Springer US},
  title           = {{A novel MPI reduction algorithm resilient to imbalances in process arrival times}},
  year            = {2016}
}
@inproceedings{Marinescu2014,
  abstract      = {Parallel programming is a computing paradigm that gains more and more adopters each year. Embracing parallel programming means in most of the cases the usage of a particular library that allows to add parallelism and concurrency to applications. Unfortunately there still is little knowledge about how parallel libraries are used in practice and without such information it is quite hard to promote them, for example, in terms of the importance of their provided functionalities. In this paper we focus on the usages of MPI, one of the most popular model facilitating parallel programming. By addressing research questions regarding the usage of MPI constructs as well as the structural complexity of MPI open source applications we aim to encourage new developers to embrace MPI, as well as to consider adopting open source systems which rely on MPI. Copyright is held by the owner/author(s).},
  author        = {Marinescu, Cristina},
  booktitle     = {ACM International Conference Proceeding Series},
  doi           = {10.1145/2601248.2601298},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/ACM International Conference Proceeding Series/An empirical investigation on MPI open source applications - Marinescu - ACM International Conference Proceeding Series.pdf:pdf},
  isbn          = {9781450324762},
  keywords      = {MPI,Software repositories,Source code,Survey},
  mendeley-tags = {MPI,Survey},
  pages         = {17--20},
  title         = {{An empirical investigation on MPI open source applications}},
  year          = {2014}
}
@inproceedings{Martinasso2016,
  abstract        = {MeteoSwiss, the Swiss national weather forecast institute, has selected densely populated accelerator servers as their primary system to compute weather forecast simulation. Servers with multiple accelerator devices that are primarily connected by a PCI-Express (PCIe) network achieve a significantly higher energy efficiency. Memory transfers between accelerators in such a system are subjected to PCIe arbitration policies. In this paper, we study the impact of PCIe topology and develop a congestion-aware performance model for PCIe communication. We present an algorithm for computing congestion factors of every communication in a congestion graph that characterizes the dynamic usage of network resources by an application. Our model applies to any PCIe tree topology. Our validation results on two different topologies of 8 GPU devices demonstrate that our model achieves an accuracy of over 97{\%} within the PCIe network. We demonstrate the model on a weather forecast application to identify the best algorithms for its communication patterns among GPUs.},
  author          = {Martinasso, Maxime and Kwasniewski, Grzegorz and Alam, Sadaf R. and Schulthess, Thomas C. and Hoefler, Torsten},
  booktitle       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi             = {10.1109/SC.2016.62},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/A PCIe Congestion-Aware Performance Model for Densely Populated Accelerator Servers - Mar.pdf:pdf},
  isbn            = {9781467388153},
  issn            = {21674337},
  keywords        = {Congestion,GPU,Modeling,Multi{\_}GPU,Multiple GPUs,PCI-Express,PCI{\_}E,performance model},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {Congestion,GPU,Modeling,Multi{\_}GPU,PCI{\_}E},
  pages           = {739--749},
  title           = {{A PCIe Congestion-Aware Performance Model for Densely Populated Accelerator Servers}},
  year            = {2016}
}
@article{Matsuoka2023,
  author          = {Matsuoka, Satoshi and Domke, Jens and Wahib, Mohamed and Drozd, Aleksandr and Hoefler, Torsten},
  doi             = {10.48550/ARXIV.2301.02432},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/arXiv/Myths and Legends in High-Performance Computing - Matsuoka et al. - arXiv.pdf:pdf},
  journal         = {arXiv},
  mendeley-groups = {MustKnow},
  pages           = {1--12},
  title           = {{Myths and Legends in High-Performance Computing}},
  year            = {2023}
}
@article{Mayer2020,
  abstract      = {Deep Learning (DL) has had an immense success in the recent past, leading to state-of-the-art results in various domains, such as image recognition and natural language processing. One of the reasons for this success is the increasing size of DL models and the proliferation of vast amounts of training data being available. To keep on improving the performance of DL, increasing the scalability of DL systems is necessary. In this survey, we perform a broad and thorough investigation on challenges, techniques and tools for scalable DL on distributed infrastructures. This incorporates infrastructures for DL, methods for parallel DL training, multi-tenant resource scheduling, and the management of training and model data. Further, we analyze and compare 11 current open-source DL frameworks and tools and investigate which of the techniques are commonly implemented in practice. Finally, we highlight future research trends in DL systems that deserve further research.},
  author        = {Mayer, Ruben and Jacobsen, Hans Arno},
  doi           = {10.1145/3363554},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/ACM Computing Surveys/Scalable deep learning on distributed infrastructures Challenges, techniques, and tools - Mayer, Jacobsen - ACM Computing Surveys.pdf:pdf},
  issn          = {15577341},
  journal       = {ACM Computing Surveys},
  keywords      = {Deep-learning systems,Deep{\_}Learning,Survey},
  mendeley-tags = {Deep{\_}Learning,Survey},
  number        = {1},
  pages         = {1--37},
  title         = {{Scalable deep learning on distributed infrastructures: Challenges, techniques, and tools}},
  volume        = {53},
  year          = {2020}
}
@inproceedings{McCool2008,
  abstract      = {Including multiple cores on a single chip has become the dominant mechanism for scaling processor performance. Exponential growth in the number of cores on a single processor is expected to lead in a short time to mainstream computers with hundreds of cores. Scalable implementations of parallel algorithms will be necessary in order to achieve improved single-application performance on such processors. In addition, memory access will continue to be an important limiting factor on achieving performance, and heterogeneous systems may make use of cores with varying capabilities and performance characteristics. An appropriate programming model can address scalability and can expose data locality while making it possible to migrate application code between processors with different parallel architectures and variable numbers and kinds of cores. We survey and evaluate a range of multicore processor architectures and programming models with a focus on GPUs and the Cell BE processor. These processors have a large number of cores and are available to consumers today, but the scalable programming models developed for them are also applicable to current and future multicore CPUs. {\textcopyright} 2008 IEEE.},
  author        = {McCool, Michael D.},
  booktitle     = {Proceedings of the IEEE},
  doi           = {10.1109/JPROC.2008.917731},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2008/Proceedings of the IEEE/Scalable programming models for massively multicore processors - McCool - Proceedings of the IEEE.pdf:pdf},
  issn          = {00189219},
  keywords      = {Computer architecture,Multicore processors,Parallel programming and computation,Programming and processing models,Programming{\_}Model},
  mendeley-tags = {Programming{\_}Model},
  number        = {5},
  pages         = {816--831},
  title         = {{Scalable programming models for massively multicore processors}},
  volume        = {96},
  year          = {2008}
}
@techreport{Mehta2021,
  author          = {Mehta, Vishal and Gadeschi, Gonzalo Brito},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Unknown/Optimizing Applications With Asynchronous Gpu Programming in Cuda C - Mehta, Gadeschi - Unknown.pdf:pdf},
  mendeley-groups = {Presentations {\&} Reports},
  title           = {{Optimizing Applications With Asynchronous Gpu Programming in Cuda C++}},
  year            = {2021}
}
@misc{Mellanox2010,
  author        = {Mellanox},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2010/Unknown/CORE-Direct The Most Advanced Technology for MPI SHMEM Collectives Offloads - Mellanox - Unknown.pdf:pdf},
  keywords      = {Collectives,Mellanox,Offloading},
  mendeley-tags = {Collectives,Mellanox,Offloading},
  number        = {May},
  title         = {{CORE-Direct The Most Advanced Technology for MPI / SHMEM Collectives Offloads}},
  url           = {https://www.mellanox.com/related-docs/whitepapers/TB{\_}CORE-Direct.pdf},
  urldate       = {2020-07-12},
  year          = {2010}
}
@article{Merelli2020,
  abstract      = {This editorial introduces the articles selected for the special issue concerning the International Conferences on Parallel, Distributed, and Network-Based Processing, which provided insights related to the efficient exploitation of parallel and distributed architectures, including power-aware computing, application scheduling, and application development for GPUs.},
  author        = {Merelli, Ivan and Li{\`{o}}, Pietro and Kotenko, Igor and D'Agostino, Daniele},
  doi           = {10.1002/cpe.5683},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Concurrency and Computation Practice and Experience (CCPE)/Latest advances in parallel, distributed, and network-based processing - Merelli et al. - Concurrency and Computation Practice and Exper.pdf:pdf},
  issn          = {15320634},
  journal       = {Concurrency and Computation: Practice and Experience (CCPE)},
  keywords      = {Computing,GPU,Network,gpu computing,network-based computing,parallel Computing},
  mendeley-tags = {GPU,Network},
  number        = {10},
  pages         = {4--7},
  title         = {{Latest advances in parallel, distributed, and network-based processing}},
  volume        = {32},
  year          = {2020}
}
@inproceedings{Milic2019,
  author          = {Milic, Ugljesa and Ramirez, Alex and Nellans, David},
  booktitle       = {Proceedings of the International Symposium on Microarchitecture (MICRO)},
  doi             = {10.1145/3123939.3124534},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Symposium on Microarchitecture (MICRO)/Beyond the Socket NUMA-Aware GPUs - Milic, Ramirez, Nellans - Proceedings of the International Symposium on Microarchitecture (MIC.pdf:pdf},
  isbn            = {9781450349529},
  keywords        = {GPU,Multi{\_}GPU,NUMA},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {GPU,Multi{\_}GPU,NUMA},
  pages           = {1--13},
  title           = {{Beyond the Socket : NUMA-Aware GPUs}},
  year            = {2019}
}
@article{Mills2020,
  abstract      = {The Portable Extensible Toolkit for Scientific computation (PETSc) library delivers scalable solvers for nonlinear time-dependent differential and algebraic equations and for numerical optimization.The PETSc design for performance portability addresses fundamental GPU accelerator challenges and stresses flexibility and extensibility by separating the programming model used by the application from that used by the library, and it enables application developers to use their preferred programming model, such as Kokkos, RAJA, SYCL, HIP, CUDA, or OpenCL, on upcoming exascale systems. A blueprint for using GPUs from PETSc-based codes is provided, and case studies emphasize the flexibility and high performance achieved on current GPU-based systems.},
  author        = {Mills, Richard Tran and Adams, Mark F. and Balay, Satish and Brown, Jed and Dener, Alp and Knepley, Matthew and Kruger, Scott E. and Morgan, Hannah and Munson, Todd and Rupp, Karl and Smith, Barry F. and Zampini, Stefano and Zhang, Hong and Zhang, Junchao},
  doi           = {10.1016/j.parco.2021.102831},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/arXiv/Toward Performance-Portable PETSc for GPU-based Exascale Systems - Mills et al. - arXiv.pdf:pdf},
  journal       = {arXiv},
  keywords      = {2010 msc,65f10,65f50,68n99,68w10,CUDA,CUDA{\_}Graphs,GPU,MPI,exascale,gpu acceleration,high-performance computing,many-core,numerical software,performance portability},
  mendeley-tags = {CUDA,CUDA{\_}Graphs,GPU,MPI},
  title         = {{Toward Performance-Portable PETSc for GPU-based Exascale Systems}},
  year          = {2020}
}
@inproceedings{Mirsadeghi2016b,
  abstract        = {As we move toward the Exascale era, HPC systems are becoming more complex, introducing increasing levels of heterogeneity in communication channels. This leads to variations in communication performance at different levels of hierarchy within modern HPC systems. Consequently, communicating peers such as MPI processes should be mapped onto the target cores in a topology-aware fashion so as to avoid message transmissions over slower channels. This is especially true for collective communications due to the global nature of their communication patterns and their vast use in many of parallel applications. In this paper, we exploit the rank reordering mechanism of MPI to realize run-time topology awareness for collective communications and in particular MPI-Allgather. To this end, we propose four fine-tuned mapping heuristics for various communication patterns and algorithms commonly used in MPI-Allgather. The heuristics provide a better match between the collective communication pattern and the topology of the target system. Our experimental results with 4096 processes show that MPI rank reordering using the proposed fine-tuned mapping heuristics can provide up to 78{\%} reduction in MPI-Allgather latency at the micro-benchmark level. At the application level, we can achieve up to 34{\%} reduction in execution time. The results also show that the proposed heuristics significantly outperform the Scotch library which provides a general-purpose graph mapping library.},
  author          = {Mirsadeghi, Seyed H. and Afsahi, Ahmad},
  booktitle       = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi             = {10.1109/IPDPSW.2016.139},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/Topology-aware rank reordering for MPI collectives - Mirsadeghi, Afsahi - Proceedings of the IEEE International.pdf:pdf},
  isbn            = {9781509021406},
  keywords        = {Collective Communications,Collectives,MPI,Mapping,Rank Reordering,Topology Awareness,Topology{\_}Aware},
  mendeley-groups = {ByPPRL},
  mendeley-tags   = {Collectives,MPI,Mapping,Topology{\_}Aware},
  pages           = {1759--1768},
  title           = {{Topology-aware rank reordering for MPI collectives}},
  year            = {2016}
}
@inproceedings{Mirsadeghi2016a,
  abstract        = {GPU accelerators have been increasingly used in modern heterogeneous HPC clusters by offering high performance and energy efficiency. Such heterogeneous GPU clusters consisting of multiple CPU cores and GPU devices have become the platform of choice for many HPC applications. The communication channels among these processing elements expose different latency and bandwidth characteristics. Thus, efficient utilization of communication channels becomes an important factor for achieving higher inter-process communication performance. In this paper, we exploit topology awareness for a better utilization of communication channels in GPU clusters. We first discuss the challenges associated with topology-aware mapping in GPU clusters, and then propose MAGC, a Mapping Approach for GPU Clusters. MAGC seeks to improve the total communication performance by a joint consideration of both CPU-to-CPU and GPU-to-GPU communications of the application, and CPU and GPU physical topologies of the underlying GPU cluster. It provides a unified framework for topology-aware process-to-core mapping and GPU-to-process assignment across a GPU cluster. We study the potential benefits of MAGC with two different mapping algorithms: a) the Scotch graph mapping library, and b) a heuristic designed to explicitly consider maximum congestion. We evaluate our design through extensive experiments at micro-benchmark and application levels on two GPU clusters with different GPU types and topologies. We have developed a micro-benchmark suite to model various communication patterns among CPU cores and among GPU devices. For application results, we use the molecular dynamics simulator, HOOMD-blue. Micro-benchmark results show that we can achieve up to 91.4{\%} improvement in communication time. At the application level, we can achieve up to 8{\%} performance improvement.},
  author          = {Mirsadeghi, Seyed H. and Faraji, Iman and Afsahi, Ahmad},
  booktitle       = {Proceedings of the International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)},
  doi             = {10.1109/SBAC-PAD.2016.15},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)/MAGC A Mapping Approach for GPU Clusters - Mirsadeghi, Faraji, Afsahi - Proceedings of the In.pdf:pdf},
  isbn            = {9781509061082},
  issn            = {15506533},
  keywords        = {GPU,GPU cluster,GPU selection,Mapping,Topology awareness,Topology{\_}Aware},
  mendeley-groups = {MustKnow,UsedInComp1,UsedInComp2,ByPPRL},
  mendeley-tags   = {GPU,Mapping,Topology{\_}Aware},
  pages           = {50--58},
  title           = {{MAGC: A Mapping Approach for GPU Clusters}},
  year            = {2016}
}
@article{Mirsadeghi2016,
  abstract        = {With the rapid increase in the size and scale of modern systems, topology-aware process mapping has become an important approach for improving system efficiency. A poor placement of processes across compute nodes could cause significant congestion within the interconnect. In this paper, we propose a new greedy mapping heuristic as well as a mapping refinement algorithm. The heuristic attempts to minimize a hybrid metric that we use for evaluating various mappings, whereas the refinement algorithm attempts to reduce maximum congestion directly. Moreover, we take advantage of parallelism in the design and implementation of our proposed algorithms to achieve scalability. We also use the underlying routing information in addition to the topology of the system to derive a better evaluation of congestion. Our experimental results with 4096 processes show that the proposed approach can provide more than 60{\%} improvement in various mapping metrics compared to an initial in-order mapping of processes. Communication time is also improved by 50{\%}. In addition, we also compare our proposed algorithms with 4 other heuristics from the LibTopoMap library, and show that we can achieve better mappings at a significantly lower cost.},
  author          = {Mirsadeghi, Seyed Hessam and Afsahi, Ahmad},
  doi             = {10.1109/IPDPSW.2016.146},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/PTRAM A parallel topology-and routing-aware mapping framework for large-scale HPC systems - Mirsadeghi, Afsahi.pdf:pdf},
  isbn            = {9781509021406},
  journal         = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  keywords        = {MPI,Mapping,Routing Awareness,Routing{\_}Aware,Topology Mapping},
  mendeley-groups = {ByPPRL},
  mendeley-tags   = {MPI,Mapping,Routing{\_}Aware},
  pages           = {386--396},
  title           = {{PTRAM: A parallel topology-and routing-aware mapping framework for large-scale HPC systems}},
  year            = {2016}
}
@phdthesis{Mirsadeghi2017,
  abstract        = {High-Performance Computing (HPC) represents the flagship domain in providing high-end computing capabilities that play a critical role in helping humanity solve its hardest problems. Ranging from answering profound questions about the universe to finding a cure for cancer, HPC applications span nearly every aspect of our life. The impressive power of HPC systems comes mainly from the massive number of processors---in the order of millions---that they provide. The efficiency of communications among these processors is the main bottleneck in the overall performance of HPC systems. This dissertation presents new algorithms for improving the communication performance in HPC systems by exploiting the topology information. We propose a parallel topology- and routing-aware mapping heuristic and a refinement algorithm that improves the communication performance by achieving a lower congestion across the network links. Our experimental results with 4,096 processors show that the proposed approach can provide more than 60{\%} improvement in various mapping metrics compared to an initial in-order mapping of processes. Communication time is also improved by up to 50{\%}. We also propose four topology-aware mapping heuristics designed specifically for collective communications in the Message Passing Interface (MPI). The heuristics provide a better match between the collective communication algorithm and the physical topology of the system, and decrease the communication latency by up to 78{\%}. Furthermore, we expand topology-aware communications into the scope of accelerated computing. Using accelerators---especially Graphics Processing Units (GPUs)---to speed up certain types of computations plays an increasingly important role in HPC. We present a unified framework for topology-aware process mapping and GPU assignment in multi-GPU systems. Our experimental results on two clusters with 64 GPUs show that the proposed approach improves communication performance by up to 91{\%}. Finally, we present a novel distributed algorithm that uses the process topology information to design optimized communication schedules for MPI neighborhood collectives. The proposed algorithm finds the common neighborhoods in a distributed graph topology and exploits them as an opportunity to improve the communication performance through message combining. The optimized schedules reduce the communication latency of MPI neighborhood collectives by more than 50{\%}.},
  author          = {Mirsadeghi, Seyed Hessamedin},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Unknown/Improving Communication Performance through Topology and Congestion Awareness in HPC Systems - Mirsadeghi - Unknown.pdf:pdf},
  keywords        = {Congestion,MPI,Thesis,Topology{\_}Aware},
  mendeley-groups = {ByPPRL,Theses},
  mendeley-tags   = {Congestion,MPI,Thesis,Topology{\_}Aware},
  pages           = {1--198},
  school          = {Queen's University},
  title           = {{Improving Communication Performance through Topology and Congestion Awareness in HPC Systems}},
  year            = {2017}
}
@inproceedings{Mirsadeghi2018,
  abstract        = {Neighborhood collectives were added to the Message Passing Interface (MPI) to better support sparse communication patterns found in many applications. These new collectives encourage more scalable programming styles, and greatly extend the scope of MPI collectives by allowing users to define their own collective communication patterns. In this paper, we describe a new, distributed algorithm for computing improved communication schedules for neighborhood collectives. We show how to discover common process neighborhoods in fully general MPI distributed graph topologies, and how to exploit this information to build message-combining communication schedules for the MPI neighborhood collectives. Our experimental results show considerable performance improvements for application communication topologies of various shapes and sizes. On average, the performance gain is around 50{\%}, but it can also be as much as 71{\%} for topologies with larger numbers of neighbors.},
  author          = {Mirsadeghi, Seyed Hessamedin and Triff, Jesper Larsson and Balaji, Pavan and Afsahi, Ahmad},
  booktitle       = {Proceedings of the IEEE International Conference on High Performance Computing (HiPC)},
  doi             = {10.1109/HiPC.2017.00047},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the IEEE International Conference on High Performance Computing (HiPC)/Exploiting common neighborhoods to optimize MPI neighborhood collectives - Mirsadeghi et al. - Proceedings of the IEE.pdf:pdf},
  isbn            = {9781538622933},
  keywords        = {MPI,Neighborhood Collective,Neighborhood{\_}Collectives,Topology,Topology{\_}Aware},
  mendeley-groups = {ByPPRL},
  mendeley-tags   = {MPI,Neighborhood{\_}Collectives,Topology{\_}Aware},
  pages           = {347--357},
  title           = {{Exploiting common neighborhoods to optimize MPI neighborhood collectives}},
  volume          = {2017-Decem},
  year            = {2018}
}
@article{Mittal2015,
  abstract        = {As both CPUs and GPUs become employedinawide rangeof applications, ithas been acknowledged that both of these Processing Units (PUs) have their unique features and strengths and hence, CPU-GPU collaboration is inevitable to achieve high-performance computing. This has motivated a significant amount of research on heterogeneous computing techniques, along with the design of CPU-GPU fused chips and petascale heterogeneous supercomputers. In this article, we survey Heterogeneous Computing Techniques (HCTs) such as workload partitioning that enable utilizing both CPUs and GPUs to improve performance and/or energy efficiency. We review heterogeneous computing approaches at runtime, algorithm, programming, compiler, and application levels. Further, we review both discrete and fused CPU-GPU systems and discuss benchmark suites designed for evaluating Heterogeneous Computing Systems (HCSs). We believe that this article will provide insights into the workings and scope of applications of HCTs to researchers and motivate them to further harness the computational powers of CPUs and GPUs to achieve the goal of exascale performance.},
  author          = {Mittal, Sparsh and Vetter, Jeffrey S.},
  doi             = {10.1145/2788396},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/ACM Computing Surveys/A survey of CPU-GPU heterogeneous computing techniques - Mittal, Vetter - ACM Computing Surveys.pdf:pdf},
  issn            = {15577341},
  journal         = {ACM Computing Surveys},
  keywords        = {CPU-GPU heterogeneous/hybrid/collaborative computi,Dynamic/static load balancing,Fused CPU-GPU chip,GPU,Heterogeneous,Pipelining,Programming frameworks,Survey,Workload division/partitioning},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,Heterogeneous,Survey},
  number          = {4},
  pages           = {1--35},
  title           = {{A survey of CPU-GPU heterogeneous computing techniques}},
  volume          = {47},
  year            = {2015}
}
@techreport{Modukuri2020,
  author          = {Modukuri, Kiran and Sen, Saptarshi and Joshi, Sandeep and Shankar, Shiva and Fiske, Barton and Qazi, Osama},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Unknown/GPUDIRECT STORAGE A DIRECT GPU-STORAGE DATA PATH - Modukuri et al. - Unknown.pdf:pdf},
  keywords        = {CUDA,GPU,GPUDirect{\_}Storage},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {CUDA,GPU,GPUDirect{\_}Storage},
  title           = {{GPUDIRECT STORAGE : A DIRECT GPU-STORAGE DATA PATH}},
  year            = {2020}
}
@article{Morell2019,
  abstract        = {In 2019, around 57{\%} of the population of the world has broadband access to the Internet. Moreover, there are 5.9 billion mobile broadband subscriptions, i.e., 1.3 subscriptions per user. So there is an enormous interconnected computational power held by users all around the world. Also, it is estimated that Internet users spend more than six and a half hours online every day. But in spite of being a great amount of time, those resources are idle most of the day. Therefore, taking advantage of them presents an interesting opportunity. In this study, we introduce JSDoop, a prototype implementation to profit from this opportunity. In particular, we propose a volunteer web browser-based high-performance computing library. JSdoop divides a problem into tasks and uses different queues to distribute the computation. Then, volunteers access the web page of the problem and start processing the tasks in their web browsers. We conducted a proof-of-concept using our proposal and TensorFlow.js to train a recurrent neural network that predicts text. We tested it in a computer cluster and with up to 32 volunteers. The experimental results show that training a neural network in distributed web browsers is feasible and accurate, has a high scalability, and it is an interesting area for research.},
  author          = {Morell, Jos{\'{e}} A. and Camero, Andr{\'{e}}s and Alba, Enrique},
  doi             = {10.1109/ACCESS.2019.2950287},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/IEEE Access/JSDoop and TensorFlow.js Volunteer Distributed Web Browser-Based Neural Network Training - Morell, Camero, Alba - IEEE Access.pdf:pdf},
  issn            = {21693536},
  journal         = {IEEE Access},
  keywords        = {Artificial intelligence,browsers,collaborative work,distributed algorithms,distributed computing,internet,javascript,jsdoop,neural networks,tensorflow,volunteer computing},
  mendeley-groups = {Web},
  pages           = {158671--158684},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  title           = {{JSDoop and TensorFlow.js: Volunteer Distributed Web Browser-Based Neural Network Training}},
  volume          = {7},
  year            = {2019}
}
@inproceedings{Morgan2017,
  abstract        = {Advantages of nonblocking collective communication in MPI have been established over the past quarter century, even predating MPI-1. For regular computations with fixed communication patterns, more optimizations can be revealed through the use of persistence (planned transfers) not currently available in the MPI-3 API except for a limited form of point-to-point persistence (aka half-channels) standardized since MPI-1. This paper covers the design, prototype implementation of LibPNBC (based on LibNBC), and MPI-4 standardization status of persistent nonblocking collective operations. We provide early performance results, using a modified version of NBCBench and an example illustrating the potential performance enhancements for such operations. Persistent operations allow MPI implementations to make intelligent choices about algorithm and resource utilization once and amortize this decision cost across many uses in a long-running program. Evidence that this approach is of value is provided. As with non-persistent, nonblocking collective operations, the requirement for strong progress and blocking completion notification are jointly needed to maximize the benefit of such operations (e.g., overlap of communication with computation or other communication). Further enhancement of the current implementation prototype as well as additional opportunities to enhance performance through the application of these new APIs comprise future work.},
  author          = {Morgan, Bradley and Holmes, Daniel J. and Skjellum, Anthony and Bangalore, Purushotham and Sridharan, Srinivas},
  booktitle       = {Proceedings of the European MPI Users' Group Meeting (EuroMPI)},
  doi             = {10.1145/3127024.3127028},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the European MPI Users' Group Meeting (EuroMPI)/Planning for performance Persistent collective operations for MPI - Morgan et al. - Proceedings of the European MPI Users' Group Meeting.pdf:pdf},
  isbn            = {9781450348492},
  keywords        = {Collective communication,Collectives,MPI,Nonblocking,Optimized algorithm,Persistence,Persistent},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,Persistent},
  pages           = {1--11},
  title           = {{Planning for performance: Persistent collective operations for MPI}},
  year            = {2017}
}
@article{Mudigere2021,
  abstract      = {Deep learning recommendation models (DLRMs) are used across many business-critical services at Facebook and are the single largest AI application in terms of infrastructure demand in its data-centers. In this paper we discuss the SW/HW co-designed solution for high-performance distributed training of large-scale DLRMs. We introduce a high-performance scalable software stack based on PyTorch and pair it with the new evolution of Zion platform, namely ZionEX. We demonstrate the capability to train very large DLRMs with up to 12 Trillion parameters and show that we can attain 40X speedup in terms of time to solution over previous systems. We achieve this by (i) designing the ZionEX platform with dedicated scale-out network, provisioned with high bandwidth, optimal topology and efficient transport (ii) implementing an optimized PyTorch-based training stack supporting both model and data parallelism (iii) developing sharding algorithms capable of hierarchical partitioning of the embedding tables along row, column dimensions and load balancing them across multiple workers; (iv) adding high-performance core operators while retaining flexibility to support optimizers with fully deterministic updates (v) leveraging reduced precision communications, multi-level memory hierarchy (HBM+DDR+SSD) and pipelining. Furthermore, we develop and briefly comment on distributed data ingestion and other supporting services that are required for the robust and efficient end-to-end training in production environments.},
  archiveprefix = {arXiv},
  arxivid       = {2104.05158},
  author        = {Mudigere, Dheevatsa and Hao, Yuchen and Huang, Jianyu and Jia, Zhihao and Tulloch, Andrew and Sridharan, Srinivas and Liu, Xing and Ozdal, Mustafa and Nie, Jade and Park, Jongsoo and Luo, Liang and Yang, Jie Amy and Gao, Leon and Ivchenko, Dmytro and Basant, Aarti and Hu, Yuxi and Yang, Jiyan and Ardestani, Ehsan K. and Wang, Xiaodong and Komuravelli, Rakesh and Chu, Ching-Hsiang and Yilmaz, Serhat and Li, Huayu and Qian, Jiyuan and Feng, Zhuobo and Ma, Yinbin and Yang, Junjie and Wen, Ellie and Li, Hong and Yang, Lin and Sun, Chonglin and Zhao, Whitney and Melts, Dimitry and Dhulipala, Krishna and Kishore, KR and Graf, Tyler and Eisenman, Assaf and Matam, Kiran Kumar and Gangidi, Adi and Chen, Guoqiang Jerry and Krishnan, Manoj and Nayak, Avinash and Nair, Krishnakumar and Muthiah, Bharath and Khorashadi, Mahmoud and Bhattacharya, Pallab and Lapukhov, Petr and Naumov, Maxim and Mathews, Ajit and Qiao, Lin and Smelyanskiy, Mikhail and Jia, Bill and Rao, Vijay},
  eprint        = {2104.05158},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/arXiv/Software-Hardware Co-design for Fast and Scalable Training of Deep Learning Recommendation Models - Mudigere et al. - arXiv.pdf:pdf},
  journal       = {arXiv},
  keywords      = {Read2},
  mendeley-tags = {Read2},
  pages         = {1--20},
  publisher     = {Association for Computing Machinery},
  title         = {{Software-Hardware Co-design for Fast and Scalable Training of Deep Learning Recommendation Models}},
  url           = {http://arxiv.org/abs/2104.05158},
  year          = {2021}
}
@phdthesis{Muthukrishnan2022,
  author          = {Muthukrishnan, Harini},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Unknown/Improving Multi-GPU Strong Scaling Through Optimization of Fine-Grained Transfers - Muthukrishnan - Unknown.pdf:pdf},
  keywords        = {GPU,Multi{\_}GPU,Thesis},
  mendeley-groups = {MustKnow,Theses},
  mendeley-tags   = {GPU,Multi{\_}GPU,Thesis},
  pages           = {1--138},
  school          = {University of Michigan},
  title           = {{Improving Multi-GPU Strong Scaling Through Optimization of Fine-Grained Transfers}},
  year            = {2022}
}
@inproceedings{Muthukrishnan2021,
  abstract      = {Suboptimal management of memory and bandwidth is one of the primary causes of low performance on systems comprising multiple GPUs. Existing memory management solutions like Unified Memory (UM) offer simplified programming but come at the cost of performance: applications can even exhibit slowdown with increasing GPU count due to their inability to leverage system resources effectively. To solve this challenge, we propose GPS, a HW/SW multi-GPU memory management technique that efficiently orchestrates inter-GPU communication using proactive data transfers. GPS offers the programmability advantage of multi-GPU shared memory with the performance of GPU-local memory. To enable this, GPS automatically tracks the data accesses performed by each GPU, maintains duplicate physical replicas of shared regions in each GPU's local memory, and pushes updates to the replicas in all consumer GPUs. GPS is compatible within the existing NVIDIA GPU memory consistency model but takes full advantage of its relaxed nature to deliver high performance.We evaluate GPS in the context of a 4-GPU system with varying interconnects and show that GPS achieves an average speedup of 3.0× relative to the performance of a single GPU, outperforming the next best available multi-GPU memory management technique by 2.3× on average. In a 16-GPU system, using a future PCIe 6.0 interconnect, we demonstrate a 7.9× average strong scaling speedup over single-GPU performance, capturing 80{\%} of the available opportunity.},
  author        = {Muthukrishnan, Harini and Lustig, Daniel and Nellans, David and Wenisch, Thomas},
  booktitle     = {Proceedings of the International Symposium on Microarchitecture (MICRO)},
  doi           = {10.1145/3466752.3480088},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the International Symposium on Microarchitecture (MICRO)/GPS A global publish-subscribe model for multi-GPU memory management - Muthukrishnan et al. - Proceedings of the International Symp.pdf:pdf},
  isbn          = {9781450385572},
  issn          = {10724451},
  keywords      = {Communication,GPGPU,GPU,GPU memory management,Heterogeneous systems,Multi-GPU,Multi{\_}GPU,Strong scaling},
  mendeley-tags = {GPU,Multi{\_}GPU},
  pages         = {46--58},
  title         = {{GPS: A global publish-subscribe model for multi-GPU memory management}},
  year          = {2021}
}
@inproceedings{Muthukrishnan2023,
  abstract      = {Recent studies have shown that using fine-grained peer-to-peer (P2P) stores to communicate among devices in multi-GPU systems is a promising path to achieve strong performance scaling. In many irregular applications, such as graph algorithms and sparse linear algebra, small sub-cache line (4-32B) stores arise naturally when using the P2P paradigm. This is particularly problematic in multi-GPU systems because inter-GPU interconnects are optimized for bulk transfers rather than small operations. As a consequence, application developers either resort to complex programming techniques to work around this small transfer inefficiency or fall back to bulk inter-GPU DMA transfers that have limited performance scalability. We propose FinePack, a set of limited I/O interconnect and GPU hardware enhancements that enable small peer-to-peer stores to achieve interconnect efficiency that rivals bulk transfers while maintaining the simplicity of a peer-to-peer memory access programming model. Exploiting the GPU's weak memory model, FinePack dynamically coalesces and compresses small writes into a larger I/O message that reduces link-level protocol overhead. FinePack is fully transparent to software and requires no changes to the GPU's virtual memory system. We evaluate FinePack on a system comprising 4 Volta GPUs on a PCIe 4.0 interconnect to show FinePack improves interconnect efficiency for small peer-to-peer stores by 3×. This results in 4-GPU strong scaling performance 1.4× better than traditional DMA based multi-GPU programming and comes within 71{\%} of the maximum achievable strong scaling performance.},
  author        = {Muthukrishnan, Harini and Lustig, Daniel and Villa, Oreste and Wenisch, Thomas and Nellans, David},
  booktitle     = {Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)},
  doi           = {10.1109/HPCA56546.2023.10070949},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/Proceedings of the International Symposium on High-Performance Computer Architecture (HPCA)/FinePack Transparently Improving the Efficiency of Fine-Grained Transfers in Multi-GPU Systems - Muthukrishnan.pdf:pdf},
  isbn          = {9781665476522},
  keywords      = {GPU},
  mendeley-tags = {GPU},
  pages         = {1--14},
  publisher     = {IEEE},
  title         = {{FinePack : Transparently Improving the Efficiency of Fine-Grained Transfers in Multi-GPU Systems}},
  year          = {2023}
}
@inproceedings{Muthukrishnan2021a,
  abstract        = {Despite continuing research into inter-GPU communication mechanisms, extracting performance from multi-GPU systems remains a significant challenge. Inter-GPU communication via bulk DMA-based transfers exposes data transfer latency on the GPU's critical execution path because these large transfers are logically interleaved between compute kernels. Conversely, fine-grained peer-to-peer memory accesses during kernel execution lead to memory stalls that can exceed the GPUs' ability to cover these operations via multi-threading. Worse yet, these sub-cacheline transfers are highly inefficient on current inter-GPU interconnects. To remedy these issues, we propose PROACT, a system enabling remote memory transfers with the programmability and pipeline advantages of peer-to-peer stores, while achieving interconnect efficiency that rivals bulk DMA transfers. Combining compile-time instrumentation with fine-grain tracking of data block readiness within each GPU, PROACT enables interconnect-friendly data transfers while hiding the transfer latency via pipelining during kernel execution. This work describes both hardware and software implementations of PROACT and demonstrates the effectiveness of a PROACT software prototype on three generations of GPU hardware and interconnects. Achieving near-ideal interconnect efficiency, PROACT realizes a mean speedup of 3.0× over single-GPU performance for 4-GPU systems, capturing 83{\%} of available performance opportunity. On a 16-GPU NVIDIA DGX-2 system, we demonstrate an 11.0× average strong-scaling speedup over single-GPU performance, 5.3× better than a bulk DMA-based approach.},
  author          = {Muthukrishnan, Harini and Nellans, David and Lustig, Daniel and Fessler, Jeffrey A. and Wenisch, Thomas F.},
  booktitle       = {Proceedings of the IEEE/ACM International Symposium on Computer Architecture (ISCA)},
  doi             = {10.1109/ISCA52012.2021.00020},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the IEEEACM International Symposium on Computer Architecture (ISCA)/Efficient multi-GPU shared memory via automatic optimization of fine-grained transfers - Muthukrishnan et al. - Proceedi.pdf:pdf},
  isbn            = {9781665433334},
  issn            = {10636897},
  keywords        = {Data movement,GPGPU,GPU,GPU memory management,Heterogeneous systems,Multi-GPU,Multi{\_}GPU,Strong scaling},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,Multi{\_}GPU},
  pages           = {139--152},
  title           = {{Efficient multi-GPU shared memory via automatic optimization of fine-grained transfers}},
  year            = {2021}
}
@article{Namashivayam2022,
  abstract        = {Modern heterogeneous supercomputing systems are comprised of compute blades that offer CPUs and GPUs. On such systems, it is essential to move data efficiently between these different compute engines across a high-speed network. While current generation scientific applications and systems software stacks are GPU-aware, CPU threads are still required to orchestrate data moving communication operations and inter-process synchronization operations. A new GPU stream-aware MPI communication strategy called stream-triggered (ST) communication is explored to allow offloading both computation and communication control paths to the GPU. The proposed ST communication strategy is implemented on HPE Slingshot Interconnects over a new proprietary HPE Slingshot NIC (Slingshot 11) using the supported triggered operations feature. Performance of the proposed new communication strategy is evaluated using a microbenchmark kernel called Faces, based on the nearest-neighbor communication pattern in the CORAL-2 Nekbone benchmark, over a heterogeneous node architecture consisting of AMD CPUs and GPUs.},
  archiveprefix   = {arXiv},
  arxivid         = {2208.04817},
  author          = {Namashivayam, Naveen and Kandalla, Krishna and White, Trey and Radcliffe, Nick and Kaplan, Larry and Pagel, Mark},
  eprint          = {2208.04817},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/arXiv/Exploring GPU Stream-Aware Message Passing using Triggered Operations - Namashivayam et al. - arXiv.pdf:pdf},
  journal         = {arXiv},
  keywords        = {GPU,MPI,Triggered},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,MPI,Triggered},
  pages           = {1--11},
  title           = {{Exploring GPU Stream-Aware Message Passing using Triggered Operations}},
  year            = {2022}
}
@misc{Narang2016,
  author        = {Narang, Sharan},
  keywords      = {Benchmark,Web},
  mendeley-tags = {Benchmark,Web},
  title         = {{DeepBench}},
  url           = {https://svail.github.io/DeepBench/},
  urldate       = {2020-07-12},
  year          = {2016}
}
@misc{Narang2017,
  author        = {Narang, Sharan and Diamos, Greg},
  keywords      = {Benchmark,Web},
  mendeley-tags = {Benchmark,Web},
  title         = {{An update to DeepBench with a focus on deep learning inference}},
  url           = {https://svail.github.io/DeepBench-update/},
  urldate       = {2020-07-12},
  year          = {2017}
}
@article{Network2002,
  author          = {Network, The Neural and Advancing, Is and Biology, Meets Marine},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2002/Brain/The Quadrics Network - Network, Advancing, Biology - Brain.pdf:pdf},
  journal         = {Brain},
  mendeley-groups = {ELEC-878},
  pages           = {6--10},
  title           = {{The Quadrics Network}},
  year            = {2002}
}
@inproceedings{Nguyen2021,
  abstract        = {Distributed training of Deep Neural Networks (DNNs) on High-Performance Computing (HPC) systems is becoming increasingly common. HPC systems dedicated entirely or mainly to Deep Learning (DL) workloads are becoming a reality. The collective communication overhead for calculating the average of weight gradients, e.g., an Allreduce operations, is one of the main factors limiting the scaling of data parallelism training. Several active efforts across different layers of the training stack including the training algorithms, parallelism strategy, communication algorithms, and system design have been proposed to cope with this communication challenge when scaling distributed training of DNNs. However, even with those methods, communication still becomes a bottleneck with the steady increase in model sizes, e.g., 100-10, 000s MB, and the number of compute nodes, e.g., 1, 000-10, 000s of GPUs.In this work, we investigate the benefits of co-design of Allreduce algorithms and the network system. We propose to replace the Fat-tree network topology with a variant of Distributed Loop Network topology that guarantees a fixed routing paths length between any pairs of computing nodes for the communication pattern of halving-doubling Allreduce algorithm. We also propose a technique to eliminate/mitigate the network contention.},
  author          = {Nguyen, Truong Thao and Wahib, Mohamed},
  booktitle       = {Proceedings of the IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)},
  doi             = {10.1109/CCGrid51090.2021.00049},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the IEEEACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)/An allreduce algorithm and network co-design for large-scale training of distributed deep learning - Nguy.pdf:pdf},
  isbn            = {9781728195865},
  keywords        = {Allreduce,Co{\_}design,Distributed Deep Learning,GPU,High Performance Computing (HPC),Interconnect,Interconnection networks,MPI},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Allreduce,Co{\_}design,GPU,Interconnect,MPI},
  pages           = {1--10},
  publisher       = {IEEE},
  title           = {{An allreduce algorithm and network co-design for large-scale training of distributed deep learning}},
  year            = {2021}
}
@inproceedings{Nguyen2018,
  abstract      = {Driven by the increase in complexity and size in Deep Learning models, training models on large-scale GPUs-accelerated clusters is becoming a commonplace. One of the main challenges for distributed training is the collective communication overhead for the very large message size: from several to hundreds of MB. In this paper, we exploit two hierarchical distributed-memory multi-leader allreduce algorithms optimized for GPU-accelerated clusters (named lr-lr and lr-rab). In which, one node performs the inter-node data transfer in parallel using other GPUs that are designated as node leaders. Each leader keeps and exchanges a partial result of local reduced values rather than the whole one. Hence we are capable of significantly reducing the time for injecting data into the internode network. We evaluate these algorithms on the discreteevent simulation Simgrid. We show that our algorithms, lr-lr and lr-rab, can cut down the execution time of an Allreduce microbenchmark that uses logical ring algorithm (lr) by up to 45{\%} and 51{\%}, respectively. In addition, saving the power consumption of network devices of up to 23{\%} and 32{\%} are projected.},
  author        = {Nguyen, Truong Thao and Wahib, Mohamed and Takano, Ryousei},
  booktitle     = {Proceedings of the International Symposium on Computing and Networking Workshops (CANDARW)},
  doi           = {10.1109/CANDARW.2018.00048},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the International Symposium on Computing and Networking Workshops (CANDARW)/Hierarchical distributed-memory multi-leader MPI-allreduce for deep learning workloads - Nguyen, Wahib, Takano -.pdf:pdf},
  isbn          = {9781538691847},
  keywords      = {Allreduce,Deep{\_}Learning,Distributed Deep Learning,Hierarchical,High Performance Computing,MPI,MPI{\_}Allreduce},
  mendeley-tags = {Deep{\_}Learning,Hierarchical,MPI,MPI{\_}Allreduce},
  pages         = {216--222},
  publisher     = {IEEE},
  title         = {{Hierarchical distributed-memory multi-leader MPI-allreduce for deep learning workloads}},
  year          = {2018}
}
@inproceedings{Nikolic2022,
  abstract        = {The CPU, GPU, and TPU are three different types of processing units. For the overall performance of the computer, the CPU is responsible. For delivering high-end graphics and video quality, the GPU is responsible. Along with the CPU, the GPU is a piece of additional hardware. TPU is used in the field of Artificial Intelligence, Machine Learning, and Deep Learning. Each of the three processing units has its own set of functions. This article may be of help to a reader with aim to understand the distinctions between the CPU, GPU, and TPU processing units.},
  author          = {Nikolic, Goran S. and Dimitrijevic, Bojan R. and Nikolic, Tatjana R. and Stojcev, Mile K.},
  booktitle       = {Proceedings of the International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST)},
  doi             = {10.1109/ICEST55168.2022.9828625},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST)/A Survey of Three Types of Processing Units CPU, GPU and TPU - Nikolic et.pdf:pdf},
  isbn            = {9781665485005},
  keywords        = {CPU,GPU,Survey,TPU,hardware accelerator},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,Survey,TPU},
  pages           = {1--6},
  title           = {{A Survey of Three Types of Processing Units: CPU, GPU and TPU}},
  year            = {2022}
}
@phdthesis{Nookala2022,
  author          = {Nookala, Poornima},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Unknown/Extreme Fine-Grained Parallelism on Modern Many-Core Architectures - Nookala - Unknown.pdf:pdf},
  keywords        = {GPU,Thesis},
  mendeley-groups = {MustKnow,Theses},
  mendeley-tags   = {GPU,Thesis},
  pages           = {1--164},
  school          = {Illinois Institute of Technology},
  title           = {{Extreme Fine-Grained Parallelism on Modern Many-Core Architectures}},
  year            = {2022}
}
@inproceedings{Nukada2021,
  author          = {Nukada, Akira},
  booktitle       = {Proceedings of the IEEE International Conference on Big Data (Big Data)},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the IEEE International Conference on Big Data (Big Data)/Performance Optimization of Allreduce Operation for Multi-GPU Systems - Nukada - Proceedings of the IEEE International Conference o.pdf:pdf},
  isbn            = {9781665439022},
  keywords        = {GPU,MPI,MPI{\_}Allreduce},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {GPU,MPI,MPI{\_}Allreduce},
  pages           = {3107--3112},
  publisher       = {IEEE},
  title           = {{Performance Optimization of Allreduce Operation for Multi-GPU Systems}},
  year            = {2021}
}
@inproceedings{Nukada2022,
  abstract        = {Allreduce is one of the important collective commu-nications used in distributed deep learning. We present a novel hybrid allreduce algorithm optimized for multi-GPU systems with NV-Link, which is current main computing platform for data-parallel distributed deep learning. The hybrid algorithm efficiently utilizes direct access to memory of peer GPU devices via the NV-Link. In addition to NV-Link, the hybrid algorithm employs PCI-Express network as extra bandwidth between GPU devices. To use the PCI-Express network we need to explicitly copy the data to host memory and these operations are software-pipelined. By selecting optimal parameters, the hybrid allreduce algorithm outperforms NVIDIA's NCCL library.},
  author          = {Nukada, Akira},
  booktitle       = {Proceedings of the International Conference on Big Data (Big Data)},
  doi             = {10.1109/bigdata52589.2021.9672073},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the International Conference on Big Data (Big Data)/Performance Optimization of Allreduce Operation for Multi-GPU Systems - Nukada - Proceedings of the International Conference on Big Data.pdf:pdf},
  isbn            = {9781665439022},
  keywords        = {Collectives,GPU,Multi{\_}Channel,Multi{\_}GPU},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,GPU,Multi{\_}Channel,Multi{\_}GPU},
  pages           = {1--6},
  publisher       = {IEEE},
  title           = {{Performance Optimization of Allreduce Operation for Multi-GPU Systems}},
  year            = {2022}
}
@article{Nuriyev2021,
  abstract        = {The performance of collective operations has been a critical issue since the advent of Message Passing Interface (MPI). Many algorithms have been proposed for each MPI collective operation but none of them proved optimal in all situations. Different algorithms demonstrate superior performance depending on the platform, the message size, the number of processes, etc. MPI implementations perform the selection of the collective algorithm empirically, executing a simple runtime decision function. While efficient, this approach does not guarantee the optimal selection. As a more accurate but equally efficient alternative, the use of analytical performance models of collective algorithms for the selection process was proposed and studied. Unfortunately, the previous attempts in this direction have not been successful. We revisit the analytical model-based approach and propose two innovations that significantly improve the selective accuracy of analytical models: (1) We derive analytical models from the code implementing the algorithms rather than from their high-level mathematical definitions. This results in more detailed and relevant models. (2) We estimate model parameters separately for each collective algorithm and include the execution of this algorithm in the corresponding communication experiment. We experimentally demonstrate the accuracy and efficiency of our approach using Open MPI broadcast and gather algorithms and two different Grid'5000 clusters and one supercomputer.},
  annote          = {T(m) = a + b.m},
  author          = {Nuriyev, Emin and Lastovetsky, Alexey},
  doi             = {10.1109/ACCESS.2021.3101689},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/IEEE Access/Efficient and Accurate Selection of Optimal Collective Communication Algorithms Using Analytical Performance Modeling - Nuriyev, Lastove.pdf:pdf},
  issn            = {21693536},
  journal         = {IEEE Access},
  keywords        = {Auto{\_}Tune,MPI,Message passing,collective communication algorithms,communication performance modeling},
  mendeley-groups = {Auto-Tuning},
  mendeley-tags   = {Auto{\_}Tune,MPI},
  pages           = {1--19},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  title           = {{Efficient and Accurate Selection of Optimal Collective Communication Algorithms Using Analytical Performance Modeling}},
  year            = {2021}
}
@article{Nuriyev2022a,
  abstract        = {The performance of collective communication operations determines the overall performance of MPI applications. Different algorithms have been developed and implemented for each MPI collective operation, but none proved superior in all situations. Therefore, MPI implementations have to solve the problem of selecting the optimal algorithm for the collective operation depending on the platform, the number of processes involved, the message size(s), etc. The current solution method is purely empirical. Recently, an alternative solution method using analytical performance models of collective algorithms has been proposed and proved both accurate and efficient for one-process-per-CPU configurations. The method derives the analytical performance models of algorithms from their code implementation rather than from high-level mathematical definitions, and estimates the parameters of the models separately for each algorithm. The method is network and topology oblivious and uses the Hockney model for point-to-point communications. In this paper, we extend that selection method to the case of clusters of multi-core processors, where each core of the platform runs a process of the MPI application. We present the proposed approach using Open MPI broadcast algorithms, and experimentally validate it on three different clusters of multi-core processors, Grisou, Gros and MareNostrum4.},
  author          = {Nuriyev, Emin and Rico-Gallego, Juan Antonio and Lastovetsky, Alexey},
  doi             = {10.1016/j.jpdc.2022.03.012},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Journal of Parallel and Distributed Computing/Model-based selection of optimal MPI broadcast algorithms for multi-core clusters - Nuriyev, Rico-Gallego, Lastovetsky - Journal of P(2).pdf:pdf},
  issn            = {07437315},
  journal         = {Journal of Parallel and Distributed Computing},
  keywords        = {Collective communication algorithms,Collectives,Communication performance modeling,MPI,Message passing,Multi-core clusters},
  mendeley-groups = {Auto-Tuning},
  mendeley-tags   = {Collectives,MPI},
  pages           = {1--16},
  title           = {{Model-based selection of optimal MPI broadcast algorithms for multi-core clusters}},
  year            = {2022}
}
@article{Nuriyev2022,
  abstract      = {The performance of collective communication operations determines the overall performance of MPI applications. Different algorithms have been developed and implemented for each MPI collective operation, but none proved superior in all situations. Therefore, MPI implementations have to solve the problem of selecting the optimal algorithm for the collective operation depending on the platform, the number of processes involved, the message size(s), etc. The current solution method is purely empirical. Recently, an alternative solution method using analytical performance models of collective algorithms has been proposed and proved both accurate and efficient for one-process-per-CPU configurations. The method derives the analytical performance models of algorithms from their code implementation rather than from high-level mathematical definitions, and estimates the parameters of the models separately for each algorithm. The method is network and topology oblivious and uses the Hockney model for point-to-point communications. In this paper, we extend that selection method to the case of clusters of multi-core processors, where each core of the platform runs a process of the MPI application. We present the proposed approach using Open MPI broadcast algorithms, and experimentally validate it on three different clusters of multi-core processors, Grisou, Gros and MareNostrum4.},
  author        = {Nuriyev, Emin and Rico-Gallego, Juan-Antonio and Lastovetsky, Alexey},
  doi           = {10.1016/j.jpdc.2022.03.012},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Journal of Parallel and Distributed Computing/Model-based selection of optimal MPI broadcast algorithms for multi-core clusters - Nuriyev, Rico-Gallego, Lastovetsky - Journal of Para.pdf:pdf},
  issn          = {07437315},
  journal       = {Journal of Parallel and Distributed Computing},
  keywords      = {Broadcast,Collectives,MPI,Modeling},
  mendeley-tags = {Broadcast,Collectives,MPI,Modeling},
  pages         = {1--16},
  publisher     = {Elsevier Inc.},
  title         = {{Model-based selection of optimal MPI broadcast algorithms for multi-core clusters}},
  year          = {2022}
}
@techreport{NVIDIACorporation2015,
  author          = {{NVIDIA Corporation}},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Unknown/Gpudirect Integrating the Gpu With a Network Interface - NVIDIA Corporation - Unknown.pdf:pdf},
  keywords        = {GPU,GPUDirect{\_}RDMA},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {GPU,GPUDirect{\_}RDMA},
  title           = {{Gpudirect : Integrating the Gpu With a Network Interface}},
  year            = {2015}
}
@techreport{NVIDIACorporation2019,
  author          = {{NVIDIA Corporation}},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Unknown/Multi-process service - NVIDIA Corporation - Unknown.pdf:pdf},
  keywords        = {GPU,MPS},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {GPU,MPS},
  number          = {November},
  title           = {{Multi-process service}},
  year            = {2019}
}
@techreport{NVIDIACorporation2020a,
  author          = {{NVIDIA Corporation}},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Unknown/NVIDIA Ampere Software Deep Dive - NVIDIA Corporation - Unknown.pdf:pdf},
  keywords        = {CUDA,CUDA{\_}Features,GPU},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {CUDA,CUDA{\_}Features,GPU},
  title           = {{NVIDIA Ampere Software Deep Dive}},
  year            = {2020}
}
@book{NVIDIACorporation2020b,
  author          = {{NVIDIA Corporation}},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Unknown/CUDA C Best Practices Guide - NVIDIA Corporation - Unknown.pdf:pdf},
  keywords        = {C++,CPP,CUDA,GPU},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {C++,CPP,CUDA,GPU},
  number          = {October},
  title           = {{CUDA C Best Practices Guide}},
  year            = {2020}
}
@techreport{NVIDIACorporation2020,
  author          = {{NVIDIA Corporation}},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Unknown/GPU Application Catalogue - NVIDIA Corporation - Unknown.pdf:pdf},
  keywords        = {Applications,CUDA,GPU,Libraries,Library},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {Applications,CUDA,GPU,Libraries,Library},
  title           = {{GPU Application Catalogue}},
  year            = {2020}
}
@inproceedings{Oden2013,
  abstract      = {Modern GPUs are powerful high-core-count processors, which are no longer used solely for graphics applications, but are also employed to accelerate computationally intensive general-purpose tasks. For utmost performance, GPUs are distributed throughout the cluster to process parallel programs. In fact, many recent high-performance systems in the TOP500 list are heterogeneous architectures. Despite being highly effective processing units, GPUs on different hosts are incapable of communicating without assistance from a CPU. As a result, communication between distributed GPUs suffers from unnecessary overhead, introduced by switching control flow from GPUs to CPUs and vice versa. Most communication libraries even require intermediate copies from GPU memory to host memory. This overhead in particular penalizes small data movements and synchronization operations, reduces efficiency and limits scalability. In this work we introduce global address spaces to facilitate direct communication between distributed GPUs without CPU involvement. Avoiding context switches and unnecessary copying dramatically reduces communication overhead. We evaluate our approach using a variety of workloads including low-level latency and bandwidth benchmarks, basic synchronization primitives like barriers, and a stencil computation as an example application. We see performance benefits of up to 2× for basic benchmarks and up to 1.67× for stencil computations. {\textcopyright} 2013 IEEE.},
  author        = {Oden, Lena and Froning, Holger},
  booktitle     = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi           = {10.1109/CLUSTER.2013.6702638},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2013/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/GGAS Global GPU address spaces for efficient communication in heterogeneous clusters - Oden, Froning - Proceedings of the I.pdf:pdf},
  isbn          = {9781479908981},
  issn          = {15525244},
  keywords      = {GPU,GPU communication,MPI,bulk-synchronous execution,hybrid computing clusters,parallel processing},
  mendeley-tags = {GPU,MPI},
  pages         = {1--8},
  title         = {{GGAS: Global GPU address spaces for efficient communication in heterogeneous clusters}},
  year          = {2013}
}
@inproceedings{Oden2014,
  abstract      = {GPUs gain high popularity in High Performance Computing, due to their massive parallelism and high performance per Watt. Despite their popularity, data transfer between multiple GPUs in a cluster remains a problem. Most communication models require the CPU to control the data flow, also intermediate staging copies to host memory are often inevitable. These two facts lead to higher CPU and memory utilization. As a result, overall performance decreases and power consumption increases. Collective operations like reduce and all reduce are very common in scientific simulations and also very sensitive to performance. Due to their massive parallelism, GPUs are very suitable for such operations, but they only excel in performance if they can process the problem in-core. Global GPU Address Spaces (GGAS) enable a direct GPU-to-GPU communication for heterogeneous clusters, which is completely in-line with the GPU's thread-collective execution model and does not require CPU assistance or staging copies in host memory. As we will see, GGAS helps to process collective operations among distributed GPUs in-core. In this paper, we introduce the implementation and optimization of collective reduce and all reduce operations using GGAS as a communication model. Compared to message passing, we get a speedup of 1.7x for small data sizes. A detailed analysis based on power measurements of CPU, host memory and GPU reveals that GGAS as communication model not only saves cycles, also the power and energy consumption is reduced dramatically. For instance, for an all reduce operation half of the energy can be saved by the reduced the power consumption in combination with the lower run time. {\textcopyright} 2014 IEEE.},
  author        = {Oden, Lena and Klenk, Benjamin and Fr{\"{o}}ning, Holger},
  booktitle     = {Proceedings of the IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)},
  doi           = {10.1109/CCGrid.2014.21},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Proceedings of the IEEEACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)/Energy-efficient collective reduce and allreduce operations on distributed gpus - Oden, Klenk, Fr{\"{o}}ning -.pdf:pdf},
  isbn          = {9781479927838},
  keywords      = {Collective Operations,Collectives,Data Transfer,Energy,GPUs,Global Address Space,MPI,Power},
  mendeley-tags = {Collectives,Energy,MPI},
  pages         = {483--492},
  title         = {{Energy-efficient collective reduce and allreduce operations on distributed gpus}},
  year          = {2014}
}
@phdthesis{Ouyang2022,
  abstract        = {Delays in the development of early literacy skills are associated with a wrath of negative educational outcomes and so addressing such delays is one of the most pressing challenges in education. This study examines the effectiveness of the Orton-Gillingham (OG) Method, a multisensory reading program where instruction utilizes two or more senses simultaneously. Originally developed in the 1930s as a program for dyslexic students, OG has seen continual use since its creation and is endorsed by the American Dyslexic Foundation and the International Dyslexic Foundation. Over the past two decades OG has increasingly been incorporated into general education settings in the primary grades as a reading intervention for struggling readers regardless of whether they have dyslexia. However, there is a dearth of research demonstrating its causal effect as a reading intervention for children with dyslexia or who are experiencing reading delays for other reasons. Two quasi-experimental methods, Regression Discontinuity Design and Nonequivalent Comparison Group Design with propensity scores, are used to test the.efficacy of an OG-based, general education reading intervention on a sample of over 700 kindergarten and first grade students who are experiencing reading delays from a large district in California. The Dynamic Indicators of Basic Early Literacy Skills (DIBELS) assessments were used to assign students to the intervention and measure their end-of- year reading outcomes. The results of both analyses revealed no effect for students enrolled in the intervention in either kindergarten or first grade. Within the year that students received the intervention, a small but non-significant gain on end-of-year DIBELS composite scores was found. Long-term outcomes showed that over half of the students in the intervention were still not meeting reading targets by the end of second grade. Moreover, while the treatment effect was found to vary significantly across classrooms and across schools, no available measures classroom or school characteristics where associated with that variation. These findings suggest that certain applications of the OG methodologies may not be effective in general education settings.},
  author          = {Ouyang, Kaiming},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Unknown/Exploring Interprocess Techniques for High-Performance MPI Communication - Ouyang - Unknown.pdf:pdf},
  isbn            = {9783319208893},
  issn            = {0100-6916},
  keywords        = {Load{\_}Balancing,MPI,Thesis},
  mendeley-groups = {MustKnow,Theses},
  mendeley-tags   = {Load{\_}Balancing,MPI,Thesis},
  pages           = {1--152},
  school          = {UNIVERSITY OF CALIFORNIA RIVERSIDE},
  title           = {{Exploring Interprocess Techniques for High-Performance MPI Communication}},
  year            = {2022}
}
@article{Ouyang2021,
  abstract        = {Recent trends in high-performance computing and deep learning have led to the proliferation of studies on large-scale deep neural network training. However, the frequent communication requirements among computation nodes drastically slow the overall training speeds, which causes bottlenecks in distributed training, particularly in clusters with limited network bandwidths. To mitigate the drawbacks of distributed communications, researchers have proposed various optimization strategies. In this paper, we provide a comprehensive survey of communication strategies from both an algorithm viewpoint and a computer network perspective. Algorithm optimizations focus on reducing the communication volumes used in distributed training, while network optimizations focus on accelerating the communications between distributed devices. At the algorithm level, we describe how to reduce the number of communication rounds and transmitted bits per round. In addition, we elucidate how to overlap computation and communication. At the network level, we discuss the effects caused by network infrastructures, including logical communication schemes and network protocols. Finally, we extrapolate the potential future challenges and new research directions to accelerate communications for distributed deep neural network training.},
  archiveprefix   = {arXiv},
  arxivid         = {2003.03009},
  author          = {Ouyang, Shuo and Dong, Dezun and Xu, Yemao and Xiao, Liquan},
  doi             = {10.1016/j.jpdc.2020.11.005},
  eprint          = {2003.03009},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Journal of Parallel and Distributed Computing/Communication optimization strategies for distributed deep neural network training A survey - Ouyang et al. - Journal of Parallel and Di.pdf:pdf},
  journal         = {Journal of Parallel and Distributed Computing},
  keywords        = {Communication optimization,Deep{\_}Learning,Distributed deep learning,Network infrastructure,Parallel algorithms,Survey},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Deep{\_}Learning,Survey},
  pages           = {52--65},
  title           = {{Communication optimization strategies for distributed deep neural network training: A survey}},
  year            = {2021}
}
@inproceedings{Oyama2018,
  abstract      = {cuDNN is a low-level library that provides GPU kernels frequently used in deep learning. Specifically, cuDNN implements several equivalent convolution algorithms, whose performance and memory footprint may vary considerably, depending on the layer dimensions. When an algorithm is automatically selected by cuDNN, the decision is performed on a per-layer basis, and thus it often resorts to slower algorithms that fit the workspace size constraints. We present u-cuDNN, a thin wrapper library for cuDNN that transparently divides layers' mini-batch computation into multiple micro-batches, both on a single GPU and a heterogeneous set of GPUs. Based on Dynamic Programming and Integer Linear Programming (ILP), u-cuDNN enables faster algorithms by decreasing the workspace requirements. At the same time, u-cuDNN does not decrease the accuracy of the results, effectively decoupling statistical efficiency from the hardware efficiency. We demonstrate the effectiveness of u-cuDNN for the Caffe and TensorFlow frameworks, achieving speedups of 1.63x for AlexNet and 1.21x for ResNet-18 on the P100-SXM2 GPU. We also show that u-cuDNN achieves speedups of up to 4.54x, and 1.60x on average for DeepBench's convolutional layers on the V100-SXM2 GPU. In a distributed setting, u-cuDNN attains a speedup of 2.20x when training ResNet-18 on a heterogeneous GPU cluster over a single GPU. These results indicate that using micro-batches can seamlessly increase the performance of deep learning, while maintaining the same overall memory footprint.},
  author        = {Oyama, Yosuke and Ben-Nun, Tal and Hoefler, Torsten and Matsuoka, Satoshi},
  booktitle     = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi           = {10.1109/CLUSTER.2018.00058},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/Accelerating Deep Learning Frameworks with Micro-Batches - Oyama et al. - Proceedings of the IEEE International Conference.pdf:pdf},
  keywords      = {Convolutional neural networks,Deep learning,Deep{\_}Learning,GPU,Micro-batch,Performance tuning},
  mendeley-tags = {Deep{\_}Learning,GPU},
  pages         = {402--412},
  title         = {{Accelerating Deep Learning Frameworks with Micro-Batches}},
  year          = {2018}
}
@article{Pan2022,
  abstract      = {Distributed sparse deep learning has been widely used in many internet-scale applications. Network communication is one of the major hurdles for the training performance. In-network gradient aggregation on programmable switches is a promising solution to speed up the performance. Nevertheless,existing in-network aggregation solutions are designed for the distributed dense deep training, and fall short when used for the sparse deep training.To address this gap, we present Libra based on our key observation of the extremely biased update frequency of parameters in distributed deep sparse training. Specifically, Libra offloads only the aggregation for "hot" parameters that are updated frequently onto programmable switches. To enable this offloading and achieve high aggregation throughput, we propose solutions to address the challenges related to hot parameter identification, parameter orchestration, floating-point summation on switches as well as system reliability. We implemented Libra on Intel Tofino switches and integrated it with PS-lite. Finally, we evaluate Libra's performance through extensive experiments and show that Libra can speed up the gradient aggregation by 1.5{\~{}}4 times.},
  archiveprefix = {arXiv},
  arxivid       = {2205.05243},
  author        = {Pan, Heng and Cui, Penglai and Li, Zhenyu and Jia, Ru and Zhang, Penghao and Zhang, Leilei and Yang, Ye and Wu, Jiahao and Dong, Jianbo and Cao, Zheng and Li, Qiang and Liu, Hongqiang Harry and Laurent, Mathy and Xie, Gaogang},
  eprint        = {2205.05243},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/arXiv/Libra In-network Gradient Aggregation for Speeding up Distributed Sparse Deep Training - Pan et al. - arXiv.pdf:pdf},
  journal       = {arXiv},
  keywords      = {Deep{\_}Learning},
  mendeley-tags = {Deep{\_}Learning},
  pages         = {1--14},
  title         = {{Libra: In-network Gradient Aggregation for Speeding up Distributed Sparse Deep Training}},
  year          = {2022}
}
@inproceedings{Parsons2015,
  abstract        = {This work improves the performance of MPI collective communication operations in the presence of imbalanced process arrival times. High performance collective communications are crucial for the performance and scalability of applications, and imbalanced process arrival times are common in these applications. A micro-benchmark is used to investigate the nature of process imbalance with perfectly balanced workloads, and understand the nature of interversus intranode imbalance. These insights are then used to develop imbalance-tolerant reduction, broadcast, and all-to-all algorithms, which minimize the synchronization delay observed by early arriving processes. These algorithms have been implemented and tested on a Cray XE6 using up to 32k cores with varying buffer sizes and levels of imbalance. Results show speedups over MPICH averaging 18.9x for reduce, 5.3x for broadcast, and 6.9x for all-to-all in the presence of high, but not unreasonable, imbalance.},
  author          = {Parsons, Benjamin S. and Pai, Viajy S.},
  booktitle       = {Proceedings of the International Conference on Supercomputing (ICS)},
  doi             = {10.1145/2751205.2751242},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Proceedings of the International Conference on Supercomputing (ICS)/Exploiting process imbalance to improve MPI collective operations in hierarchical systems - Parsons, Pai - Proceedings of the Internati.pdf:pdf},
  isbn            = {9781450335591},
  keywords        = {Collectives,MPI,PAP},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {Collectives,MPI,PAP},
  pages           = {57--66},
  title           = {{Exploiting process imbalance to improve MPI collective operations in hierarchical systems}},
  year            = {2015}
}
@inproceedings{Parsons2014,
  abstract      = {This paper presents and evaluates a universal algorithm to improve the performance of MPI collective communication operations on hierarchical clusters with many-core nodes. This algorithm exploits shared-memory buffers for efficient intra-node communication while still allowing the use of unmodified, hierarchy-unaware traditional collectives for inter-node communication (including collectives like Alltoallv). This algorithm improves on past works that convert a specific collective algorithm into a hierarchical version and are generally restricted to fan-in, fan-out, and All gather algorithms. Experimental results show impressive performance improvements utilizing a variety of collectives from MPICH as well as the closed-source Cray MPT for the inter-node communication. The experimental evaluation tests the new algorithms with as many as 65536 cores and sees speedups over the baseline averaging 14.2x for Alltoallv, 26x for All gather, and 32.7x for Reduce-Scatter. The paper further improves inter-node communication by utilizing multiple senders from the same shared memory buffer, achieving additional speedups averaging 2.5x. The discussion also evaluates special-purpose extensions to improve intra-node communication by returning shared memory or copy-on-write protected buffers from the collective. {\textcopyright} 2014 IEEE.},
  author        = {Parsons, Benjamin S. and Pai, Vijay S.},
  booktitle     = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi           = {10.1109/IPDPS.2014.32},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/Accelerating MPI collective communications through hierarchical algorithms without sacrificing inter-node commu.pdf:pdf},
  isbn          = {9780769552071},
  issn          = {23321237},
  keywords      = {Collectives,Hierarchical,Inter{\_}node,MPI},
  mendeley-tags = {Collectives,Hierarchical,Inter{\_}node,MPI},
  pages         = {208--218},
  publisher     = {IEEE},
  title         = {{Accelerating MPI collective communications through hierarchical algorithms without sacrificing inter-node communication flexibility}},
  year          = {2014}
}
@inproceedings{Patinyasakdikul2019a,
  abstract        = {The Message Passing Interface (MPI) has been one of the most prominent programming paradigms in high-performance computing (HPC) for the past decade. Lately, with changes in modern hardware leading to a drastic increase in the number of processor cores, developers of parallel applications are moving toward more integrated parallel programming paradigms, where MPI is used along with other, possibly node-level, programming paradigms, or MPI+X. MPI+threads emerged as one of the favorite choices in HPC community, according to a survey of the HPC community. However, threading support in MPI comes with many compromises to the overall performance delivered, and, therefore, its adoption is compromised.This paper studies in depth the MPI multi-threaded implementation design in one of the leading MPI implementations, Open MPI, and expose some of the shortcomings of the current design. We propose, implement, and evaluate a new design of the internal handling of communication progress which allows for a significant boost in multi-threading performance, increasing the viability of MPI in the MPI+X programming paradigm.},
  author          = {Patinyasakdikul, Thananon and Eberius, David and Bosilca, George and Hjelm, Nathan},
  booktitle       = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi             = {10.1109/CLUSTER.2019.8891015},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/Give MPI Threading a Fair Chance A Study of Multithreaded MPI Designs - Patinyasakdikul et al. - Proceedings of the IEEE In.pdf:pdf},
  isbn            = {9781728147345},
  issn            = {15525244},
  keywords        = {Hybrid{\_}MPI,Message{\_}Matching,Multithreaded{\_}MPI,hybrid MPI+threads,message passing,threads},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {Hybrid{\_}MPI,Message{\_}Matching,Multithreaded{\_}MPI},
  pages           = {1--11},
  title           = {{Give MPI Threading a Fair Chance: A Study of Multithreaded MPI Designs}},
  year            = {2019}
}
@inproceedings{Patinyasakdikul2019,
  abstract      = {As the modern hardware landscape continues to drastically change, the degree of parallelism required to maintain a high occupancy of resources has substantially increased. These hardware changes have highlighted the limitations of the traditional method of using one process per processing unit, which indicates that a more flexible programming paradigm is necessary. In the context of the message passing paradigm, MPI needs a significant improvement in threaded performance in order to fully utilize all hardware capabilities. However, for developers to know what needs to be improved, and for users to know what performance to expect, benchmarks are needed to quickly assess the capabilities and performance of MPI implementations. This paper introduces a new communication benchmark designed to replicate typical application communication patterns and assess their performance with a varied amount of resources. We evaluate three MPI implementations with our benchmark suite and assess their strengths and weaknesses.},
  author        = {Patinyasakdikul, Thananon and Luo, Xi and Eberius, David and Bosilca, George},
  booktitle     = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi           = {10.1109/ExaMPI49596.2019.00006},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Multirate A Flexible MPI Benchmark for Fast Assessment of Multithreaded Communication Per.pdf:pdf},
  isbn          = {9781728160092},
  keywords      = {Benchmark,MPI,Multithreaded{\_}MPI},
  mendeley-tags = {Benchmark,MPI,Multithreaded{\_}MPI},
  pages         = {1--11},
  title         = {{Multirate: A Flexible MPI Benchmark for Fast Assessment of Multithreaded Communication Performance}},
  year          = {2019}
}
@article{Pearson2018,
  abstract      = {High-performance computing increasingly relies on heterogeneous systems with specialized hardware accelerators to improve application performance. For example, NVIDIA{\&}{\#}x2019;s CUDA programming system and general-purpose GPUs have emerged as a widespread accelerator in HPC systems. This trend has exacerbated challenges of data placement as accelerators often have fast local memories to fuel their computational demands, but slower interconnects to feed those memories. Crucially, real-world data-transfer performance is strongly influenced not just by the underlying hardware, but by the capabilities of the programming systems. Understanding how application performance is affected by the logical communication exposed through abstractions, as well as the underlying system topology, is crucial for developing high-performance applications and architectures. This report presents initial data-transfer microbenchmark results from two POWER-based systems obtained during work towards developing an automated system performance characterization tool.},
  author        = {Pearson, Carl and Chung, I. Hsin and Sura, Zehra and Hwu, Wen Mei and Xiong, Jinjun},
  doi           = {10.1007/978-3-030-02465-9_32},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Lecture Notes in Computer Science/NUMA-Aware Data-Transfer Measurements for PowerNVLink Multi-GPU Systems - Pearson et al. - Lecture Notes in Computer Science.pdf:pdf},
  isbn          = {9783030024642},
  issn          = {16113349},
  journal       = {Lecture Notes in Computer Science},
  keywords      = {Benchmark,CUDA,GPGPU,GPU,Multi{\_}GPU,NUMA,NVLink,Unified Memory},
  mendeley-tags = {GPU,Multi{\_}GPU,NUMA,NVLink},
  pages         = {448--454},
  title         = {{NUMA-Aware Data-Transfer Measurements for Power/NVLink Multi-GPU Systems}},
  volume        = {11203 LNCS},
  year          = {2018}
}
@inproceedings{Pearson2019,
  abstract        = {Data-intensive applications such as machine learning and analyt-ics have created a demand for faster interconnects to avert the memory bandwidth wall and allow GPUs to be effectively leveraged for lower compute intensity tasks. This has resulted in wide adoption of heterogeneous systems with varying underlying interconnects, and has delegated the task of understanding and copying data to the system or application developer. No longer is a malloc followed by memcpy the only or dominating modality of data transfer; application developers are faced with additional options such as unified memory and zero-copy memory. Data transfer performance on these systems is now impacted by many factors including data transfer modality, system interconnect hardware details, CPU caching state, CPU power management state, driver policies, virtual memory paging efficiency, and data placement. This paper presents Comm|Scope, a set of microbenchmarks designed for system and application developers to understand memory transfer behavior across different data placement and exchange scenarios. Comm|Scope comprehensively measures the latency and bandwidth of CUDA data transfer primitives, and avoids common pitfalls in ad-hoc measurements by controlling CPU caches, clock frequencies, and avoids measuring synchronization costs imposed by the measurement methodology where possible. This paper also presents an evaluation of Comm|Scope on systems featuring the POWER and x86 CPU architectures and PCIe 3, NVLink 1, and NVLink 2 interconnects. These systems are chosen as representative configurations of current high-performance GPU platforms. Comm|Scope measurements can serve to update insights about the relative performance of data transfer methods on current systems. This work also reports insights for how high-level system design choices affect the performance of these data transfers, and how developers can optimize applications on these systems.},
  author          = {Pearson, Carl and Dakkak, Abdul and Hashash, Sarah and Li, Cheng and Chung, I. Hsin and Xiong, Jinjun and Hwu, Wen Mei},
  booktitle       = {Proceedings of the International Conference on Performance Engineering (ICPE)},
  doi             = {10.1145/3297663.3310299},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Conference on Performance Engineering (ICPE)/Evaluating characteristics of CUDA communication primitives on high-bandwidth interconnects - Pearson et al. - Proceedings of.pdf:pdf},
  isbn            = {9781450362399},
  keywords        = {Benchmarking,CUDA,GPU,NUMA,NVLink,POWER,X86},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {CUDA,GPU,NVLink},
  pages           = {209--218},
  title           = {{Evaluating characteristics of CUDA communication primitives on high-bandwidth interconnects}},
  year            = {2019}
}
@inproceedings{Pearson2019a,
  abstract        = {Data-intensive applications such as machine learning and analyt-ics have created a demand for faster interconnects to avert the memory bandwidth wall and allow GPUs to be effectively lever-aged for lower compute intensity tasks. This has resulted in wide adoption of heterogeneous systems with varying underlying interconnects , and has delegated the task of understanding and copying data to the system or application developer. No longer is a malloc followed by memcpy the only or dominating modality of data transfer ; application developers are faced with additional options such as unified memory and zero-copy memory. Data transfer performance on these systems is now impacted by many factors including data transfer modality, system interconnect hardware details, CPU caching state, CPU power management state, driver policies, virtual memory paging efficiency, and data placement. This paper presents Comm|Scope, a set of microbenchmarks designed for system and application developers to understand memory transfer behavior across different data placement and exchange scenarios. Comm|Scope comprehensively measures the latency and bandwidth of CUDA data transfer primitives, and avoids common pitfalls in ad-hoc measurements by controlling CPU caches, clock frequencies, and avoids measuring synchronization costs imposed by the measurement methodology where possible. This paper also presents an evaluation of Comm|Scope on systems featuring the POWER and x86 CPU architectures and PCIe 3, NVLink 1, and NVLink 2 interconnects. These systems are chosen as representative configurations of current high-performance GPU platforms. Comm|Scope measurements can serve to update insights about the relative performance of data transfer methods on current systems. This work also reports insights for how high-level system design choices affect the performance of these data transfers, and how developers can optimize applications on these systems.},
  author          = {Pearson, Carl and Dakkak, Abdul and Hashash, Sarah and Li, Cheng and Chung, I-Hsin and Xiong, Jinjun and Hwu, Wen-Mei},
  booktitle       = {Proceedings of the International Conference on Performance Engineering (ICPE)},
  doi             = {10.1145/3297663.3310299},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Conference on Performance Engineering (ICPE)/Evaluating Characteristics of CUDA Communication Primitives on High-Bandwidth Interconnects - Pearson et al. - Proceedings(2).pdf:pdf},
  isbn            = {9781450362399},
  keywords        = {CUDA,Interconnect},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {CUDA,Interconnect},
  pages           = {1--10},
  publisher       = {ACM},
  title           = {{Evaluating Characteristics of CUDA Communication Primitives on High-Bandwidth Interconnects}},
  year            = {2019}
}
@inproceedings{Penna2013,
  abstract        = {Data movement is of high relevance for GPU Computing. Communication and performance efficiencies of applications and systems with GPU accelerators depend on onand off-node data paths, thereby making tuning and optimization an increasingly complex task. In this paper we conduct an in-depth study to establish the parameters that influence performance of data transfers between on-node GPU devices, and located on separate nodes (off-node). We compare the most recent version of MVAPICH2 featuring seamless remote GPU transfers with our own low-level benchmarks, and discuss the bottlenecks that may arise. Data path performance and bottlenecks between GPU devices are analyzed and compared for two substantially different systems: an IBM iDataPlex relying on an InfiniBand QDR fabric with two on-node GPU devices, and a Cray XK6, featuring a single GPU per node, and connected through a Gemini interconnect. Finally, we adapt LAMMPS, a GPU-accelerated application, to benefit from efficient inter-GPU data transfers, and validate our findings. {\textcopyright} 2013 IEEE.},
  author          = {Pe{\~{n}}na, Antonio J. and Alam, Sadaf R.},
  booktitle       = {Proceedings of the IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)},
  doi             = {10.1109/CCGrid.2013.15},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2013/Proceedings of the IEEEACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)/Evaluation of inter- and intra-node data transfer efficiencies between gpu devices and their impact on sc.pdf:pdf},
  isbn            = {9780769549965},
  keywords        = {Cluster computing,GPU,GPU computing,High performance computing,Inter{\_}node,Intra{\_}node,Performance evaluation},
  mendeley-groups = {MustKnow,UsedInComp1,UsedInComp2},
  mendeley-tags   = {GPU,Inter{\_}node,Intra{\_}node},
  pages           = {144--151},
  title           = {{Evaluation of inter- and intra-node data transfer efficiencies between gpu devices and their impact on scalable applications}},
  year            = {2013}
}
@techreport{Perelygin2017,
  author          = {Perelygin, Kyrylo and Lin, Yuan},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Unknown/Cooperative Groups - Perelygin, Lin - Unknown.pdf:pdf},
  keywords        = {CUDA,CUDA{\_}Features,Cooperative{\_}Groups,GPU},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {CUDA,CUDA{\_}Features,Cooperative{\_}Groups,GPU},
  title           = {{Cooperative Groups}},
  year            = {2017}
}
@article{Petrini2003,
  abstract        = {In this paper we describe how we improved the effective performance of ASCI Q, the world's second-fastest supercomputer, to meet our expectations. Using an arsenal of performance-analysis techniques including analytical models, custom microbenchmarks, full applications, and simulators, we succeeded in observing a serious-but previously undetected-performance problem. We identified the source of the problem, eliminated the problem, and "closed the loop" by demonstrating up to a factor of 2 improvement in application performance. We present our methodology and provide insight into performance analysis that is immediately applicable to other large-scale supercomputers. {\textcopyright} 2003 ACM.},
  author          = {Petrini, Fabrizio and Kerbyson, Darren J. and Pakin, Scott},
  doi             = {10.1145/1048935.1050204},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2003/Unknown/The Case of the Missing Supercomputer Performance - Petrini, Kerbyson, Pakin - Unknown.pdf:pdf},
  isbn            = {1581136951},
  mendeley-groups = {ELEC-878},
  number          = {November 2002},
  pages           = {55},
  title           = {{The Case of the Missing Supercomputer Performance}},
  year            = {2003}
}
@inproceedings{Pfisterer2021,
  abstract      = {Stencil codes are valuable methods to solve partial differential equations of models in a wide range of applications in science and engineering. Graphics processing units (GPUs) provide a highly parallel architecture with fast directly accessible memory that is desirable to run stencil codes. They enable larger and more complex simulations that are solved faster compared to simulating on CPUs. We provide a solution for users to run highly parallel stencil codes on GPUs, that can also be efficiently used on a distributed GPU cluster.In this work, we present an extension to the multi-disciplinary framework NAStJA originally designed to efficiently run stencil codes on the CPUs in current high-performance computing (HPC) systems, to also be able to run on GPUs. We describe different methods to increase the performance of stencil codes on GPUs like a border exchange method which is transparent to the user, as well as a buffer for gradient values that are needed multiple times. We show their performance using the phase-field method as a stencil code example.With this GPU extension and optimizations implemented into the NAStJA framework, we can show highly improved performance compared to the CPU implementation, and an efficiency of 92{\%} (weak scaling) for a large-scale example simulation on 64 GPUs on the ForHLR II HPC system.},
  author        = {Pfisterer, Nikolai and Berghoff, Marco and Streit, Achim},
  booktitle     = {Proceedings of the Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)},
  doi           = {10.1109/PDP52278.2021.00043},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)/On GPU optimizations of stencil codes for highly parallel simulations - Pfisterer, Bergho.pdf:pdf},
  keywords      = {CUDA,GPU,GPU optimizations,Multi{\_}GPU,heterogeneous parallelization,scalability analysis,stencil code},
  mendeley-tags = {CUDA,GPU,Multi{\_}GPU},
  pages         = {228--235},
  title         = {{On GPU optimizations of stencil codes for highly parallel simulations}},
  year          = {2021}
}
@inproceedings{Pjesivac-Grbovic2004,
  abstract        = {Previous studies of application usage show that the performance of collective communications are critical for high-performance computing. Despite active research in the field, both general and feasible solution to the optimization of collective communication problem is still missing. In this paper, we analyze and attempt to improve intra-cluster collective communication in the context of the widely deployed MPI programming paradigm by extending accepted models of point-to-point communication, such as Hockney, LogP/LogGP, and PLogP, to collective operations. We compare the predictions from models against the experimentally gathered data and using these results, construct optimal decision function for broadcast collective. We quantitatively compare the quality of the model-based decision functions to the experimentally-optimal one. Additionally, in this work, we also introduce a new form of an optimized tree-based broadcast algorithm, splitted-binary. Our results show that all of the models can provide useful insights into various aspects of the different algorithms as well as their relative performance. Still, based on our findings, we believe that the complete reliance on models would not yield optimal results. In addition, our experimental results have identified the gap parameter as being the most critical for accurate modeling of both the classical point-to-point-based pipeline and our extensions to fan-out topologies. {\textcopyright} Springer Science+Business Media, LLC 2007.},
  author          = {Pje{\v{s}}ivac-Grbovi{\'{c}}, Jelena and Angskun, Thara and Bosilca, George and Fagg, Graham E. and Gabriel, Edgar and Dongarra, Jack J.},
  booktitle       = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi             = {10.1007/s10586-007-0012-0},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2004/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/Performance analysis of MPI collective operations - Pje{\v{s}}ivac-Grbovi{\'{c}} et al. - Proceedings of the IEEE Internati.pdf:pdf},
  issn            = {15731936},
  keywords        = {Collectives,Hockney,LogGP,LogP,MPI,MPI collective communication,Modeling,PLogP,Parallel communication models,Performance modeling},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,MPI,Modeling},
  number          = {2},
  pages           = {127--143},
  title           = {{Performance analysis of MPI collective operations}},
  volume          = {10},
  year            = {2004}
}
@inproceedings{Potluri2012,
  abstract        = {Many modern clusters are being equipped with multiple GPUs per node to achieve better compute density and power efficiency. However, moving data in/out of GPUs continues to remain a major performance bottleneck. With CUDA 4.1, NVIDIA has introduced Inter-Process Communication (IPC) to address data movement overheads between processes using different GPUs connected to the same node. State-of-the-art MPI libraries like MVAPICH2 are being modified to allow application developers to use MPI calls directly over GPU device memory. This improves the programmability for application developers by removing the burden of dealing with complex data movement optimizations. In this paper, we propose efficient designs for intra-node MPI communication on multi-GPU nodes, taking advantage of IPC capabilities provided in CUDA. We also demonstrate how MPI one-sided communication semantics can provide better performance and overlap by taking advantage of IPC and the Direct Memory Access (DMA) engine on a GPU. We demonstrate the effectiveness of our designs using micro-benchmarks and an application. The proposed designs improve GPU-to-GPU MPI Send/Receive latency for 4MByte messages by 79{\%} and achieve 4 times the bandwidth for the same message size. One-sided communication using Put and Active synchronization shows 74{\%} improvement in latency for 4MByte message, compared to the existing Send/Receive based implementation. Our benchmark using Get and Passive Synchronization demonstrates that true asynchronous progress can be achieved using IPC and the GPU DMA engine. Our designs for two-sided and one-sided communication improve the performance of GPULBM, a CUDA implementation of Lattice Boltzmann Method for multiphase flows, by 16{\%}, compared to the performance using existing designs in MVAPICH2. To the best of our knowledge, this is the first paper to provide a comprehensive solution for MPI two-sided and one-sided GPU-to-GPU communication within a node, using CUDA IPC. {\textcopyright} 2012 IEEE.},
  author          = {Potluri, S. and Wang, H. and Bureddy, D. and Singh, A. K. and Rosales, C. and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
  doi             = {10.1109/IPDPSW.2012.228},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2012/Proceedings of the IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)/Optimizing MPI communication on multi-GPU systems using CUDA inter-process communication - Potluri e.pdf:pdf},
  isbn            = {9780769546766},
  keywords        = {CUDA{\_}IPC,GPU,IPC,MPI,Multi{\_}GPU},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {CUDA{\_}IPC,GPU,MPI,Multi{\_}GPU},
  pages           = {1848--1857},
  title           = {{Optimizing MPI communication on multi-GPU systems using CUDA inter-process communication}},
  year            = {2012}
}
@inproceedings{Potluri2018,
  abstract      = {GPUs have become an essential component for building compute clusters with high compute density and high performance per watt. As such clusters scale to have 1000s of GPUs, efficiently moving data between the GPUs becomes imperative to get maximum performance. NVSHMEM is an implementation of the OpenSHMEM standard for NVIDIA GPU clusters which allows communication to be issued from inside GPU kernels. In earlier work, we have shown how NVSHMEM can be used to achieve better application performance on GPUs connected through PCIe or NVLink. As part of this effort, we implement IB verbs for Mellanox InfiniBand adapters in CUDA. We evaluate different design alternatives, taking into consideration the relaxed memory model, automatic memory access coalescing and thread hierarchy on the GPU. We also consider correctness issues that arise in these designs. We take advantage of these designs transparently or through API extensions in NVSHMEM. With micro-benchmarks, we show that a Nvidia Pascal P100 GPU is able saturate the network bandwidth using only one or two of its 56 available streaming multiprocessors (SM). On a single GPU using a single IB EDR adapter, we achieve a throughput of around 90 million messages per second. In addition, we implement a 2dstencil application kernel using NVSHMEM and compare its performance with a CUDA-aware MPI-based implementation that uses GPUDirect RDMA. Speedups in the range of 23{\%} to 42{\%} are seen for input sizes large enough to fill the occupancy of Nvidia Pascal P100 GPUs on 2 to 4 nodes indicating that there are gains to be had by eliminating the CPU from the communication path when all computation runs on the GPU.},
  author        = {Potluri, Sreeram and Goswami, Anshuman and Rossetti, Davide and Newburn, C. J. and Venkata, Manjunath Gorentla and Imam, Neena},
  booktitle     = {Proceedings of the IEEE International Conference on High Performance Computing (HiPC)},
  doi           = {10.1109/HiPC.2017.00037},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the IEEE International Conference on High Performance Computing (HiPC)/GPU-Centric Communication on NVIDIA GPU Clusters with InfiniBand A Case Study with OpenSHMEM - Potluri et al. - Proce.pdf:pdf},
  isbn          = {9781538622933},
  keywords      = {CUDA,CUDA aware MPI,GPU,GPU initiated communication,GPUDirectAsync,GPUDirectRDMA,GPUDirect{\_}Async,GPUDirect{\_}RDMA,IB Verbs,InfiniBand,MPI,OpenSHMEM,PGAS},
  mendeley-tags = {CUDA,GPU,GPUDirect{\_}Async,GPUDirect{\_}RDMA,InfiniBand,MPI,OpenSHMEM},
  pages         = {253--262},
  title         = {{GPU-Centric Communication on NVIDIA GPU Clusters with InfiniBand: A Case Study with OpenSHMEM}},
  volume        = {2017-Decem},
  year          = {2018}
}
@article{Potluri2013a,
  abstract      = {Intel's Xeon Phi coprocessor, based on Many Integrated Core architecture, packs more than 1TFLOP of performance on a single chip and offers x86 compatibility. While MPI libraries can run out-of-the-box on the Xeon Phi coprocessors, it is critical to tune them for the new architecture and to redesign them using any new system level features offered in order to deliver performance. In this paper, we discuss the tuning and redesign of the MVAPICH2 MPI library for efficient intra-node and inter-node point-to-point communication on XeonPhi clusters with InfiniBand. We evaluate the designs using micro-benchmarks and application kernels. The results show significant improvements in performance of intra-MIC, intranode and internode communication. For the internode MIC-MIC path, the latency of 4M messages is reduced by 65{\%} and the bandwidth for the same message size is improved by 5 times. The designs show 50{\%} and 16{\%} improvement in performance of 3DStencil communication kernel and P3DFFT library on 32 and 8 nodes, respectively. We discuss the challenges involved in providing a further optimized MVAPICH2 MPI library for Xeon Phi clusters. {\textcopyright} 2013 IEEE.},
  author        = {Potluri, Sreeram and Hamidouche, Khaled and Bureddy, Devendar and Panda, Dhabaleswar K.},
  doi           = {10.1109/XSW.2013.8},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2013/Proceedings of the Extreme Scaling Workshop (XSW)/MVAPICH2-MIC A high performance MPI library for Xeon Phi clusters with infiniband - Potluri et al. - Proceedings of the Extreme Scaling.pdf:pdf},
  isbn          = {9781479936915},
  journal       = {Proceedings of the Extreme Scaling Workshop (XSW)},
  keywords      = {InfiniBand,MPI,Xeon{\_}Phi},
  mendeley-tags = {InfiniBand,MPI,Xeon{\_}Phi},
  pages         = {25--32},
  publisher     = {IEEE},
  title         = {{MVAPICH2-MIC: A high performance MPI library for Xeon Phi clusters with infiniband}},
  volume        = {1},
  year          = {2013}
}
@inproceedings{Potluri2013,
  abstract        = {GPUs and accelerators have become ubiquitous in modern supercomputing systems. Scientific applications from a wide range of fields are being modified to take advantage of their compute power. However, data movement continues to be a critical bottleneck in harnessing the full potential of a GPU. Data in the GPU memory has to be moved into the host memory before it can be sent over the network. MPI libraries like MVAPICH2 have provided solutions to alleviate this bottleneck using techniques like pipelining. GPUDirect RDMA is a feature introduced in CUDA 5.0, that allows third party devices like network adapters to directly access data in GPU device memory, over the PCIe bus. NVIDIA has partnered with Mellanox to make this solution available for InfiniBand clusters. In this paper, we evaluate the first version of GPUDirect RDMA for InfiniBand and propose designs in MVAPICH2 MPI library to efficiently take advantage of this feature. We highlight the limitations posed by current generation architectures in effectively using GPUDirect RDMA and address these issues through novel designs in MVAPICH2. To the best of our knowledge, this is the first work to demonstrate a solution for internode GPU-to-GPU MPI communication using GPUDirect RDMA. Results show that the proposed designs improve the latency of internode GPU-to-GPU communication using MPI Send/MPI Recv by 69{\%} and 32{\%} for 4Byte and 128KByte messages, respectively. The designs boost the uni-directional bandwidth achieved using 4KByte and 64KByte messages by 2x and 35{\%}, respectively. We demonstrate the impact of the proposed designs using two end-applications: LBMGPU and AWP-ODC. They improve the communication times in these applications by upto 35{\%} and 40{\%}, respectively. {\textcopyright} 2013 IEEE.},
  author          = {Potluri, Sreeram and Hamidouche, Khaled and Venkatesh, Akshay and Bureddy, Devendar and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the International Conference on Parallel Processing (ICPP)},
  doi             = {10.1109/ICPP.2013.17},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2013/Proceedings of the International Conference on Parallel Processing (ICPP)/Efficient inter-Node MPI communication using GPUDirect RDMA for InfiniBand clusters with NVIDIA GPUs - Potluri et al. - Proceedin.pdf:pdf},
  isbn            = {9780769551173},
  issn            = {01903918},
  keywords        = {CUDA{\_}IPC,Clusters,GPU,GPUDirect RDMA,GPUDirect{\_}RDMA,InfiniBand,Infiniband,Inter{\_}node,MPI,PCI{\_}E,PCIe},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {CUDA{\_}IPC,GPU,GPUDirect{\_}RDMA,InfiniBand,Inter{\_}node,PCI{\_}E},
  pages           = {80--89},
  publisher       = {IEEE},
  title           = {{Efficient inter-Node MPI communication using GPUDirect RDMA for InfiniBand clusters with NVIDIA GPUs}},
  year            = {2013}
}
@article{Proficz2018,
  abstract        = {Two new algorithms for the all-reduce operation optimized for imbalanced process arrival patterns (PAPs) are presented: (1) sorted linear tree, (2) pre-reduced ring as well as a new way of online PAP detection, including process arrival time estimations, and their distribution between cooperating processes was introduced. The idea, pseudo-code, implementation details, benchmark for performance evaluation and a real case example for machine learning are provided. The results of the experiments were described and analyzed, showing that the proposed solution has high scalability and improved performance in comparison with the usually used ring and Rabenseifner algorithms.},
  author          = {Proficz, Jerzy},
  doi             = {10.1007/s11227-018-2356-z},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Journal of Supercomputing/Improving all-reduce collective operations for imbalanced process arrival patterns - Proficz - Journal of Supercomputing.pdf:pdf},
  issn            = {15730484},
  journal         = {Journal of Supercomputing},
  keywords        = {All-reduce,Collectives,MPI,PAP,Pre-reduced ring,Process arrival pattern,Sorted linear tree},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {Collectives,MPI,PAP},
  pages           = {3071--3092},
  publisher       = {Springer US},
  title           = {{Improving all-reduce collective operations for imbalanced process arrival patterns}},
  year            = {2018}
}
@article{Proficz2020,
  abstract        = {Imbalanced process arrival patterns (PAPs) are ubiquitous in many parallel and distributed systems, especially in HPC ones. The collective operations, e.g. in MPI, are designed for equal process arrival times, and are not optimized for deviations in their appearance. We propose eight new PAP-aware algorithms for the scatter and gather operations. They are binomial or linear tree adaptations introducing additional process ordering and (in some cases) additional activities in a special background thread. The solution was implemented using one of the most popular open source MPI compliant library (OpenMPI), and evaluated in a typical HPC environment using a specially developed benchmark as well as a real application: FFT. The experimental results show a significant advantage of the proposed approach over the default OpenMPI implementation, showing good scalability and high performance with the FFT acceleration for the communication run time: 16.7{\%} and for the total application execution time: 3.3{\%}.},
  author          = {Proficz, Jerzy},
  doi             = {10.1007/s10586-019-03040-x},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Cluster Computing/Process arrival pattern aware algorithms for acceleration of scatter and gather operations - Proficz - Cluster Computing.pdf:pdf},
  isbn            = {1058601903},
  issn            = {15737543},
  journal         = {Cluster Computing},
  keywords        = {Collectives,Gather,MPI,PAP,PAP-aware algorithm,Process arrival pattern,Scatter},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Collectives,MPI,PAP},
  pages           = {2735--2751},
  publisher       = {Springer US},
  title           = {{Process arrival pattern aware algorithms for acceleration of scatter and gather operations}},
  url             = {https://doi.org/10.1007/s10586-019-03040-x},
  year            = {2020}
}
@article{Proficz2021,
  abstract        = {Two novel algorithms for the all-gather operation resilient to imbalanced process arrival patterns (PATs) are presented. The first one, Background Disseminated Ring (BDR), is based on the regular parallel ring algorithm often supplied in MPI implementations and exploits an auxiliary background thread for early data exchange from faster processes to accelerate the performed all-gather operation. The other algorithm, Background Sorted Linear synchronized tree with Broadcast (BSLB), is built upon the already existing PAP-Aware gather algorithm, that is, Background Sorted Linear Synchronized tree (BSLS), followed by a regular broadcast distributing gathered data to all participating processes. The background of the imbalanced PAP subject is described, along with the PAP monitoring and evaluation topics. An experimental evaluation of the algorithms based on a proposed mini-benchmark is presented. The mini-benchmark was performed over 2,000 times in a typical HPC cluster architecture with homogeneous compute nodes. The obtained results are analyzed according to different PATs, data sizes, and process numbers, showing that the proposed optimization works well for various configurations, is scalable, and can significantly reduce the all-gather elapsed times, in our case, up to factor 1.9 or 47{\%} in comparison with the best state-of-The-Art solution.},
  author          = {Proficz, Jerzy},
  doi             = {10.1145/3460122},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/ACM Transactions on Architecture and Code Optimization/All-gather Algorithms Resilient to Imbalanced Process Arrival Patterns - Proficz - ACM Transactions on Architecture and Code Optimizatio.pdf:pdf},
  issn            = {15443973},
  journal         = {ACM Transactions on Architecture and Code Optimization},
  keywords        = {All-gather,Collectives,MPI,PAP,background disseminated ring,background sorted linear synchronized tree with br,process arrival pattern},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Collectives,MPI,PAP},
  pages           = {1--22},
  title           = {{All-gather Algorithms Resilient to Imbalanced Process Arrival Patterns}},
  year            = {2021}
}
@article{Proficz20201,
  abstract        = {The paper presents an evaluation of all-reduce collective MPI algorithms for an environment based on a geographically-distributed compute cluster. The testbed was split into two sites: CI TASK in Gdansk University of Technology and ICM in University of Warsaw, located about 300 km from each other, both connected by a fast optical fiber Ethernet-based 100 Gbps network (900 km part of the PIONIER backbone). Each site hosted a set of 10 compute nodes interconnected locally by the InfiniBand switches with the traffic forwarded by specialized hardware: IBEX G40 - QDR InfiniBand RDMA based Extension Platform. A set of six all-reduce algorithms, consisting of two ring-based (including a PAP-aware pre-reduced ring), two binomial-tree based and two hierarchical ones, was tested for balanced and imbalanced process arrival patterns (PAPs). The results showed high and stable bandwidth with large data transmission latency of the branch connecting the remote sites (about 13 ms in comparison to 10 µs locally), and for the tested algorithms there was an advantage of hierarchical approach, and then binomial tree. Finally, we also observed some performance increase in PAP-aware solution in comparison to its regular counterpart. The main conclusion is that for the distributed cluster environment with imbalanced PAPs, there is a need for designing new hierarchical algorithms with PAP-aware support.},
  author          = {Proficz, Jerzy and Sumionka, Piotr and Skomia{\l}, Jaros{\l}aw and Semeniuk, Marcin and Niedzielewski, Karol and Walczak, Maciej},
  doi             = {10.1007/978-3-030-44041-1_72},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the International Conference on Advances in Intelligent Systems and Computing (AINA)/Investigation into MPI All-Reduce Performance in a Distributed Cluster with Consideration of Imbalanced.pdf:pdf},
  isbn            = {9783030440404},
  issn            = {21945365},
  journal         = {Proceedings of the International Conference on Advances in Intelligent Systems and Computing (AINA)},
  keywords        = {All-reduce,Collectives,Distributed cluster,HPC,MPI,PAP,Process arrival pattern},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {Collectives,MPI,PAP},
  pages           = {817--829},
  title           = {{Investigation into MPI All-Reduce Performance in a Distributed Cluster with Consideration of Imbalanced Process Arrival Patterns}},
  year            = {2020}
}
@article{Punniyamurthy2023,
  abstract        = {In order to satisfy their ever increasing capacity and compute requirements, many machine learning models are distributed across multiple nodes using space-efficient parallelism strategies. As a result, collective communications are often on the critical path, and hiding their latency by overlapping kernel-granular communication and computation is difficult due to the absence of independent computation. In this work, we propose fusing computation with communication using GPU-initiated networking, and leverage GPUs' massive parallelism to enable fine-grained overlap of the fused operations. We have developed a single, self-contained GPU kernel where workgroups (WGs) immediately communicate their results to remote GPUs when they complete their computation. Meanwhile, other WGs within the same kernel perform overlapping computation, maintaining high ALU utilization. Furthermore, we propose zero-copy optimizations for peer-to-peer GPU communication where the data computed by one GPU is directly written to the destination buffers within the peer GPUs, eliminating intermediate stores and extra buffering. Our approach leverages the emerging multi-node GPU system trend where GPUs are physically close to network with direct GPU-NIC interconnects. We demonstrate our approach by creating an embedding + All-to-All fused kernel which overlaps embedding operations and the dependent all-to-all collective in DLRM models. We evaluate our approach both using simulation and real hardware. Our evaluations show that our approach can effectively overlap All-to-All communication with embedding computations, subsequently reducing their combined execution time by 31{\%} on average (up to 58{\%}) for inter-node and by 25{\%} (up to 35{\%}) for intra-node configurations. Scale-out simulations indicate that our approach reduces DLRM execution time by {\~{}}10{\%} for 128 node system.},
  archiveprefix   = {arXiv},
  arxivid         = {2305.06942},
  author          = {Punniyamurthy, Kishore and Beckmann, Bradford M. and Hamidouche, Khaled},
  eprint          = {2305.06942},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/arXiv/GPU-initiated Fine-grained Overlap of Collective Communication with Computation - Punniyamurthy, Beckmann, Hamidouche - arXiv.pdf:pdf},
  journal         = {arXiv},
  keywords        = {Collectives,GPU},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,GPU},
  pages           = {1--13},
  title           = {{GPU-initiated Fine-grained Overlap of Collective Communication with Computation}},
  url             = {http://arxiv.org/abs/2305.06942},
  year            = {2023}
}
@article{qian2011,
  abstract        = {Recent studies show that MPI processes in real applications could arrive at an MPI collective operation at different times. This imbalanced process arrival pattern can significantly affect the performance of the collective operation. MPI-Alltoall() and MPI-Allgather() are communication-intensive collective operations that are used in many scientific applications. Therefore, their efficient implementations under different process arrival patterns are critical to the performance of scientific applications running on modern clusters. In this paper, we propose novel RDMA-based process arrival pattern aware MPI-Alltoall() and MPI-Allgather() for different message sizes over InfiniBand clusters. We also extend the algorithms to be shared memory aware for small to medium size messages under process arrival patterns. The performance results indicate that the proposed algorithms outperform the native MVAPICH implementations as well as other non-process arrival pattern aware algorithms when processes arrive at different times. Specifically, the RDMA-based process arrival pattern aware MPI-Alltoall() and MPI-Allgather() are 3.1 times faster than MVAPICH for 8 KB messages. On average, the applications studied in this paper (FT, RADIX, and N-BODY) achieve a speedup of 1.44 using the proposed algorithms. {\textcopyright} 2010 Springer Science+Business Media, LLC.},
  author          = {Qian, Ying and Afsahi, Ahmad},
  doi             = {10.1007/s10766-010-0152-3},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2011/International Journal of Parallel Programming/Process arrival pattern aware Alltoall and Allgather on InfiniBand clusters - Qian, Afsahi - International Journal of Parallel Programmi.pdf:pdf},
  journal         = {International Journal of Parallel Programming},
  keywords        = {Collective communications,InfiniBand,MPI,MPI-Allgather,MPI-Alltoall,PAP,Process arrival pattern,RDMA},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {InfiniBand,MPI,PAP},
  pages           = {473--493},
  title           = {{Process arrival pattern aware Alltoall and Allgather on InfiniBand clusters}},
  year            = {2011}
}
@inproceedings{Qiao2020,
  abstract        = {CUDA graph is an asynchronous task-graph programming model recently released by Nvidia. It encapsulates application workflows in a graph, with nodes being operations connected by dependencies. The new API brings two benefits: Reduced work launch overhead and whole workflow optimizations. In this paper, we improve the ability of CUDA graph to exploit workflow optimizations, e.g., concurrent kernel executions with complementary resource occupancy. Additionally, we argue that the advantages of DSLs are complementary to CUDA graph, and joining the two techniques can benefit from the best of both worlds. Here, we propose a compiler-based approach that combines CUDA graph with an image processing DSL and a source-to-source compiler called Hipacc. For ten image processing applications benchmarked on two Nvidia GPUs, our approach is able to achieve a geometric mean speedup of 1.30 over Hipacc without CUDA graph, 1.11 over CUDA graph without Hipacc, and 3.96 over another state-of-the-art DSL called Halide.},
  author          = {Qiao, Bo and {Akif Ozkan}, M. and Teich, Jurgen and Hannig, Frank},
  booktitle       = {Proceedings of the ACM/IEEE Design Automation Conference (DAC)},
  doi             = {10.1109/DAC18072.2020.9218531},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the ACMIEEE Design Automation Conference (DAC)/The best of both worlds Combining CUDA graph with an image processing DSL - Qiao et al. - Proceedings of the ACMIEEE Design Automation C.pdf:pdf},
  isbn            = {9781450367257},
  issn            = {0738100X},
  keywords        = {CUDA{\_}Graphs,GPU},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {CUDA{\_}Graphs,GPU},
  pages           = {1--6},
  title           = {{The best of both worlds: Combining CUDA graph with an image processing DSL}},
  year            = {2020}
}
@inproceedings{Quan2022,
  abstract        = {Quality assurance is of great importance for deep learning (DL) systems, especially when they are applied in safety-critical applications. While quality issues of native DL applications have been extensively analyzed, the issues of JavaScript-based DL applications have never been systematically studied. Compared with native DL applications, JavaScript-based DL applications can run on major browsers, making the platform- and device-independent. Specifically, the quality of JavaScript-based DL applications depends on the 3 parts: the application, the third-party DL library used and the underlying DL framework (e.g., TensorFlow.js), called JavaScript-based DL system. In this paper, we conduct the first empirical study on the quality issues of JavaScript-based DL systems. Specifically, we collect and analyze 700 real-world faults from relevant GitHub repositories, including the official TensorFlow.js repository, 13 third-party DL libraries, and 58 JavaScript-based DL applications. To better understand the characteristics of these faults, we manually analyze and construct taxonomies for the fault symptoms, root causes, and fix patterns, respectively. Moreover, we also study the fault distributions of symptoms and root causes, in terms of the different stages of the development lifecycle, the 3-level architecture in the DL system, and the 4 major components of TensorFlow.js framework. Based on the results, we suggest actionable implications and research avenues that can potentially facilitate the development, testing, and debugging of JavaScript-based DL systems.},
  archiveprefix   = {arXiv},
  arxivid         = {2209.04791},
  author          = {Quan, Lili and Guo, Qianyu and Xie, Xiaofei and Chen, Sen and Li, Xiaohong and Liu, Yang},
  doi             = {10.1145/3551349.3560427},
  eprint          = {2209.04791},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Unknown/Towards Understanding the Faults of JavaScript-Based Deep Learning Systems - Quan et al. - Unknown.pdf:pdf},
  isbn            = {9781450396240},
  mendeley-groups = {Web},
  month           = {oct},
  pages           = {1--13},
  publisher       = {Association for Computing Machinery (ACM)},
  title           = {{Towards Understanding the Faults of JavaScript-Based Deep Learning Systems}},
  year            = {2022}
}
@inproceedings{Rabenseifner2004,
  abstract        = {A 5-year-profiling in production mode at the University of Stuttgart has shown that more than 40{\%} of the execution time of Message Passing Interface (MPI) routines is spent in the collective communication routines MPI{\_}Allreduce and MPI{\_}Reduce. Although MPI implementations are now available for about 10 years and all vendors are committed to this Message Passing Interface standard, the vendors' and publicly available reduction algorithms could be accelerated with new algorithms by a factor between 3 (IBM, sum) and 100 (Cray T3E, maxloc) for long vectors. This paper presents five algorithms optimized for different choices of vector size and number of processes. The focus is on bandwidth dominated protocols for power-of-two and non-power-of-two number of processes, optimizing the load balance in communication and computation. {\textcopyright} Springer-Verlag 2004.},
  author          = {Rabenseifner, Rolf},
  booktitle       = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi             = {10.1007/978-3-540-24685-5_1},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2004/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/Optimization of collective reduction operations - Rabenseifner - Proceedings of the IEEE International Conference on Cluste.pdf:pdf},
  isbn            = {9783540221142},
  issn            = {16113349},
  keywords        = {Collective Operations,Collectives,MPI,Message Passing,Reduction},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,MPI,Reduction},
  pages           = {1--9},
  title           = {{Optimization of collective reduction operations}},
  volume          = {3036},
  year            = {2004}
}
@inproceedings{Rabenseifner2009,
  abstract      = {Today most systems in high-performance computing (HPC) feature a hierarchical hardware design: Shared memory nodes with several multi-core CPUs are connected via a network infrastructure. Parallel programming must combine distributed memory parallelization on the node interconnect with shared memory parallelization inside each node. We describe potentials and challenges ofthe dominant programming models on hierarchically structured hardware: Pure MPI (Message Passing Interface), pure OpenMP (with distributed shared memory extensions) and hybrid MPI+OpenMP in several flavors. We pinpoint cases where a hybrid programming model can indeed be the superior solution because of reduced communication needs and memory consumption, or improved load balance. Furthermore we show that machine topology has a significant impact on performance for all parallelization strategies and that topology awareness should be built into all applications in the future. Finally we give an outlook on possible standardization goals and extensions that could make hybrid programming easier to do with performance in mind. {\textcopyright} 2009 IEEE.},
  author        = {Rabenseifner, Rolf and Hager, Georg and Jost, Gabriele},
  booktitle     = {Proceedings of the Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)},
  doi           = {10.1109/PDP.2009.43},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2009/Proceedings of the Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP)/Hybrid MPIOpenMP parallel programming on clusters of multi-core SMP nodes - Rabenseifner,.pdf:pdf},
  isbn          = {9780769535449},
  keywords      = {Hybrid{\_}MPI,OpenMP,SMP},
  mendeley-tags = {Hybrid{\_}MPI,OpenMP,SMP},
  number        = {c},
  pages         = {427--436},
  publisher     = {IEEE},
  title         = {{Hybrid MPI/OpenMP parallel programming on clusters of multi-core SMP nodes}},
  year          = {2009}
}
@inproceedings{Raffenetti2017,
  abstract        = {This paper provides an in-depth analysis of the software overheads in the MPI performance-critical path and exposes mandatory per-formance overheads that are unavoidable based on the MPI-3.1 specification. We first present a highly optimized implementation of the MPI-3.1 standard in which the communication stack—all the Publication rights licensed to ACM. ACM acknowledges that this contribution was authored or co-authored by an employee, contractor or affiliate of the United States government. As such, the Government retains a nonexclusive, royalty-free right to publish or reproduce this article, or to allow others to do so, for Government purposes only. way from the application to the low-level network communication API—takes only a few tens of instructions. We carefully study these instructions and analyze the root cause of the overheads based on specific requirements from the MPI standard that are unavoid-able under the current MPI standard. We recommend potential changes to the MPI standard that can minimize these overheads. Our experimental results on a variety of network architectures and applications demonstrate significant benefits from our proposed changes.},
  author          = {Raffenetti, Ken and Amer, Abdelhalim and Oden, Lena and Archer, Charles and Bland, Wesley and Fujita, Hajime and Guo, Yanfei and Janjusic, Tomislav and Durnov, Dmitry and Blocksome, Michael and Si, Min and Seo, Sangmin and Langer, Akhil and Zheng, Gengbin and Takagi, Masamichi and Coffman, Paul and Jose, Jithin and Sur, Sayantan and Sannikov, Alexander and Oblomov, Sergey and Chuvelev, Michael and Hatanaka, Masayuki and Zhao, Xin and Fischer, Paul and Rathnayake, Thilina and Otten, Matt and Min, Misun and Balaji, Pavan},
  booktitle       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi             = {10.1145/3126908.3126963},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Why is MPI so slow Analyzing the Fundamental Limits in Implementing MPI-3.1 - Raffenetti.pdf:pdf},
  isbn            = {9781450351140},
  keywords        = {MPI,Survey},
  mendeley-groups = {UsedInComp1,UsedInComp2},
  mendeley-tags   = {MPI,Survey},
  pages           = {1--12},
  title           = {{Why is MPI so slow? Analyzing the Fundamental Limits in Implementing MPI-3.1}},
  year            = {2017}
}
@article{Ranganath2019,
  abstract        = {In order to address the vast needs of disparate domains, computing engines are becoming more sophisticated and complex. A typical high-performance computational engine is composed of several accelerator units, in most cases GPUs, plus one or more CPU controllers. All these components are becoming increasingly interconnected to satisfy bandwidth and latency tolerance demands from modern workloads. Due to these constraints, solutions to efficiently interconnect them or to systematically manage their traffic-such as PCIe v3, NVLink v1 and v2 on the hardware side, and NVIDIA Collective Communication Library (NCCL) and AMD ROCM layer on the software side-are becoming more commonplace inside HPC systems and cloud data centers. However, as the number of accelerators increases, workloads (especially machine learning) might not be able to fully exploit the computational substrate due to inefficient use of hardware interconnects. Such scenarios can lead to performance bottlenecks where high-bandwidth links are not used by the underlying libraries and under-performing links are overused. This work proposes Workload Optimization Through Inter-GPU Re-routing (WOTIR), which consists of enhanced NCCL-based collective primitives that aim to boost bandwidth utilization (through more efficient routing) and reduce communication overhead. WOTIR targets GPUs with no direct NVLink communication path (which leads to PCIe communications) and instead re-routes communication through intermediate GPUs to bridge NVLink segments and avoid PCIe communications. Such method allows the maximum possible utilization of the NVLink bandwidth between the GPUs without routing through the PCIe bus. Using this method, we see a reduction of up to 34 percent in execution time for selected machine learning workloads when non-optimal GPU allocations arise.},
  author          = {Ranganath, Kiran and Abdolrashidi, Amir Ali and Song, Shuaiwen Leon and Wong, Daniel},
  doi             = {10.1109/LCA.2019.2933842},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/IEEE Computer Architecture Letters/Speeding up Collective Communications through Inter-GPU Re-Routing - Ranganath et al. - IEEE Computer Architecture Letters.pdf:pdf},
  issn            = {15566064},
  journal         = {IEEE Computer Architecture Letters},
  keywords        = {Collective communication,Collectives,GPU,interconnect},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {Collectives,GPU},
  number          = {2},
  pages           = {128--131},
  title           = {{Speeding up Collective Communications through Inter-GPU Re-Routing}},
  volume          = {18},
  year            = {2019}
}
@inproceedings{Rashidi2022,
  author          = {Rashidi, Saeed and Won, William and Srinivasan, Sudarshan and Sridharan, Srinivas and Krishna, Tushar},
  booktitle       = {Proceedings of the IEEE/ACM International Symposium on Computer Architecture (ISCA)},
  doi             = {10.1145/3470496.3527382},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the IEEEACM International Symposium on Computer Architecture (ISCA)/Themis A Network Bandwidth-Aware Collective Scheduling Policy for Distributed Training of DL Models - Rashidi et al. - P.pdf:pdf},
  isbn            = {9781450386104},
  keywords        = {Collectives,Deep{\_}Learning,Network,Scheduling,bandwidth-aware,bandwidth-aware communication scheduling,collective communication,communication scheduling,distributed training},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,Deep{\_}Learning,Network,Scheduling},
  pages           = {581--596},
  title           = {{Themis: A Network Bandwidth-Aware Collective Scheduling Policy for Distributed Training of DL Models}},
  year            = {2022}
}
@article{Rashti2011,
  abstract      = {To avoid the memory registration cost for small messages in MPI implementations over RDMA-enabled networks, message transfer protocols involve a copy to intermediate buffers at both sender and receiver. In this paper, we propose to eliminate the send-side copy when an application buffer is reused frequently. We show that it is more efficient to register the application buffer and use it for data transfer. The idea is examined for small message transfer protocols in MVAPICH2, including RDMA Write and Send/Receive based communications, one-sided communications and collectives. The proposed protocol adaptively falls back to the current protocol when the application does not frequently use its buffers. The performance results over InfiniBand indicate up to 14{\%} improvement for single message latency, close to 20{\%} improvement for one-sided operations and up to 25{\%} improvement for collectives. In addition, the communication time in MPI applications with high buffer reuse is improved using this technique. {\textcopyright} 2011 Springer Science+Business Media, LLC.},
  author        = {Rashti, Mohammad J. and Afsahi, Ahmad},
  doi           = {10.1007/s10586-011-0165-8},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2011/Cluster Computing/Exploiting application buffer reuse to improve MPI small message transfer protocols over RDMA-enabled networks - Rashti, Afsahi - Cluste.pdf:pdf},
  issn          = {13867857},
  journal       = {Cluster Computing},
  keywords      = {Buffer copy,Buffer reuse,Eager protocol,MPI,Memory registration,RDMA},
  mendeley-tags = {MPI,RDMA},
  number        = {4},
  pages         = {345--356},
  title         = {{Exploiting application buffer reuse to improve MPI small message transfer protocols over RDMA-enabled networks}},
  volume        = {14},
  year          = {2011}
}
@inproceedings{Rashti2010,
  abstract      = {iWARP represents the leading edge of high performance Ethernet technologies. By utilizing an asynchronous communication model, iWARP brings the advantages of OS bypass and RDMA technology to Ethernet. The current specification of iWARP is only defined over connection-oriented transports such as TCP. The memory requirements of many connections along with TCP's flow and reliability controls lead to scalability and performance issues for large-scale HPC and datacenter applications. In this research, we propose guidelines to extend iWARP over datagrams to provide better scalability and performance. While the proposed extension is designed for use in both HPC and datacenters, the emphasis of this paper is on HPC applications. We present our software implementation of datagram-iWARP over UDP and MPI over datagram-iWARP. Our microbenchmark and MPI application results show performance and memory usage benefits for MPI applications, promoting the use of datagram-iWARP for large-scale HPC applications. {\textcopyright}2010 IEEE.},
  author        = {Rashti, Mohammad J. and Grant, Ryan E. and Afsahi, Ahmad and Balaji, Pavan},
  booktitle     = {Proceedings of the IEEE International Conference on High Performance Computing (HiPC)},
  doi           = {10.1109/HIPC.2010.5713192},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2010/Proceedings of the IEEE International Conference on High Performance Computing (HiPC)/iWARP redefined Scalable connectionless communication over high-speed ethernet - Rashti et al. - Proceedings of the I.pdf:pdf},
  isbn          = {9781424485185},
  keywords      = {Datagram,Ethernet,IWARP,MPI,Message passing interface,Message{\_}Passing,iWARP},
  mendeley-tags = {IWARP,MPI,Message{\_}Passing},
  pages         = {1--10},
  publisher     = {IEEE},
  title         = {{iWARP redefined: Scalable connectionless communication over high-speed ethernet}},
  year          = {2010}
}
@inproceedings{Risso2019,
  abstract      = {Clusters with GPUs are mainstream in HPC as shown by the last edition of the Top500 list, increasing the demand for GPU capable scientific computing software. Programming large scale GPU systems in an efficient and future-proof way present numerous challenges, such as optimizations for a variety of GPUs and interconnect hardware, hiding communication overhead with computation and efficient domain partitioning. We present an improvement to the CUDA-based communication of stencil applications in the WALBERLA framework, achieving scalability while supporting different GPUs and communication infrastructures. We utilize the lattice Boltzmann Method for fluid flows as a representative of stencil-based scientific computing and implement a communication hiding strategy that is capable of adjusting to a system's computing and communication capabilities. We compare the use of CUDAMemCopy with the use of customized pack/unpack kernels and show that packing achieves almost linear weak scaling behavior in the Santos Dumont supercomputer with up to 128 GPUs. We also show that the proposed approach is not sensitive to the direction of the domain partitioning, one of the biggest challenges when communicating 3D domains in GPU-based stencil simulations.},
  author        = {Risso, Joao Victor Tozatti and Bauer, Martin and Carvalho, Paulo Roberto and Rude, Ulrich and Weingaertner, Daniel},
  booktitle     = {Proceedings of the International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)},
  doi           = {10.1109/SBAC-PAD.2019.00026},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)/Scalable GPU communication with code generation on stencil applications - Risso et al. - Proc.pdf:pdf},
  keywords      = {CUDA,GPU,GPU clusters,GPU communication,Lattice Boltzmann Method,Multi{\_}GPU,Scalability},
  mendeley-tags = {CUDA,GPU,Multi{\_}GPU},
  pages         = {88--95},
  title         = {{Scalable GPU communication with code generation on stencil applications}},
  year          = {2019}
}
@techreport{Rossetti2021,
  author          = {Rossetti, Davide and Markthub, Pak and Howell, Seth},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Unknown/The Latest in GPUDirect - Rossetti, Markthub, Howell - Unknown.pdf:pdf},
  keywords        = {GPU,GPUDirect{\_}Async,Network},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {GPU,GPUDirect{\_}Async,Network},
  title           = {{The Latest in GPUDirect}},
  url             = {https://github.com/NVIDIA/gdrcopy},
  year            = {2021}
}
@inproceedings{Ruhela2018,
  abstract        = {The overlap of computation and communication is critical for good performance of many HPC applications. State-of-the-art designs for the asynchronous progress require specially designed hardware resources (advanced switches or network interface cards), dedicated processor cores or application modification (e.g. use of MPI{\_}Test). These techniques suffer from various issues like increasing code complexity/cost and loss of available compute resources for end applications. In this paper, we take up this challenge and propose a simple yet effective technique to achieve good overlap without needing any additional hardware or software resources. The proposed thread-based design allows MPI libraries to self-detect when asynchronous communication progress is needed and minimizes the number of context-switches and preemption between the main thread and the asynchronous progress thread. We evaluate the proposed design against state-of-the-art designs in other MPI libraries including MVAPICH2, Intel MPI, and Open MPI. We demonstrate benefits of the proposed approach at microbenchmark and at application level at scale on four different architectures including Intel Broadwell, Intel Xeon Phi (KNL), IBM OpenPOWER, and Intel Skylake with InfiniBand and Omni-Path interconnects. Compared to other state-of-the-art designs, our proposed approach shows upto 46{\%}, 37{\%}, and 49{\%} improvement for All-to-one, One-to-all, and All-to-all communication patterns respectively collectives on 1,024 processes. We also show 38{\%} performance improvement for SPEC MPI compute-intensive applications on 384 processes and 44{\%} performance improvement with the P3DFFT application on 448 processes.},
  author          = {Ruhela, Amit and Bayatpour, Mohammadreza and Subramoni, Hari and Kousha, Pouya and Chakraborty, Sourav and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the European MPI Users' Group Meeting (EuroMPI)},
  doi             = {10.1145/3236367.3236376},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the European MPI Users' Group Meeting (EuroMPI)/Efficient asynchronous communication progress for MPI without dedicated resources - Ruhela et al. - Proceedings of the European MPI User.pdf:pdf},
  isbn            = {9781450364928},
  keywords        = {Async progress,Blocking/nonblocking operations,Collective operations,Collectives,Communication computation overlap,HPC,MPI,Multithreaded{\_}MPI,P3DFFT,SPEC MPI2007 benchmarks},
  mendeley-groups = {ELEC-873,UsedInComp1},
  mendeley-tags   = {Collectives,MPI,Multithreaded{\_}MPI},
  pages           = {1--12},
  title           = {{Efficient asynchronous communication progress for MPI without dedicated resources}},
  year            = {2018}
}
@inproceedings{SalimiBeni2020,
  abstract      = {Abstract—With the increasing rate of data generation in recent years, there is a need for modern tools to process these massive amounts of data. To that end, in-memory platforms are becoming increasingly popular, which can process high volumes of data at high speed and performance by utilizing Main Memory. Apache Ignite is one of the in-memory platforms that can process in parallel on multiple nodes. Although this platform provides many useful features, one of its limitations is the lack of utilizing the GPU's high processing power. Undoubtedly, using GPUs for operations that deal with heavy processing or high data volumes can be very beneficial, and significantly accelerate processing. One of the algorithms supported by Ignite is the Genetic Algorithm, which usually deals with large amounts of data, and might be very timeconsuming. In this paper, we have provided an extension for Ignite in which users can utilize GPUs to run their Genetic Algorithm applications. Also, we have used various GPUrelated optimization techniques to improve performance and finally evaluated our extension with three benchmarks. Our results proved the ease of use, and the high performance of the proposed work compared to Ignite.},
  author        = {{Salimi Beni}, Majid and Sojoodi, Amir Hossein and Khunjush, Farshad},
  booktitle     = {Proceedings of the International Symposium on Computer Architecture and Digital Systems (CADS)},
  doi           = {10.1109/CADS50570.2020.9211857},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the International Symposium on Computer Architecture and Digital Systems (CADS)/A GPU-Enabled Extension for Apache Ignite to Facilitate Running Genetic Algorithms - Salimi Beni, Sojoodi, K.pdf:pdf},
  isbn          = {9781728181110},
  keywords      = {GPU,Genetic{\_}Algorithm,Ignite,apache ignite,gpu,in-memory computing},
  mendeley-tags = {GPU,Genetic{\_}Algorithm,Ignite},
  pages         = {1--8},
  title         = {{A GPU-Enabled Extension for Apache Ignite to Facilitate Running Genetic Algorithms}},
  year          = {2020}
}
@inproceedings{Sanders2002,
  author        = {Sanders, Peter and Traff, Jesper Larsson},
  booktitle     = {Proceedings of the European Conference on Parallel Processing (Euro-Par)},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2002/Proceedings of the European Conference on Parallel Processing (Euro-Par)/The Hierarchical Factor Algorithm for All-to-All Communication - Sanders, Traff - Proceedings of the European Conference on Parall.pdf:pdf},
  keywords      = {All{\_}to{\_}All,Collectives,Hierarchical,MPI},
  mendeley-tags = {All{\_}to{\_}All,Collectives,Hierarchical,MPI},
  pages         = {799--803},
  title         = {{The Hierarchical Factor Algorithm for All-to-All Communication}},
  year          = {2002}
}
@inproceedings{Sanghoon2023,
  abstract      = {Training is an important aspect of deep learning to enable network models to be deployed. To scale training, multiple GPUs are commonly used with data parallelism to exploit the additional GPU compute and memory capacity. However, one challenge in scalability is the collective communication between GPUs. In this work, we propose to accelerate the AllReduce collective. AllReduce communication is often based on a logical topology (e.g., ring or tree algorithms) that is mapped to a physical topology or the physical connectivity between the nodes. In this work, we propose a logical/physical topology-aware collective communication that we refer to as C-Cube architecture-Chaining Collective Communication with Computation. C-Cube exploits the opportunity to overlap or chain different phases of collective communication as well as forward computation in a tree algorithm AllReduce. We exploit the communication pattern in a logical tree topology to overlap the different phases of communication. Since ordering is maintained in the tree collective algorithm, we propose gradient queuing to enable chaining of communication with forward computation to accelerate overall performance while having no impact on training accuracy. We also exploit the physical topology characteristics to further improve the performance, including proposing detour connections for collective communication while leveraging the additional connectivity to enable a double-tree C-Cube implementation. We implement a C-Cube proof-of-concept on a real system (8-GPU NVIDIA DGX-1) and show C-Cube results in performance improvement in communication performance compared to non-overlapped tree algorithms as well as overall performance.},
  author        = {Sanghoon, Jo and Son, Hyojun and Kim, John},
  booktitle     = {Proceedings of International Symposium on High-Performance Computer Architecture (HPCA)},
  doi           = {10.1109/HPCA56546.2023.10071117},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/Proceedings of International Symposium on High-Performance Computer Architecture (HPCA)/LogicalPhysical Topology-Aware Collective Communication in Deep Learning Training - Sanghoon, Son, Kim - Proceeding.pdf:pdf},
  isbn          = {9781665476522},
  keywords      = {Deep{\_}Learning,Topology{\_}Aware},
  mendeley-tags = {Deep{\_}Learning,Topology{\_}Aware},
  pages         = {56--68},
  publisher     = {IEEE},
  title         = {{Logical/Physical Topology-Aware Collective Communication in Deep Learning Training}},
  year          = {2023}
}
@article{Schade2021,
  abstract      = {We push the boundaries of electronic structure-based $\backslash$textit{\{}ab-initio{\}} molecular dynamics (AIMD) beyond 100 million atoms. This scale is otherwise barely reachable with classical force-field methods or novel neural network and machine learning potentials. We achieve this breakthrough by combining innovations in linear-scaling AIMD, efficient and approximate sparse linear algebra, low and mixed-precision floating-point computation on GPUs, and a compensation scheme for the errors introduced by numerical approximations. The core of our work is the non-orthogonalized local submatrix (NOLSM) method, which scales very favorably to massively parallel computing systems and translates large sparse matrix operations into highly parallel, dense matrix operations that are ideally suited to hardware accelerators. We demonstrate that the NOLSM method, which is at the center point of each AIMD step, is able to achieve a sustained performance of 324 PFLOP/s in mixed FP16/FP32 precision corresponding to an efficiency of 67.7$\backslash${\%} when running on 1536 NVIDIA A100 GPUs.},
  archiveprefix = {arXiv},
  arxivid       = {2104.08245},
  author        = {Schade, Robert and Kenter, Tobias and Elgabarty, Hossam and Lass, Michael and Sch{\"{u}}tt, Ole and Lazzaro, Alfio and Pabst, Hans and Mohr, Stephan and Hutter, J{\"{u}}rg and K{\"{u}}hne, Thomas D. and Plessl, Christian},
  eprint        = {2104.08245},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/arXiv/Enabling Electronic Structure-Based Ab-Initio Molecular Dynamics Simulations with Hundreds of Millions of Atoms - Schade et al. - arXiv.pdf:pdf},
  journal       = {arXiv},
  keywords      = {CUDA,CUDA{\_}Graphs,MPI},
  mendeley-tags = {CUDA,CUDA{\_}Graphs,MPI},
  title         = {{Enabling Electronic Structure-Based Ab-Initio Molecular Dynamics Simulations with Hundreds of Millions of Atoms}},
  year          = {2021}
}
@article{Schonbein2018a,
  abstract        = {MPI usage patterns are changing as applications move towards fully-multithreaded runtimes. However, the impact of these patterns on MPI message matching is not well-studied. In particular, MPI's mechanic for receiver-side data placement, message matching, can be impacted by increased message volume and nondeterminism incurred by multithreading. While there has been significant developer interest and work to provide an efficient MPI interface for multithreaded access, there has not been a study showing how these patterns affect messaging patterns and matching behavior. In this paper, we present a framework for studying the effects of multithreading on MPI message matching. This framework allows us to explore the implications of different common communication patterns and thread-level decompositions. We present a study of these impacts on the architecture of two of the Top 10 supercomputers (NERSC's Cori and LANL's Trinity). This data provides a baseline to evaluate reasonable matching engine queue lengths, search depths, and queue drain times under the multithreaded model. Furthermore, the study highlights surprising results on the challenge posed by message matching for multithreaded application performance.},
  author          = {Schonbein, Whit and Dosanjh, Matthew G.F. and Grant, Ryan E. and Bridges, Patrick G.},
  doi             = {10.1007/978-3-319-96983-1_34},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)/Measuring Multithreaded Message Matching Misery - Schonbein et al. - L.pdf:pdf},
  isbn            = {9783319969824},
  issn            = {16113349},
  journal         = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  mendeley-groups = {ELEC-878},
  pages           = {480--491},
  title           = {{Measuring Multithreaded Message Matching Misery}},
  volume          = {11014 LNCS},
  year            = {2018}
}
@inproceedings{Schonbein2018,
  author          = {Schonbein, Whit and Grant, Ryan E. and Bridges, Patrick G.},
  booktitle       = {Proceedings of the European Conference on Parallel Processing (Euro-Par)},
  doi             = {10.1007/978-3-319-96983-1},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the European Conference on Parallel Processing (Euro-Par)/Measuring Multithreaded Message Matching Misery - Schonbein, Grant, Bridges - Proceedings of the European Conference on Parallel P.pdf:pdf},
  isbn            = {9783319969831},
  keywords        = {Message{\_}Matching,Multithreaded{\_}MPI},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {Message{\_}Matching,Multithreaded{\_}MPI},
  pages           = {703--717},
  title           = {{Measuring Multithreaded Message Matching Misery}},
  year            = {2018}
}
@inproceedings{Schonbein2020,
  author        = {Schonbein, Whit and Levy, Scott and Marts, W Pepper and Dosanjh, Matthew G F and Grant, Ryan E},
  booktitle     = {Proceedings of the IEEE International Conference on High Performance Computing and Communications (HPCC)},
  doi           = {10.1109/HPCC-SmartCity-DSS50907.2020.00022},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the IEEE International Conference on High Performance Computing and Communications (HPCC)/Low-cost MPI Multithreaded Message Matching Benchmarking - Schonbein et al. - Proceedings of the I.pdf:pdf},
  keywords      = {Benchmark,Message{\_}Matching,Multithreaded{\_}MPI},
  mendeley-tags = {Benchmark,Message{\_}Matching,Multithreaded{\_}MPI},
  pages         = {170--179},
  title         = {{Low-cost MPI Multithreaded Message Matching Benchmarking}},
  year          = {2020}
}
@article{Schuchart2021,
  abstract      = {Asynchronous programming models (APM) are gaining more and more traction, allowing applications to expose the available concurrency to a runtime system tasked with coordinating the execution. While MPI has long provided support for multi-threaded communication and non-blocking operations, it falls short of adequately supporting APMs as correctly and efficiently handling MPI communication in different models is still a challenge. We have previously proposed an extension to the MPI standard providing operation completion notifications using callbacks, so-called MPI Continuations. This interface is flexible enough to accommodate a wide range of different APMs. In this paper, we present an extension to the previously described interface that allows for finer control of the behavior of the MPI Continuations interface. We then present some of our first experiences in using the interface in the context of different applications, including the NAS parallel benchmarks, the PaRSEC task-based runtime system, and a load-balancing scheme within an adaptive mesh refinement solver called ExaHyPE. We show that the interface, implemented inside Open MPI, enables low-latency, high-throughput completion notifications that outperform solutions implemented in the application space.},
  author        = {Schuchart, Joseph and Samfass, Philipp and Niethammer, Christoph and Gracia, Jos{\'{e}} and Bosilca, George},
  doi           = {10.1016/j.parco.2021.102793},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Parallel Computing/Callback-based completion notification using MPI Continuations - Schuchart et al. - Parallel Computing.pdf:pdf},
  issn          = {01678191},
  journal       = {Parallel Computing},
  keywords      = {MPI,MPI Continuations,OmpSs,OpenMP,PaRSEC,TAMPI,Task-based programming models},
  mendeley-tags = {MPI,OpenMP},
  pages         = {1--12},
  publisher     = {Elsevier B.V.},
  title         = {{Callback-based completion notification using MPI Continuations}},
  url           = {https://doi.org/10.1016/j.parco.2021.102793},
  year          = {2021}
}
@article{Shafi2021,
  abstract      = {Dask is a popular parallel and distributed computing framework, which rivals Apache Spark to enable task-based scalable processing of big data. The Dask Distributed library forms the basis of this computing engine and provides support for adding new communication devices. It currently has two communication devices: one for TCP and the other for high-speed networks using UCX-Py - a Cython wrapper to UCX. This paper presents the design and implementation of a new communication backend for Dask - called MPI4Dask - that is targeted for modern HPC clusters built with GPUs. MPI4Dask exploits mpi4py over MVAPICH2-GDR, which is a GPU-aware implementation of the Message Passing Interface (MPI) standard. MPI4Dask provides point-to-point asynchronous I/O communication coroutines, which are non-blocking concurrent operations defined using the async/await keywords from the Python's asyncio framework. Our latency and throughput comparisons suggest that MPI4Dask outperforms UCX by 6× for 1 Byte message and 4× for large messages (2 MBytes and beyond) respectively. We also conduct comparative performance evaluation of MPI4Dask with UCX using two benchmark applications: 1) sum of cuPy array with its transpose, and 2) cuDF merge. MPI4Dask speeds up the overall execution time of the two applications by an average of 3.47× and 3.11× respectively on an in-house cluster built with NVIDIA Tesla V100 GPUs for 1 - 6 Dask workers. We also perform scalability analysis of MPI4Dask against UCX for these applications on TACC's Frontera (GPU) system with upto 32 Dask workers on 32 NVIDIA Quadro RTX 5000 GPUs and 256 CPU cores. MPI4Dask speeds up the execution time for cuPy and cuDF applications by an average of 1.71× and 2.91× respectively for 1 - 32 Dask workers on the Frontera (GPU) system.},
  author        = {Shafi, Aamir and Hashmi, Jahanzeb Maqbool and Subramoni, Hari and Panda, Dhabaleswar K. DK},
  doi           = {10.1109/ccgrid51090.2021.00037},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/arXiv/Efficient MPI-based Communication for GPU-Accelerated Dask Applications - Shafi et al. - arXiv.pdf:pdf},
  isbn          = {9781728195865},
  journal       = {arXiv},
  keywords      = {Dask,GPU,MPI,UCX},
  mendeley-tags = {Dask,GPU,MPI,UCX},
  pages         = {1--10},
  title         = {{Efficient MPI-based Communication for GPU-Accelerated Dask Applications}},
  year          = {2021}
}
@inproceedings{ShafieKhorassani2022,
  abstract      = {The Slingshot interconnect designed by HPE/Cray is becoming more relevant in High-Performance Computing with its deployment on the upcoming exascale systems. In particular, it is the interconnect empowering the first exascale and highest-ranked supercomputer in the world, Frontier. It offers various features such as adaptive routing, congestion control, and isolated workloads. The deployment of newer interconnects raises questions about performance , scalability, and any potential bottlenecks as they are a critical element contributing to the scalability across nodes on these systems. In this paper, we will delve into the challenges the slingshot interconnect poses with current state-of-the-art MPI libraries. In particular, we look at the scalability performance when using slingshot across nodes. We present a comprehensive evaluation using various MPI and communication libraries including Cray MPICH, OpenMPI + UCX, RCCL, and MVAPICH2-GDR on GPUs on the Spock system, an early access cluster deployed with Slingshot and AMD MI100 GPUs, to emulate the Frontier system.},
  author        = {{Shafie Khorassani}, Kawthar and Chen, Chen-Chun and Ramesh, Bharath and Shafi, Aamir and Subramoni, Hari and Panda, Dhabaleswar K},
  booktitle     = {Practice and Experience in Advanced Research Computing (PEARC)},
  doi           = {10.1145/3491418.3530773},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Practice and Experience in Advanced Research Computing (PEARC)/High Performance MPI over the Slingshot Interconnect Early Experiences - Shafie Khorassani et al. - Practice and Experience in Advanced.pdf:pdf},
  isbn          = {9781450391610},
  keywords      = {AMD GPUs,GPU,Interconnect Technology,MPI,MPI.,Slingshot},
  mendeley-tags = {GPU,MPI,Slingshot},
  pages         = {1--7},
  title         = {{High Performance MPI over the Slingshot Interconnect: Early Experiences}},
  year          = {2022}
}
@inproceedings{Shah2021,
  abstract        = {Machine learning models are increasingly being trained across multiple GPUs and multiple machines. In this setting, data is transferred between GPUs using communication collectives such as AlltoAll and AllReduce, which can become a significant bottleneck in large models. It is important to use efficient algorithms for collective communication. We introduce TACCL, a tool that allows algorithm designers to guide a synthesizer into automatically generating algorithms for a given hardware configuration and communication collective. TACCL uses the novel communication sketch abstraction to obtain crucial information from the designer that is used to significantly reduce the state space and guide the synthesizer towards better algorithms. TACCL also uses a novel encoding of the problem that allows it to scale beyond single-node topologies. We use TACCL to synthesize algorithms for three collectives and two hardware topologies: DGX-2 and NDv2. We demonstrate that the algorithms synthesized by TACCL outperform the NVIDIA Collective Communication Library (NCCL) by up to 6.7{\$}\backslashtimes{\$}. We also show that TACCL can speed up end-to-end training of Transformer-XL and BERT models by 11{\%}--2.3{\$}\backslashtimes{\$} for different batch sizes.},
  archiveprefix   = {arXiv},
  arxivid         = {2111.04867},
  author          = {Shah, Aashaka and Chidambaram, Vijay and Cowan, Meghan and Maleki, Saeed and Musuvathi, Madan and Mytkowicz, Todd and Nelson, Jacob and Saarikivi, Olli and Singh, Rachee},
  booktitle       = {Proceedings of USENIX Symposium on Networked Systems Design and Implementation (NSDI)},
  eprint          = {2111.04867},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of USENIX Symposium on Networked Systems Design and Implementation (NSDI)/TACCL Guiding Collective Algorithm Synthesis using Communication Sketches - Shah et al. - Proceedings of USENIX Sympo.pdf:pdf},
  keywords        = {Collectives,GPU,MPI,NCCL,Topology{\_}Aware},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,GPU,MPI,NCCL,Topology{\_}Aware},
  pages           = {1--20},
  title           = {{TACCL: Guiding Collective Algorithm Synthesis using Communication Sketches}},
  url             = {http://arxiv.org/abs/2111.04867},
  year            = {2021}
}
@inproceedings{Shatnawi2018,
  abstract      = {Deep Learning (DL) is one of the hottest trends in machine learning as DL approaches produced results superior to the state-of-the-art in problematic areas such as image processing and natural language processing (NLP). To foster the growth of the DL community, several open source frameworks appeared providing implementations of the most common DL algorithms. These frameworks vary in the algorithms they support and in the quality of their implementations. The purpose of this work is to provide a qualitative and quantitative comparison among three of the most popular and most comprehensive DL frameworks (namely Google's TensorFlow, University of Montreal's Theano, and Microsoft's CNTK). The ultimate goal of this work is to help end users make an informed decision about the best DL framework that suits their needs and resources. To ensure that our study is as comprehensive as possible, we conduct several experiments using multiple benchmark datasets and measure the performance of the frameworks' implementation of different DL algorithms. For most of our experiments, we find out that CNTK's implementations are superior to the other ones under consideration.},
  author        = {Shatnawi, Ali and Al-Bdour, Ghadeer and Al-Qurran, Raffi and Al-Ayyoub, Mahmoud},
  booktitle     = {Proceedings of the International Conference on Information and Communication Systems (ICICS)},
  doi           = {10.1109/IACS.2018.8355444},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the International Conference on Information and Communication Systems (ICICS)/A comparative study of open source deep learning frameworks - Shatnawi et al. - Proceedings of the Internation.pdf:pdf},
  keywords      = {CIFAR-10,CNN,CNTK,Deep Learning,Deep{\_}Learning,MNIST,TensorFlow,Theano},
  mendeley-tags = {Deep{\_}Learning},
  pages         = {72--77},
  title         = {{A comparative study of open source deep learning frameworks}},
  year          = {2018}
}
@inproceedings{Shi2014,
  abstract        = {Increasing number of MPI applications are being ported to take advantage of the compute power offered by GPUs. Data movement on GPU clusters continues to be the major bottleneck that keeps scientific applications from fully harnessing the potential of GPUs. Earlier, GPU-GPU inter-node communication has to move data from GPU memory to host memory before sending it over the network. MPI libraries like MVAPICH2 have provided solutions to alleviate this bottleneck using host-based pipelining techniques. Besides that, the newly introduced GPUDirect RDMA (GDR) is a promising solution to further solve this data movement bottleneck. However, existing design in MPI libraries applies the rendezvous protocol for all message sizes, which incurs considerable overhead for small message communications due to extra synchronization message exchange. In this paper, we propose new techniques to optimize internode GPU-to-GPU communications for small message sizes. Our designs to support the eager protocol include efficient support at both sender and receiver sides. Furthermore, we propose a new data path to provide fast copies between host and GPU memories. To the best of our knowledge, this is the first study to propose efficient designs for GPU communication for small message sizes, using eager protocol. Our experimental results demonstrate up to 59{\%} and 63{\%} reduction in latency for GPU-to-GPU and CPU-to-GPU point-to-point communications, respectively. These designs boost the uni-directional bandwidth by 7.3x and 1.7x, respectively. We also evaluate our proposed design with two end-applications: GPULBM and HOOMD-blue. Performance numbers on Kepler GPUs shows that, compared to the best existing GDR design, our proposed designs achieve up to 23.4{\%} latency reduction for GPULBM and 58{\%} increase in average TPS for HOOMD-blue, respectively.},
  author          = {Shi, Rong and Potluri, Sreeram and Hamidouche, Khaled and Perkins, Jonathan and Li, Mingzhe and Rossetti, Davide and Panda, Dhabaleswar K.},
  booktitle       = {Proceedings of the IEEE International Conference on High Performance Computing (HiPC)},
  doi             = {10.1109/HiPC.2014.7116873},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Proceedings of the IEEE International Conference on High Performance Computing (HiPC)/Designing efficient small message transfer mechanism for inter-node MPI communication on InfiniBand GPU clusters - Sh.pdf:pdf},
  isbn            = {9781479959761},
  keywords        = {CUDA,GPU,GPU Direct RDMA,GPUDirect{\_}RDMA,InfiniBand,Inter{\_}node,MPI},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {CUDA,GPU,GPUDirect{\_}RDMA,InfiniBand,Inter{\_}node,MPI},
  pages           = {1--10},
  title           = {{Designing efficient small message transfer mechanism for inter-node MPI communication on InfiniBand GPU clusters}},
  year            = {2014}
}
@article{Shi2018,
  abstract        = {Deep learning frameworks have been widely deployed on GPU servers for deep learning applications in both academia and industry. In training deep neural networks (DNNs), there are many standard processes or algorithms, such as convolution and stochastic gradient descent (SGD), but the running performance of different frameworks might be different even running the same deep model on the same GPU hardware. In this study, we evaluate the running performance of four state-of-The-Art distributed deep learning frameworks (i.e., Caffe-MPI, CNTK, MXNet, and TensorFlow) over single-GPU, multi-GPU, and multi-node environments. We first build performance models of standard processes in training DNNs with SGD, and then we benchmark the running performance of these frameworks with three popular convolutional neural networks (i.e., AlexNet, GoogleNet and ResNet-50), after that, we analyze what factors that result in the performance gap among these four frameworks. Through both analytical and experimental analysis, we identify bottlenecks and overheads which could be further optimized. The main contribution is that the proposed performance models and the analysis provide further optimization directions in both algorithmic design and system configuration.},
  author          = {Shi, Shaohuai and Wang, Qiang and Chu, Xiaowen},
  doi             = {10.1109/DASC/PiCom/DataCom/CyberSciTec.2018.000-4},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the IEEE International Conference on Dependable, Autonomic and Secure Computing (DASC)/Performance modeling and evaluation of distributed deep learning frameworks on GPUs - Shi, Wang, Chu.pdf:pdf},
  isbn            = {9781538675182},
  journal         = {Proceedings of the IEEE International Conference on Dependable, Autonomic and Secure Computing (DASC)},
  keywords        = {Convolutional Neural Networks,Deep Learning,Deep Learning Frameworks,Deep{\_}Learning,Distributed SGD,GPU,Modeling},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Deep{\_}Learning,GPU,Modeling},
  pages           = {943--948},
  title           = {{Performance modeling and evaluation of distributed deep learning frameworks on GPUs}},
  year            = {2018}
}
@inproceedings{Si2014,
  abstract        = {Many-core architectures, such as the Intel Xeon Phi, provide dozens of cores and hundreds of hardware threads. To utilize such architectures, application programmers are increasingly looking at hybrid programming models, where multiple threads interact with the MPI library (frequently called "MPI+X" models). A common mode of operation for such applications uses multiple threads to parallelize the computation, while one of the threads also issues MPI operations (i.e., MPI FUNNELED or SERIALIZED thread-safety mode). In MPI+OpenMP applications, this is achieved, for example, by placing MPI calls in OpenMP critical sections or outside the OpenMP parallel regions. However, such a model often means that the OpenMP threads are active only during the parallel computation phase and idle during the MPI calls, resulting in wasted computational resources. In this paper, we present MT-MPI, an internally multithreaded MPI implementation that transparently coordinates with the threading runtime system to share idle threads with the application. It is designed in the context of OpenMP and requires modifications to both the MPI implementation and the OpenMP runtime in order to share appropriate information between them. We demonstrate the benefit of such internal parallelism for various aspects of MPI processing, including derived datatype communication, shared-memory communication, and network I/O operations. {\textcopyright} 2014 ACM.},
  author          = {Si, Min and Pe{\~{n}}a, Antonio J. and Balaji, Pavan and Takagi, Masamichi and Ishikawa, Yutaka},
  booktitle       = {Proceedings of the International Conference on Supercomputing (ICS)},
  doi             = {10.1145/2597652.2597658},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Proceedings of the International Conference on Supercomputing (ICS)/MT-MPI Multithreaded MPI for many-core environments - Si et al. - Proceedings of the International Conference on Supercomputing (ICS).pdf:pdf},
  isbn            = {9781450326421},
  keywords        = {MPI,Multithreaded{\_}MPI,OpenMP,Xeon{\_}Phi,many-core,mpi,openmp,threads,xeon phi},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Multithreaded{\_}MPI,OpenMP,Xeon{\_}Phi},
  pages           = {125--134},
  title           = {{MT-MPI: Multithreaded MPI for many-core environments}},
  year            = {2014}
}
@article{SiavashKatebzadeh2020,
  abstract      = {Today's cloud datacenters feature a large number of concurrently executing applications with diverse intradatacenter latency and bandwidth requirements. To remove the network as a potential performance bottleneck, datacenter operators have begun deploying high-end HPC-grade networks, such as InfiniBand (IB), which offer fully offloaded network stacks, remote direct memory access (RDMA) capability, and non-discarding links. While known to provide both low latency and high bandwidth for a single application, it is not clear how well such networks accommodate a mix of latencyand bandwidth-sensitive traffic that is likely in a real-world deployment. As a step toward answering this question, we develop a performance measurement tool for RDMA-based networks, RPerf, that is capable of precisely measuring the IB switch performance without hardware support. Using RPerf, we benchmark a rack-scale IB cluster in isolated and mixedtraffic scenarios. Our key finding is that the evaluated switch can provide either low latency or high bandwidth, but not both simultaneously in a mixed-traffic scenario. We evaluate several options to improve the latency-bandwidth trade-off and demonstrate that none are ideal.},
  author        = {{Siavash Katebzadeh}, M. R. and Costa, Paolo and Grot, Boris},
  doi           = {10.1109/ISPASS48437.2020.00033},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)/Evaluation of an InfiniBand Switch Choose Latency or Bandwidth, but Not Both - Siavash Katebzadeh,.pdf:pdf},
  isbn          = {9781728147987},
  journal       = {Proceedings of the IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS)},
  keywords      = {Datacenter Networks,InfiniBand,Network,Quality-of-Service},
  mendeley-tags = {InfiniBand,Network},
  pages         = {180--191},
  title         = {{Evaluation of an InfiniBand Switch: Choose Latency or Bandwidth, but Not Both}},
  year          = {2020}
}
@article{Singh2011,
  abstract        = {General Purpose Graphics Processing Units (GPGPUs) are rapidly becoming an integral part of high performance system architectures. The Tianhe-1A and Tsubame systems received significant attention for their architectures that leverage GPGPUs. Increasingly many scientific applications that were originally written for CPUs using MPI for parallelism are being ported to these hybrid CPU-GPU clusters. In the traditional sense, CPUs perform computation while the MPI library takes care of communication. When computation is performed on GPGPUs, the data has to be moved from device memory to main memory before it can be used in communication. Though GPGPUs provide huge compute potential, the data movement to and from GPGPUs is both a performance and productivity bottleneck. Recently, the MVAPICH2 MPI library has been modified to directly support point-to-point MPI communication from the GPU memory [1]. Using this support, programmers do not need to explicitly move data to main memory before using MPI. This feature also enables performance improvement due to tight integration of GPU data movement and MPI internal protocols. Typically, scientific applications spend a significant portion of their execution time in collective communication. Hence, optimizing performance of collectives has a significant impact on their performance. MPI-Alltoall is a heavily used collective that has O(N2) communication, for N processes. In this paper, we outline the major design alternatives for MPI-Alltoall collective communication operation on GPGPU clusters. We propose three design alternatives and provide a corresponding performance analysis. Using our dynamic staging techniques, the latency of MPI-Alltoall on GPU clusters can be improved by 44{\%} over a user level implementation and 31{\%} over a send-recv based implementation for 256 KByte messages on 8 processes. {\textcopyright} 2011 IEEE.},
  author          = {Singh, Ashish Kumar and Potluri, Sreeram and Wang, Hao and Kandalla, Krishna and Sur, Sayantan and Panda, Dhabaleswar K.},
  doi             = {10.1109/CLUSTER.2011.67},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2011/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/MPI alltoall personalized exchange on GPGPU clusters Design alternatives and benefit - Singh et al. - Proceedings of the IE.pdf:pdf},
  isbn            = {9780769545165},
  issn            = {15525244},
  journal         = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  keywords        = {Clusters,Collectives,GPGPU,GPU,InfiniBand,Infiniband,MPI},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,GPU,InfiniBand,MPI},
  pages           = {420--427},
  title           = {{MPI alltoall personalized exchange on GPGPU clusters: Design alternatives and benefit}},
  year            = {2011}
}
@article{Sojoodi2020,
  abstract      = {During recent years, big data explosion and the increase in main memory capacity, on the one hand, and the need for faster data processing, on the other hand, have caused the development of various in-memory processing tools to manage and analyze data. Engaging the speed of the main memory and advantaging data locality, these tools can process a large amount of data with high performance. Apache Ignite, as a distributed in-memory platform, can process massive volumes of data in parallel. Currently, this platform is CPU-based and does not utilize the GPU's processing resources. To address this concern, we introduce Ignite-GPU that uses the GPU's massively parallel processing power. Ignite-GPU handles a number of challenges in integrating GPUs into Ignite and utilizes the GPU's available resources. We have also identified and eliminated time-consuming overheads and used various GPU-specific optimization techniques to improve overall performance. Eventually, we have evaluated Ignite-GPU with the Genetic Algorithm, as a representative of data and compute-intensive algorithms, and gained more than thousands of times speedup in comparison with its CPU version.},
  author        = {Sojoodi, Amir Hossein and {Salimi Beni}, Majid and Khunjush, Farshad},
  doi           = {10.1007/s11227-020-03390-z},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Journal of Supercomputing/Ignite-GPU a GPU-enabled in-memory computing architecture on clusters - Sojoodi, Salimi Beni, Khunjush - Journal of Supercomputing.pdf:pdf},
  isbn          = {1122702003390},
  issn          = {15730484},
  journal       = {Journal of Supercomputing},
  keywords      = {Apache Ignite,GPU,Genetic{\_}Algorithm,Ignite,In-memory computing,Parallel processing},
  mendeley-tags = {GPU,Genetic{\_}Algorithm,Ignite},
  pages         = {1--28},
  publisher     = {Springer US},
  title         = {{Ignite-GPU: a GPU-enabled in-memory computing architecture on clusters}},
  year          = {2020}
}
@phdthesis{Sojoodi2020t,
  author          = {Sojoodi, Amirhossein},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Unknown/High-Performance Communications in Hybrid Clusters - Sojoodi - Unknown.pdf:pdf},
  keywords        = {Comp1},
  mendeley-groups = {ByPPRL},
  mendeley-tags   = {Comp1},
  pages           = {1--30},
  school          = {Queen's University},
  title           = {{High-Performance Communications in Hybrid Clusters}},
  year            = {2020}
}
@inproceedings{Sourouri,
  author        = {Sourouri, Mohammed and Gillberg, Tor and Baden, Scott B and Cai, Xing},
  booktitle     = {Proceedings of the IEEE International Conference on Parallel and Distributed Systems (ICPADS)},
  doi           = {10.1109/PADSW.2014.7097919},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Proceedings of the IEEE International Conference on Parallel and Distributed Systems (ICPADS)/Effective Multi GPU Communicatiom Using Multiple CUDA Streams and Threads - Sourouri et al. - Proceedings of.pdf:pdf},
  keywords      = {CUDA,GPU,Multi{\_}GPU,asynchronous communication,cuda,dual-gpu,gpu,gpudirect,intra-node,mpi,multi-gpu,openmp,p2p},
  mendeley-tags = {CUDA,GPU,Multi{\_}GPU},
  pages         = {981--986},
  title         = {{Effective Multi GPU Communicatiom Using Multiple CUDA Streams and Threads}},
  year          = {2014}
}
@article{Soyturk2021,
  abstract        = {Communication among devices in multi-GPU systems plays an important role in terms of performance and scalability. In order to optimize an application, programmers need to know the type and amount of the communication happening among GPUs. Although there are prior works to gather this information in MPI applications on distributed systems and multi-threaded applications on shared memory systems, there is no tool that identifies communication among GPUs. Our prior work, ComScribe, presents a point-to-point (P2P) communication detection tool for GPUs sharing a common host. In this work, we extend ComScribe to identify communication among GPUs for collective and P2P communication primitives in NVIDIA's NCCL library. In addition to P2P communications, collective communications are commonly used in HPC and AI workloads thus it is important to monitor the induced data movement due to collectives. Our tool extracts the size and the frequency of data transfers in an application and visualizes them as a communication matrix. To demonstrate the tool in action, we present communication matrices and some statistics for two applications coming from machine translation and image classification domains.},
  archiveprefix   = {arXiv},
  arxivid         = {2110.10401},
  author          = {Soyturk, Muhammet Abdullah and Akhtar, Palwisha and Tezcan, Erhan and Unat, Didem},
  eprint          = {2110.10401},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/arXiv/Monitoring Collective Communication Among GPUs - Soyturk et al. - arXiv.pdf:pdf},
  journal         = {arXiv},
  keywords        = {Benchmark,Collectives,GPU,MPI,Multi{\_}GPU,Profile,inter-gpu communication,multi-gpus,profiling},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Benchmark,Collectives,GPU,MPI,Multi{\_}GPU,Profile},
  pages           = {1--12},
  title           = {{Monitoring Collective Communication Among GPUs}},
  year            = {2021}
}
@inproceedings{Sridharan2014,
  abstract        = {Modern high-speed interconnection networks are designed with capabilities to support communication from multiple processor cores. The MPI endpoints extension has been proposed to ease process and thread count tradeoffs by enabling multithreaded MPI applications to efficiently drive independent network communication. In this work, we present the first implementation of the MPI endpoints interface and demonstrate the first applications running on this new interface. We use a novel library-based design that can be layered on top of any existing, production MPI implementation. Our approach uses proxy processes to isolate threads in an MPI job, eliminating threading overheads within the MPI library and allowing threads to achieve process-like communication performance. We evaluate the performance advantages of our implementation through several benchmarks and kernels. Performance results for the Lattice QCD Dslash kernel indicate that endpoints provides up to 2.9× improvement in communication performance and 1.87× overall performance improvement over a highly optimized hybrid MPI+OpenMP baseline on 128 processors.},
  author          = {Sridharan, Srinivas and Dinan, James and Kalamkar, Dhiraj D.},
  booktitle       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi             = {10.1109/SC.2014.45},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Enabling Efficient Multithreaded MPI Communication through a Library-Based Implementation.pdf:pdf},
  isbn            = {9781479955008},
  issn            = {21674337},
  keywords        = {Endpoints,Hybrid Parallel Programming,Hybrid{\_}MPI,MPI,Multithreaded{\_}MPI},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {Endpoints,Hybrid{\_}MPI,MPI,Multithreaded{\_}MPI},
  pages           = {487--498},
  title           = {{Enabling Efficient Multithreaded MPI Communication through a Library-Based Implementation of MPI Endpoints}},
  year            = {2014}
}
@phdthesis{Steiner2023,
  abstract        = {The Message Passing Interface (MPI) underlies most software run on large parallel machines or supercomputers, facilitating the development of highly parallel applications across various fields. Collective communication operations make up a large fraction of the runtime of MPI applications. These collective operations are generally implemented in multiple different algorithms, off which no single one performs the best for all inputs. Common MPI libraries include a large set of algorithms for each collective operation and decision logic for selection. The default selection, however, frequently underperforms, leaving room for performance improvements. State-of-the-art approaches commonly apply an offline tuning step, to adapt the selection logic to a specific machine and workload. An offline approach suffers from two main drawbacks: 1) a potentially long-running tuning step and 2) the necessity to predefine the collective cases to be tuned. To address these limitations, this thesis proposes a low-overhead online auto-tuner to be injected into the execution of MPI applications. Algorithms are selected randomly based on their predicted runtime, as indicated in the lightweight algorithm selection models. The actual runtime of collective operations is recorded and periodically used to train a runtime prediction model for each algorithm. Subsequently, these prediction models are used to update the algorithm selection models, which are injected into the next MPI applications. We demonstrate the feasibility of this auto-tuner in a quantitative study, achieving performance improvements through tuning ECP proxy applications on two distinct compute clusters},
  author          = {Steiner, Sebastian},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/Unknown/Online Algorithm Selection of MPI Collective Communication Operations - Steiner - Unknown.pdf:pdf},
  keywords        = {Auto-Tuning,Auto{\_}Tune,Collective Communication,Collectives,Keywords: HPC,MPI,Parallel Computing,Performance Prediction,Thesis},
  mendeley-groups = {Theses},
  mendeley-tags   = {Auto{\_}Tune,Collectives,Thesis},
  school          = {University of Wien},
  title           = {{Online Algorithm Selection of MPI Collective Communication Operations}},
  year            = {2023}
}
@techreport{Stevenson2023,
  author          = {Stevenson, Sally and System, Senior and Engineer, S W and March, G T C},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/Unknown/CUDA Graphs 101 - Stevenson et al. - Unknown.pdf:pdf},
  mendeley-groups = {Presentations {\&} Reports},
  title           = {{CUDA Graphs 101}},
  year            = {2023}
}
@techreport{Strengert2023,
  author          = {Strengert, Magnus},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/Unknown/Become Faster in Writing Performant CUDA Kernels using the Source Page in Nsight Compute Nsight Compute Nsight Systems Nsight Graphics N.pdf:pdf},
  mendeley-groups = {Presentations {\&} Reports},
  title           = {{Become Faster in Writing Performant CUDA Kernels using the Source Page in Nsight Compute Nsight Compute Nsight Systems Nsight Graphics Nsight Deep Learning Designer}},
  year            = {2023}
}
@inproceedings{Stuart2009,
  abstract      = {This paper explores the challenges in implementing a message passing interface usable on systems with dataparallel processors. As a case study, we design and implement the "DCGN" API on NVIDIA GPUs that is similar to MPI and allows full access to the underlying architecture. We introduce the notion of data-parallel thread-groups as a way to map resources to MPI ranks. We use a method that also allows the data-parallel processors to run autonomously from user-written CPU code. In order to facilitate communication, we use a sleep-based polling system to store and retrieve messages. Unlike previous systems, our method provides both performance and flexibility. By running a test suite of applications with different communication requirements, we find that a tolerable amount of overhead is incurred, somewhere between one and five percent depending on the application, and indicate the locations where this overhead accumulates. We conclude that with innovations in chipsets and drivers, this overhead will be mitigated and provide similar performance to typical CPUbased MPI implementations while providing fully-dynamic communication. {\textcopyright} 2009 IEEE.},
  author        = {Stuart, Jeff A. and Owens, John D.},
  booktitle     = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi           = {10.1109/IPDPS.2009.5161065},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2009/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/Message passing on data-parallel architectures - Stuart, Owens - Proceedings of the IEEE International Parallel.pdf:pdf},
  isbn          = {9781424437504},
  keywords      = {GPU,MPI},
  mendeley-tags = {GPU,MPI},
  pages         = {1--12},
  publisher     = {IEEE},
  title         = {{Message passing on data-parallel architectures}},
  year          = {2009}
}
@inproceedings{Subramoni2009,
  abstract      = {Though convergence has been a buzzword in the networking industry for sometime now, no vendor has successfully brought out a solution which combines the ubiquitous nature of Ethernet with the low latency and high performance capabilities that InfiniBand offers. Most of the overlay protocols introduced in the past have had to bear with some form of performance trade off or overhead. Recent advances in InfiniBand interconnect technology has allowed vendors to come out with a new model for network convergence - RDMA over Ethernet (RDMAoE). In this model, the IB packets are encapsulated into Ethernet frames thereby allowing us to transmit them seamlessly over an Ethernet network. The job of translating Infini-Band addresses to Ethernet addresses and back is taken care of by the InfiniBand HCA. This model, allows end users access to large computational clusters through the use of ubiquitous Ethernet interconnect technology while retaining the high performance, low latency guarantees that InfiniBand provides. In this paper, we present a detailed evaluation and analysis of the new RDMAoE protocol as opposed to the earlier overlay protocols as well as native-IB and socket based implementations. Through these evaluations, we also look at whether RDMAoE brings us closer the eventual goal of network convergence. The experimental results obtained with verbs, MPI, application and data center level evaluations show that RDMAoE is capable of providing performance comparable to Native-IB based applications on a standard 10GigE network. {\textcopyright} 2009 IEEE.},
  author        = {Subramoni, Hari and Lai, Ping and Luo, Miao and Panda, Dhabaleswar K.},
  booktitle     = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi           = {10.1109/CLUSTR.2009.5289144},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2009/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/RDMA over Ethernet - A preliminary study - Subramoni et al. - Proceedings of the IEEE International Conference on Cluster C.pdf:pdf},
  isbn          = {9781424450121},
  issn          = {15525244},
  keywords      = {RDMA},
  mendeley-tags = {RDMA},
  title         = {{RDMA over Ethernet - A preliminary study}},
  year          = {2009}
}
@inproceedings{Svedin2021,
  abstract        = {For many, Graphics Processing Units (GPUs) provides a source of reliable computing power. Recently, Nvidia introduced its 9th generation HPC-grade GPUs, the Ampere 100 (A100), claiming significant performance improvements over previous generations, particularly for AI-workloads, as well as introducing new architectural features such as asynchronous data movement. But how well does the A100 perform on non-AI benchmarks, and can we expect the A100 to deliver the application improvements we have grown used to with previous GPU generations? In this paper, we benchmark the A100 GPU and compare it to four previous generations of GPUs, with a particular focus on empirically quantifying our derived performance expectations. We find that the A100 delivers less performance increase than previous generations for the well-known Rodinia benchmark suite; we show that some of these performance anomalies can be remedied through clever use of the new data-movement features, which we microbenchmark and demonstrate where (and more importantly, how) they should be used.},
  author          = {Svedin, Martin and Chien, Steven W.D. and Chikafa, Gibson and Jansson, Niclas and Podobas, Artur},
  booktitle       = {Proceedings of the International Symposium on Highly Efficient Accelerators and Reconfigurable Technologies},
  doi             = {10.1145/3468044.3468053},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the International Symposium on Highly Efficient Accelerators and Reconfigurable Technologies/Benchmarking the Nvidia GPU Lineage From Early K80 to Modern A100 with Asynchronous Memory Tran.pdf:pdf},
  isbn            = {9781450385497},
  issn            = {1355-6037},
  keywords        = {Async{\_}Copy,GPU},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {Async{\_}Copy,GPU},
  pages           = {1--6},
  title           = {{Benchmarking the Nvidia GPU Lineage: From Early K80 to Modern A100 with Asynchronous Memory Transfers}},
  year            = {2021}
}
@article{Tallent2018,
  abstract        = {Scaling deep learning workloads across multiple GPUs on a single node has become increasingly important in data analytics. A key question is how well a PCIe-based GPU interconnect can perform relative to a custom high-performance interconnect such as NVIDIA's NVLink. This paper evaluates two such on-node interconnects for eight NVIDIA Pascal P100 GPUs: (a) the NVIDIA DGX-1's NVLink 1.0 ‘hybrid cube mesh'; and (b) the Cirrascale GX8's two-level PCIe tree using dual SR3615 switch risers. To show the effects of a range of neural network workloads, we define a parameterized version of the popular ResNet architecture. We define a workload intensity metric that characterizes the expected computation/communication ratio; we also locate AlexNet and GoogLeNet within that space. As expected, the DGX-1 typically has superior performance. However, the GX8 is very competitive on all ResNet workloads. With 8 GPUs, the GX8 can outperform the DGX-1 on all-to-all reductions by 10{\%} for medium-sized payloads; and in rare cases, the GX8 slightly outperforms on ResNet.},
  author          = {Tallent, Nathan R. and Gawande, Nitin A. and Siegel, Charles and Vishnu, Abhinav and Hoisie, Adolfy},
  doi             = {10.1007/978-3-319-72971-8_1},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Lecture Notes in Computer Science/Evaluating On-Node GPU interconnects for deep learning workloads - Tallent et al. - Lecture Notes in Computer Science.pdf:pdf},
  isbn            = {9783319729701},
  issn            = {16113349},
  journal         = {Lecture Notes in Computer Science},
  keywords        = {Cirrascale SR3615 switch riser,Convolutional neural networks,Deep{\_}Learning,GPU,GPU interconnects,Interconnect,Multi{\_}GPU,NVIDIA DGX-1,NVIDIA NVLink},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Deep{\_}Learning,GPU,Interconnect,Multi{\_}GPU},
  pages           = {3--21},
  title           = {{Evaluating On-Node GPU interconnects for deep learning workloads}},
  year            = {2018}
}
@article{Tan2021,
  abstract        = {Multi-Instance GPU (MIG) is a new feature introduced by NVIDIA A100 GPUs that partitions one physical GPU into multiple GPU instances. With MIG, A100 can be the most cost-efficient GPU ever for serving Deep Neural Networks (DNNs). However, discovering the most efficient GPU partitions is challenging. The underlying problem is NP-hard; moreover, it is a new abstract problem, which we define as the Reconfigurable Machine Scheduling Problem (RMS). This paper studies serving DNNs with MIG, a new case of RMS. We further propose a solution, MIG-serving. MIG- serving is an algorithm pipeline that blends a variety of newly designed algorithms and customized classic algorithms, including a heuristic greedy algorithm, Genetic Algorithm (GA), and Monte Carlo Tree Search algorithm (MCTS). We implement MIG-serving on Kubernetes. Our experiments show that compared to using A100 as-is, MIG-serving can save up to 40{\%} of GPUs while providing the same throughput.},
  archiveprefix   = {arXiv},
  arxivid         = {2109.11067},
  author          = {Tan, Cheng and Li, Zhichao and Zhang, Jian and Cao, Yu and Qi, Sikai and Liu, Zherui and Zhu, Yibo and Guo, Chuanxiong},
  eprint          = {2109.11067},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/arXiv/Serving DNN Models with Multi-Instance GPUs A Case of the Reconfigurable Machine Scheduling Problem - Tan et al. - arXiv.pdf:pdf},
  journal         = {arXiv},
  keywords        = {GPU,MIG},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {GPU,MIG},
  pages           = {1--20},
  title           = {{Serving DNN Models with Multi-Instance GPUs: A Case of the Reconfigurable Machine Scheduling Problem}},
  year            = {2021}
}
@inproceedings{Tatsugi2022,
  author          = {Tatsugi, Yuya and Nukada, Akira},
  booktitle       = {Proceedings of the Workshop on General Purpose Processing using GPUs (GPGPU)},
  doi             = {10.1145/3530390.3532732},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the Workshop on General Purpose Processing using GPUs (GPGPU)/Accelerating data transfer between host and device using idle GPU - Tatsugi, Nukada - Proceedings of the Workshop on General P.pdf:pdf},
  isbn            = {9781450393485},
  keywords        = {2022,GPU,GPUDirect{\_}Async,accelerating data trans-,acm reference format,data transfer,device using idle gpu,fer between host and,in the 14th work-,multi-gpu,nukada,nvidia cuda,yuya tatsugi and akira},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,GPUDirect{\_}Async},
  pages           = {1--6},
  title           = {{Accelerating data transfer between host and device using idle GPU}},
  year            = {2022}
}
@phdthesis{Temucin2021t,
  author          = {Temucin, Yıltan Hassan},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Unknown/High-Performance Interconnect-Aware MPI communication for Deep Learning Workloads - Temucin - Unknown.pdf:pdf},
  keywords        = {Deep{\_}Learning,GPU,MPI,Thesis},
  mendeley-groups = {MustKnow,ByPPRL,Theses},
  mendeley-tags   = {Deep{\_}Learning,GPU,MPI,Thesis},
  number          = {November},
  pages           = {1--128},
  title           = {{High-Performance Interconnect-Aware MPI communication for Deep Learning Workloads}},
  year            = {2021}
}
@inproceedings{Temucin2022,
  author        = {Temu{\c{c}}in, Yıltan Hassan and Grant, Ryan E and Afsahi, Ahmad},
  booktitle     = {Proceedings of the International Conference on Parallel Processing (ICPP)},
  doi           = {10.1145/3545008.3545088},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the International Conference on Parallel Processing (ICPP)/Micro-Benchmarking MPI Partitioned Point-to-Point Communication - Temu{\c{c}}in, Grant, Afsahi - Proceedings of the International Confe.pdf:pdf},
  isbn          = {9781450397339},
  keywords      = {Halo Exchange,MPI,Micro-Benchmarking,Partitioned,Partitioned Communication,Sweep3D,halo,micro-benchmarking,mpi,partitioned communication},
  mendeley-tags = {MPI,Partitioned},
  pages         = {1--12},
  publisher     = {Association for Computing Machinery},
  title         = {{Micro-Benchmarking MPI Partitioned Point-to-Point Communication}},
  year          = {2022}
}
@inproceedings{Temucin2021,
  author          = {Temucin, Yıltan Hassan and Sojoodi, Amirhossein and Alizadeh, Pedram and Afsahi, Ahmad},
  booktitle       = {Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)},
  doi             = {10.1109/HOTI52880.2021.00018},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the IEEE Symposium on High-Performance Interconnects (HOTI)/Efficient Multi-Path NVLink PCIe-Aware UCX based Collective Communication for Deep Learning - Temucin et al. - Proceedings of t.pdf:pdf},
  keywords        = {-mpi,Deep{\_}Learning,GPU,MPI,UCX,collective communication,cuda,deep learning workloads,gpu,nvlink,ucx},
  mendeley-groups = {MustKnow,UsedInComp2,ByPPRL},
  mendeley-tags   = {Deep{\_}Learning,GPU,MPI,UCX},
  pages           = {1--10},
  title           = {{Efficient Multi-Path NVLink / PCIe-Aware UCX based Collective Communication for Deep Learning}},
  year            = {2021}
}
@article{Temuc2021b,
  author          = {Temucin, Yıltan Hassan and Sojoodi, Amirhossein and Alizadeh, Pedram and Kitor, Benjamin W and Afsahi, Ahmad},
  doi             = {10.1109/MM.2022.3148670},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/IEEE Micro/Accelerating Deep Learning using Interconnect-Aware UCX Communication for MPI Collectives - Temucin et al. - IEEE Micro.pdf:pdf},
  journal         = {IEEE Micro},
  keywords        = {Deep{\_}Learning,GPU,MPI},
  mendeley-groups = {MustKnow,ByPPRL},
  mendeley-tags   = {Deep{\_}Learning,GPU,MPI},
  pages           = {1--9},
  title           = {{Accelerating Deep Learning using Interconnect-Aware UCX Communication for MPI Collectives}},
  year            = {2021}
}
@article{Thakur2005,
  abstract        = {We describe our work on improving the performance of collective communication operations in MPICH for clusters connected by switched networks. For each collective operation, we use multiple algorithms depending on the message size, with the goal of minimizing latency for short messages and minimizing bandwidth use for long messages. Although we have implemented new algorithms for all MPI (Message Passing Interface) collective operations, because of limited space we describe only the algorithms for allgather, broadcast, all-to-all, reduce-scatter, reduce, and allreduce. Performance results on a Myrinet-connected Linux cluster and an IBM SP indicate that, in all cases, the new algorithms significantly outperform the old algorithms used in MPICH on the Myrinet cluster, and, in many cases, they outperform the algorithms used in IBM's MPI on the SP. We also explore in further detail the optimization of two of the most commonly used collective operations, allreduce and reduce, particularly for long messages and non-power-of-two numbers of processes. The optimized algorithms for these operations perform several times better than the native algorithms on a Myrinet cluster, IBM SP, and Cray T3E. Our results indicate that to achieve the best performance for a collective communication operation, one needs to use a number of different algorithms and select the right algorithm for a particular message size and number of processes. {\textcopyright} 2005 Sage Publications.},
  author          = {Thakur, Rajeev and Rabenseifner, Rolf and Gropp, William},
  doi             = {10.1177/1094342005051521},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2005/The International Journal of High Performance Computing Applications/Optimization of collective communication operations in MPICH - Thakur, Rabenseifner, Gropp - The International Journal of High Perform.pdf:pdf},
  journal         = {The International Journal of High Performance Computing Applications},
  keywords        = {Collective communication,Collectives,MPI,Message passing,Reduction},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,MPI},
  number          = {1},
  pages           = {49--66},
  title           = {{Optimization of collective communication operations in MPICH}},
  volume          = {19},
  year            = {2005}
}
@article{ThaoNguyen2021,
  abstract        = {Training models on large-scale GPUs-accelerated clusters are becoming a commonplace due to the increase in complexity and size in deep learning models. One of the main challenges for distributed training is the collective communication overhead for large message sizes: up to hundreds of MB. In this paper, we propose two hierarchical distributed memory multileader AllReduce algorithms optimized for GPU-accelerated clusters (named lr{\_}lr and lr{\_}rab), in which GPUs inside a computing node perform an intra-node communication phase to gather and store results of local reduced values to designated GPUs (known as node leaders). Node leaders then keep a role as an inter-node communicator. Each leader exchanges one part of reduced values to the leaders of the other nodes in parallel. Hence, we are capable of significantly reducing the time for injecting data into the inter-node network. We also overlap the inter-node and intra-node communication by implementing our proposal in a pipelined manner. We evaluate those algorithms on the discrete-event simulation Simgrid. We show that our algorithms, lr{\_}lr and lr{\_}rab, can cut down the execution time of an AllReduce microbenchmark that uses the logical ring algorithm (lr) by up to 45{\%} and 51{\%}, respectively. With the pipelined implementation, our lr{\_}lr{\_}pipe achieves 15{\%} performance improvement when compared with lr{\_}lr. In addition, the simulation result also projects power savings for the network devices of up to 23{\%} and 32{\%}.},
  author          = {{Thao Nguyen}, Truong and Wahib, Mohamed and Takano, Ryousei},
  doi             = {10.1002/cpe.5574},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Concurrency and Computation Practice and Experience (CCPE)/Efficient MPI-AllReduce for large-scale deep learning on GPU-clusters - Thao Nguyen, Wahib, Takano - Concurrency and Computation Practic.pdf:pdf},
  issn            = {15320634},
  journal         = {Concurrency and Computation: Practice and Experience (CCPE)},
  keywords        = {AllReduce,Deep{\_}Learning,GPU,MPI,MPI{\_}Allreduce,distributed deep learning,high-performance computing (HPC)},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {Deep{\_}Learning,GPU,MPI,MPI{\_}Allreduce},
  pages           = {1--20},
  title           = {{Efficient MPI-AllReduce for large-scale deep learning on GPU-clusters}},
  volume          = {33},
  year            = {2021}
}
@article{Thune2023,
  author          = {Thune, Andreas and Reinemo, Sven-arne and Skeie, Tor and Cai, Xing},
  doi             = {10.1109/TPDS.2023.3253881},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/IEEE Transactions on Parallel and Distributed Systems/Detailed modeling of heterogeneous and communication - Thune et al. - IEEE Transactions on Parallel and Distributed Systems.pdf:pdf},
  journal         = {IEEE Transactions on Parallel and Distributed Systems},
  keywords        = {MPI,Modeling},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {MPI,Modeling},
  pages           = {1--14},
  title           = {{Detailed modeling of heterogeneous and communication}},
  year            = {2023}
}
@techreport{Toledo2021,
  author        = {Toledo, Leonel and Valero-Lara, Pedro and Pena, Antonio J.},
  booktitle     = {GPU Technology Conference},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/GPU Technology Conference/Accelerating Machine Learning Applications Using CUDA Graph and OpenACC - Toledo, Valero-Lara, Pena - GPU Technology Conference.pdf:pdf},
  keywords      = {CUDA,CUDA{\_}Graphs,GPU,Machine{\_}Learning},
  mendeley-tags = {CUDA,CUDA{\_}Graphs,GPU,Machine{\_}Learning},
  title         = {{Accelerating Machine Learning Applications Using CUDA Graph and OpenACC}},
  url           = {https://www.nvidia.com/en-us/on-demand/session/gtcspring21-e31212/},
  year          = {2021}
}
@inproceedings{Traff2020a,
  abstract        = {Many modern, high-performance systems increase the cumulated node-bandwidth by offering more than a single communication network and/or by having multiple connections to the network, such that a single processor-core cannot by itself saturate the off-node bandwidth. Efficient algorithms and implementations for collective operations as found in, e.g., MPI, must be explicitly designed for exploiting such multilane capabilities. We are interested in gauging to which extent this might be the case. We systematically decompose the MPI collectives into similar operations that can execute concurrently on and exploit multiple network lanes. Our decomposition is applicable to all standard MPI collectives (broadcast, gather, scatter, allgather, reduce allreduce, reduce-scatter, scan, alltoall), and our implementations' performance can be readily compared to the native collectives of any given MPI library. Contrary to expectation, our full-lane, performance guideline implementations in many cases show surprising performance improvements with different MPI libraries on a dual-socket, dual-network Intel OmniPath cluster, indicating a large potential for improving the performance of native MPI library implementations. Our full-lane implementations are in many cases large factors faster than the corresponding MPI collectives. We see similar results on a larger, dual-rail Intel InfiniBand cluster. The results indicate considerable room for improvement of the MPI collectives in current MPI libraries including a more efficient use of multilane capabilities.},
  author          = {Traff, Jesper Larsson and Hunold, Sascha},
  booktitle       = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi             = {10.1109/CLUSTER49012.2020.00037},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/Decomposing MPI Collectives for Exploiting Multi-lane Communication - Traff, Hunold - Proceedings of the IEEE Internatio(2).pdf:pdf},
  isbn            = {9781728166773},
  issn            = {15525244},
  keywords        = {Collectives,MPI},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Collectives,MPI},
  pages           = {270--280},
  title           = {{Decomposing MPI Collectives for Exploiting Multi-lane Communication}},
  year            = {2020}
}
@inproceedings{Traff2020,
  abstract      = {Many modern, high-performance systems increase the cumulated node-bandwidth by offering more than a single communication network and/or by having multiple connections to the network, such that a single processor-core cannot by itself saturate the off-node bandwidth. Efficient algorithms and implementations for collective operations as found in, e.g., MPI, must be explicitly designed for exploiting such multilane capabilities. We are interested in gauging to which extent this might be the case. We systematically decompose the MPI collectives into similar operations that can execute concurrently on and exploit multiple network lanes. Our decomposition is applicable to all standard MPI collectives (broadcast, gather, scatter, allgather, reduce allreduce, reduce-scatter, scan, alltoall), and our implementations' performance can be readily compared to the native collectives of any given MPI library. Contrary to expectation, our full-lane, performance guideline implementations in many cases show surprising performance improvements with different MPI libraries on a dual-socket, dual-network Intel OmniPath cluster, indicating a large potential for improving the performance of native MPI library implementations. Our full-lane implementations are in many cases large factors faster than the corresponding MPI collectives. We see similar results on a larger, dual-rail Intel InfiniBand cluster. The results indicate considerable room for improvement of the MPI collectives in current MPI libraries including a more efficient use of multilane capabilities.},
  author        = {Traff, Jesper Larsson and Hunold, Sascha},
  booktitle     = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi           = {10.1109/CLUSTER49012.2020.00037},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/Decomposing MPI Collectives for Exploiting Multi-lane Communication - Traff, Hunold - Proceedings of the IEEE International.pdf:pdf},
  isbn          = {9781728166773},
  issn          = {15525244},
  keywords      = {Collectives,MPI},
  mendeley-tags = {Collectives,MPI},
  pages         = {270--280},
  title         = {{Decomposing MPI Collectives for Exploiting Multi-lane Communication}},
  year          = {2020}
}
@article{Tripathy2021,
  abstract      = {Hash tables are used in a plethora of applications, including database operations, DNA sequencing, string searching, and many more. As such, there are many parallelized hash tables targeting multicore, distributed, and accelerator-based systems. We present in this work a multi-GPU hash table implementation that can process keys at a throughput comparable to that of distributed hash tables. Distributed CPU hash tables have received significantly more attention than GPU-based hash tables. We show that a single node with multiple GPUs offers roughly the same performance as a 500-1,000-core CPU-based cluster. Our algorithm's key component is our use of multiple sparse-graph data structures and binning techniques to build the hash table. As has been shown individually, these components can be written with massive parallelism that is amenable to GPU acceleration. Since we focus on an individual node, we also leverage communication primitives that are typically prohibitive in distributed environments. We show that our new multi-GPU algorithm shares many of the same features of the single GPU algorithm -- thus we have efficient collision management capabilities and can deal with a large number of duplicates. We evaluate our algorithm on two multi-GPU compute nodes: 1) an NVIDIA DGX2 server with 16 GPUs and 2) an IBM Power 9 Processor with 6 NVIDIA GPUs. With 32-bit keys, our implementation processes 8B keys per second, comparable to some 500-1,000-core CPU-based clusters and 4X faster than prior single-GPU implementations.},
  archiveprefix = {arXiv},
  arxivid       = {2104.00792},
  author        = {Tripathy, Alok and Green, Oded},
  eprint        = {2104.00792},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/arXiv/Scalable Hash Table for NUMA Systems - Tripathy, Green - arXiv.pdf:pdf},
  journal       = {arXiv},
  keywords      = {GPU,Hash{\_}Table},
  mendeley-tags = {GPU,Hash{\_}Table},
  pages         = {1--11},
  title         = {{Scalable Hash Table for NUMA Systems}},
  year          = {2021}
}
@article{Trobec2016,
  abstract      = {This article provides background information about interconnection networks, an analysis of previous developments, and an overview of the state of the art. The main contribution of this article is to highlight the importance of the interpolation and extrapolation of technological changes and physical constraints in order to predict the optimum future interconnection network. The technological changes are related to three of the most important attributes of interconnection networks: topology, routing, and flow-control algorithms. On the other hand, the physical constraints, that is, port counts, number of communication nodes, and communication speed, determine the realistic properties of the network. We present the state-of-the-art technology for the most commonly used interconnection networks and some background related to often-used network topologies. The interconnection networks of the best-performing petascale parallel computers from past and present Top500 lists are analyzed. The lessons learned from this analysis indicate that computer networks need better performance in future exascale computers. Such an approach leads to the conclusion that a high-radix topology with optical connections for longer links is set to become the optimum interconnect for a number of relevant application domains.},
  author        = {Trobec, Roman and Vasiljevi{\'{c}}, Radivoje and Toma{\v{s}}evi{\'{c}}, Milo and Milutinovi{\'{c}}, Veljko and Beivide, Ramon and Valero, Mateo},
  doi           = {10.1145/2983387},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/ACM Computing Surveys/Interconnection networks in petascale computer systems A survey - Trobec et al. - ACM Computing Surveys.pdf:pdf},
  issn          = {15577341},
  journal       = {ACM Computing Surveys},
  keywords      = {Exascale,Exascale computers,High performance parallel computers,Interconnect,Interconnection networks,Survey,Top500 list},
  mendeley-tags = {Exascale,Interconnect,Survey},
  number        = {3},
  title         = {{Interconnection networks in petascale computer systems: A survey}},
  volume        = {49},
  year          = {2016}
}
@article{Trumper2023,
  abstract        = {Performance optimization is an increasingly challenging but often repetitive task. While each platform has its quirks, the underlying code transformations rely on data movement and computational characteristics that recur across applications. This paper proposes to leverage those similarities by constructing an embedding space for subprograms. The continuous space captures both static and dynamic properties of loop nests via symbolic code analysis and performance profiling, respectively. Performance embeddings enable direct knowledge transfer of performance tuning between applications, which can result from autotuning or tailored improvements. We demonstrate this transfer tuning approach on case studies in deep neural networks, dense and sparse linear algebra compositions, and numerical weather prediction stencils. Transfer tuning reduces the search complexity by up to four orders of magnitude and outperforms the MKL library in sparse-dense matrix multiplication. The results exhibit clear correspondences between program characteristics and optimizations, outperforming prior specialized state-of-the-art approaches and generalizing beyond their capabilities.},
  archiveprefix   = {arXiv},
  arxivid         = {2303.08142},
  author          = {Tr{\"{u}}mper, Lukas and Ben-Nun, Tal and Schaad, Philipp and Calotoiu, Alexandru and Hoefler, Torsten},
  eprint          = {2303.08142},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/arXiv/Performance Embeddings A Similarity-based Approach to Automatic Performance Optimization - Tr{\"{u}}mper et al. - arXiv.pdf:pdf},
  journal         = {arXiv},
  keywords        = {Auto{\_}Tune},
  mendeley-groups = {Auto-Tuning},
  mendeley-tags   = {Auto{\_}Tune},
  pages           = {1--14},
  title           = {{Performance Embeddings: A Similarity-based Approach to Automatic Performance Optimization}},
  year            = {2023}
}
@article{Turchetto2020,
  abstract      = {This article presents a multi-GPU implementation of a Finite-Volume solver on a multi-resolution grid. The implementation completely offloads the computation to the GPUs and communications between different GPUs are implemented by means of the Message Passing Interface (MPI) API. Different domain decomposition techniques have been considered and the one based on the Hilbert Space Filling Curves (HSFC) showed optimal scalability. Several optimizations are introduced: One-to-one MPI communications among MPI ranks are completely masked by GPU computations on internal cells and a novel dynamic load balancing algorithm is introduced to minimize the waiting times at global MPI synchronization barriers. Such algorithm adapts the computational load of ranks in response to dynamical changes in the execution time of blocks and in network performances; Its capability to converge to a balanced computation has been empirically shown by numerical experiments. Tests exploit up to 64 GPUs and 83M cells and achieve an efficiency of 90 percent in weak scalability and 85 percent for strong scalability. The framework is general and the results of the article can be ported to a wide range of explicit 2D Partial Differential Equations solvers.},
  author        = {Turchetto, Massimiliano and Palu, Alessandro Dal and Vacondio, Renato},
  doi           = {10.1109/TPDS.2019.2961909},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/IEEE Transactions on Parallel and Distributed Systems/A General Design for a Scalable MPI-GPU Multi-Resolution 2D Numerical Solver - Turchetto, Palu, Vacondio - IEEE Transactions on Parallel.pdf:pdf},
  journal       = {IEEE Transactions on Parallel and Distributed Systems},
  keywords      = {AMR,CUDA,GPU,MPI,Multi{\_}GPU,dynamic load balancing,hilbert space filling curves,multi-GPU,multi-resolution grid,shallow water equations (SWE)},
  mendeley-tags = {CUDA,GPU,MPI,Multi{\_}GPU},
  pages         = {1036--1047},
  title         = {{A General Design for a Scalable MPI-GPU Multi-Resolution 2D Numerical Solver}},
  year          = {2020}
}
@techreport{TwimlAI2018,
  author          = {TwimlAI},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Unknown/Trends in Deep Learning with Jeremy Howard - TwimlAI - Unknown.pdf:pdf},
  keywords        = {Deep{\_}Learning},
  mendeley-groups = {Presentations {\&} Reports},
  mendeley-tags   = {Deep{\_}Learning},
  title           = {{Trends in Deep Learning with Jeremy Howard}},
  url             = {https://twimlai.com/twiml-talk-214-trends-in-deep-learning-with-jeremy-howard/},
  year            = {2018}
}
@article{Ueno2019,
  abstract        = {Data-parallel distributed deep learning requires an AllReduce operation between all GPUs with message sizes in the order of hundreds of megabytes. The popular implementation of AllReduce for deep learning is the Ring-AllReduce, but this method suffers from latency when using thousands of GPUs. There have been efforts to reduce this latency by combining the ring with more latency-optimal hierarchical methods. In the present work, we consider these hierarchical communication methods as a general hierarchical Ring-AllReduce with a pure Ring-AllReduce on one end and Rabenseifner's algorithm on the other end of the spectrum. We exhaustively test the various combinations of hierarchical partitioning of processes on the ABCI system in Japan on up to 2048 GPUs. We develop a performance model for this generalized hierarchical Ring-AllReduce and show the lower-bound of the effective bandwidth achievable for the hierarchical NCCL communication on thousands of GPUs. Our measurements agree well with our performance model. We also find that the optimal large-scale process hierarchy contains the optimal small-scale process hierarchy so the search space for the optimal communication will be reduced.},
  author          = {Ueno, Yuichiro and Yokota, Rio},
  doi             = {10.1109/CCGRID.2019.00057},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the IEEEACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)/Exhaustive study of hierarchical allreduce patterns for large messages between GPUs - Ueno, Yokota - Proc.pdf:pdf},
  isbn            = {9781728109121},
  journal         = {Proceedings of the IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing (CCGRID)},
  keywords        = {AllReduce,Deep Learning,Deep{\_}Learning,GPU,Hierarchical,InfiniBand,Large Message,MPI,MPI{\_}Allreduce,NCCL,NVLink},
  mendeley-groups = {MustKnow,UsedInComp1,UsedInComp2},
  mendeley-tags   = {Deep{\_}Learning,GPU,InfiniBand,MPI,MPI{\_}Allreduce,NCCL,NVLink},
  pages           = {430--439},
  title           = {{Exhaustive study of hierarchical allreduce patterns for large messages between GPUs}},
  year            = {2019}
}
@inproceedings{Underwood2004,
  abstract        = {It is well known that traditional micro-benchmarks do not fully capture the salient architectural features that impact application performance. Even worse, micro-benchmarks that target MPI and the communications sub-system do not accurately represent the way that applications use MPI. For example, traditional MPI latency benchmarks time a ping-pong communication with one send and one receive on each of two nodes. The time to post the receive is never counted as part of the latency. This scenario is not even marginally representative of most applications. Two new micro-benchmarks are presented here that analyze network latency in a way that more realistically represents the way that MPI is typically used. These benchmarks are used to evaluate modern high-performance networks, including Quadrics, InfiniBand, and Myrinet.},
  author          = {Underwood, Keith D. and Brightwell, Ron},
  booktitle       = {Proceedings of the International Conference on Parallel Processing (ICPP)},
  doi             = {10.1109/ICPP.2004.1327915},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2004/Proceedings of the International Conference on Parallel Processing (ICPP)/The impact of MPI queue usage on message latency - Underwood, Brightwell - Proceedings of the International Conference on Paralle.pdf:pdf},
  isbn            = {0769521975},
  issn            = {01903918},
  keywords        = {MPI,Message{\_}Matching},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {MPI,Message{\_}Matching},
  pages           = {152--160},
  title           = {{The impact of MPI queue usage on message latency}},
  year            = {2004}
}
@inproceedings{Underwood2005,
  abstract      = {With the heavy reliance of modern scientific applications upon the MPI Standard, it has become critical for the implementation of MPI to be as capable and as fast as possible. This has led some of the fastest modem networks to introduce the capability to offload aspects of MPI processing to an embedded processor on the network interface. With this important capability has come significant performance implications. Most notably, the time to process long queues of posted receives or unexpected messages is substantially longer on embedded processors. This paper presents an associative list matching structure to accelerate the processing of moderate length queues in MPI. Simulations are used to compare the performance of an embedded processor augmented with this capability to a baseline implementation. The proposed enhancement significantly reduces latency for moderate length queues while adding virtually no overhead for extremely short queues.},
  author        = {Underwood, Keith D. and Hemmert, K. Scott and Rodrigues, Arun and Murphy, Richard and Brightwell, Ron},
  booktitle     = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi           = {10.1109/IPDPS.2005.30},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2005/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/A hardware acceleration unit for MPI queue processing - Underwood et al. - Proceedings of the IEEE Internationa.pdf:pdf},
  isbn          = {0769523129},
  keywords      = {MPI,Message{\_}Matching},
  mendeley-tags = {MPI,Message{\_}Matching},
  pages         = {1--10},
  title         = {{A hardware acceleration unit for MPI queue processing}},
  year          = {2005}
}
@techreport{Unnikrishnan2023,
  author          = {Unnikrishnan, Deepak and System, Senior and Engineer, Software},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/Unknown/Measure Right ! Best Practices When Benchmarking CUDA Applications - Unnikrishnan, System, Engineer - Unknown.pdf:pdf},
  mendeley-groups = {Presentations {\&} Reports},
  title           = {{Measure Right ! Best Practices When Benchmarking CUDA Applications}},
  year            = {2023}
}
@inproceedings{Vadhiyar2000,
  abstract        = {The performance of the MPI's collective communications is critical in most MPI-based applications. A general algorithm for a given collective communication operation may not give good performance on all systems due to the differences in architectures, network parameters and the storage capacity of the underlying MPI implementation. In this paper, we discuss an approach in which the collective communications are tuned for a given system by conducting a series of experiments on the system. We also discuss a dynamic topology method that uses the tuned static topology shape, but re-orders the logical addresses to compensate for changing run time variations. A series of experiments were conducted comparing our tuned collective communication operations to various native vendor MPI implementations. The use of the tuned collective communications resulted in about 30{\%}-650{\%} improvement in performance over the native MPI implelementations.},
  author          = {Vadhiyar, S.S. and Fagg, G.E. and Dongarra, J.},
  booktitle       = {Proceedings of the ACM/IEEE Conference on Supercomputing (SC)},
  doi             = {10.1109/sc.2000.10024},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2000/Proceedings of the ACMIEEE Conference on Supercomputing (SC)/Automatically Tuned Collective Communications - Vadhiyar, Fagg, Dongarra - Proceedings of the ACMIEEE Conference on Supercomputing (SC).pdf:pdf},
  isbn            = {0780398025},
  keywords        = {Auto{\_}Tune,Collectives,Heuristics},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Auto{\_}Tune,Collectives,Heuristics},
  pages           = {1--11},
  title           = {{Automatically Tuned Collective Communications}},
  year            = {2000}
}
@inproceedings{Vaidyanathan2015,
  abstract        = {We present a new approach for multithreaded communication and asynchronous progress in MPI applications, wherein we offload communication processing to a dedicated thread. The central premise is that given the rapidly increasing core counts on modern systems, the improvements in MPI performance arising from dedicating a thread to drive communication outweigh the small loss of resources for application computation, particularly when overlap of communication and computation can be exploited. Our approach allows application threads to make MPI calls concurrently, enqueuing these as communication tasks to be processed by a dedicated communication thread. This not only guarantees progress for such communication operations, but also reduces load imbalance. Our implementation additionally significantly reduces the overhead of mutual exclusion seen in existing implementations for applications using MPI-THREAD-MULTIPLE. Our technique requires no modification to the application, and we demonstrate significant performance improvement (up to 2X) for QCD, 1-D FFT and deep learning CNN applications.},
  author          = {Vaidyanathan, Karthikeyan and Kalamkar, Dhiraj D. and Pamnany, Kiran and Hammond, Jeff R. and Balaji, Pavan and Das, Dipankar and Park, Jongsoo and Jo{\'{o}}, B{\'{a}}lint},
  booktitle       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi             = {10.1145/2807591.2807602},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Improving concurrency and asynchrony in multithreaded MPI applications using software off.pdf:pdf},
  isbn            = {9781450337236},
  issn            = {21674337},
  keywords        = {Hybrid{\_}MPI,Multithreaded{\_}MPI,Offloading},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {Hybrid{\_}MPI,Multithreaded{\_}MPI,Offloading},
  pages           = {1--12},
  title           = {{Improving concurrency and asynchrony in multithreaded MPI applications using software offloading}},
  year            = {2015}
}
@inproceedings{Venkata2019,
  abstract      = {OpenSHMEM is one of the key programming models for High Performance Computing (HPC) applications with irregular communication patterns. Particularly, it is useful for problems that cannot be decomposed easily such as graph partitioning. The programming model supports Remote Memory Access (RMA), atomics, and collective operations. In this paper, we explore and evaluate the In-network Computing approach for accelerating the OpenSHMEM collective operations, particularly barrier, broadcast, and reduction operations. To achieve acceleration, In-network Computing leverages hardware engines on the networking elements and effective software that can efficiently use these capabilities. We explore the value of this approach for collective operations on the InfiniBand Host Channel Adapters (HCAs) and switches. Particularly, we focus on the recently introduced collective offload feature provided by the Mellanox Scalable Hierarchical Aggregation and Reduction Protocol (SHARP) TM capability, which accelerates the barriers and reduction operations; the multicast capability accelerates the broadcast collective operation. To leverage the hardware capabilities, we complement it with an effective software stack that includes Hierarchical Collectives (HCOLL) library, and SHARP layer. Our evaluation on Oak Ridge National Laboratory (ORNL)'s Summit system, which is the fastest supercomputer on the June 2019 Top 500 list, show that the hardware and software acceleration in the In-network Computing approach is key for achieving the performance and scalability required for collectives and applications. For a 5120 process OpenSHMEM job, our results show that the barrier operation is 710{\%} faster, broadcast is 370{\%} faster, and reduction operation is 10 times faster when compared with the implementation of collective operations with no acceleration. Further, experiments with a 2D-Heat kernel show that the In-network Computing approach is very effective for realworld applications.},
  author        = {Venkata, Manjunath Gorentla and Bloch, Gil and Shainer, Gilad and Graham, Richard L.},
  booktitle     = {Proceedings of the International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)},
  doi           = {10.1109/SBAC-PAD.2019.00042},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)/Accelerating OpenSHMEM collectives using in-network computing approach - Venkata et al. - Pro.pdf:pdf},
  isbn          = {9781728141947},
  issn          = {15506533},
  keywords      = {Collective Operations,Collectives,HPC,InfiniBand,MPI,OpenSHMEM,Parallel Programming Models,Programming{\_}Model},
  mendeley-tags = {Collectives,MPI,OpenSHMEM,Programming{\_}Model},
  pages         = {212--219},
  publisher     = {IEEE},
  title         = {{Accelerating OpenSHMEM collectives using in-network computing approach}},
  volume        = {2019-Octob},
  year          = {2019}
}
@inproceedings{Venkatesh2016,
  abstract      = {GPGPUs are becoming ubiquitous entities in high performance computing systems owing to their large compute capacities at low power footprints. Together with high performance interconnects such as InfiniBand (IB), GPGPUs are paving the way for highly capable, energy-efficient distributed computing systems for scientific applications. GPGPUs are throughput devices that benefit immensely from latency hiding techniques. Thus, long latency communication operations such as MPI collectives that originate or finish at GPU memories must be well hidden. Although popular Message Passing libraries offer non-blocking collective operations based on host memories, no known works have explored the same for GPU memories. In this work we propose, for first time, Non-blocking MPI collective operations from GPU memories and realize an efficient implementation through the coupling of CORE-Direct offload mechanisms and NVIDIA CUDA capabilities. In addition, we also propose a novel way to avoid peer-To-peer limitations without explicit host processor intervention to maximize overlap with good latency. Our micro-benchmark evaluations show that the proposed designs can yield close to maximum overlap percentages for dense collective operations. Results with as many as 64 GPU nodes also show that the designs can perform comparably with the latency of blocking variant of the collective in the medium and large message ranges.},
  author        = {Venkatesh, A. and Hamidouche, K. and Subramoni, H. and Panda, Dhabaleswar K.},
  booktitle     = {Proceedings of the IEEE International Conference on High Performance Computing (HiPC)},
  doi           = {10.1109/HiPC.2015.50},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the IEEE International Conference on High Performance Computing (HiPC)/Offloaded GPU Collectives Using CORE-Direct and CUDA Capabilities on InfiniBand Clusters - Venkatesh et al. - Proceed.pdf:pdf},
  isbn          = {9781467384872},
  keywords      = {CUDA,Collectives,Core-direct,GPU,GPU-Direct RDMA,GPUDirect{\_}RDMA,Non-blocking collectives,Nonblocking,Offloading},
  mendeley-tags = {CUDA,Collectives,GPUDirect{\_}RDMA,Nonblocking,Offloading},
  pages         = {234--243},
  publisher     = {IEEE},
  title         = {{Offloaded GPU Collectives Using CORE-Direct and CUDA Capabilities on InfiniBand Clusters}},
  year          = {2016}
}
@inproceedings{Venkatesh2014,
  abstract      = {Several streaming applications in the field of high performance computing are obtaining significant speedups in execution time by leveraging the raw compute power offered by modern GPGPUs. This raw compute power, coupled with the high network throughput offered by high performance interconnects such as InfiniBand (IB) are allowing streaming applications to scale to rapidly. A frequently used operation that constitutes to the execution of multi-node streaming applications is the broadcast operation where data from a single source is transmitted to multiple sinks, typically from a live data site. Although high performance networks like IB offer novel features like hardware based multicast to speed up the performance of the broadcast operation, their benefits have been limited to host based applications due to the inability of IB Host Channel Adapters (HCAs) to directly access the memory of the GPGPUs. This poses a significant performance bottleneck to high performance streaming applications that rely heavily on broadcast operations from GPU memories. The recently introduced GPUDirect RDMA feature alleviates this bottleneck by enabling IB HCAs to perform data transfers directly to / from GPU memory (bypassing host memory). Thus, it presents an attractive alternative to designing high performance broadcast operations for GPGPU based high performance streaming applications. In this work, we propose a novel method for fully utilizing GPUDirect RDMA and hardware multicast features in tandem to design a high performance broadcast operation for streaming applications. The experiments conducted with the proposed design show up 60{\%} decrease in latency and 3X-4X improvement in a throughput benchmark compared to the naive scheme on 64 GPU nodes.},
  author        = {Venkatesh, A. and Subramoni, H. and Hamidouche, K. and Panda, Dhabaleswar K.},
  booktitle     = {Proceedings of the IEEE International Conference on High Performance Computing (HiPC)},
  doi           = {10.1109/HiPC.2014.7116875},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Proceedings of the IEEE International Conference on High Performance Computing (HiPC)/A high performance broadcast design with hardware multicast and GPUDirect RDMA for streaming applications on Infiniba.pdf:pdf},
  isbn          = {9781479959761},
  keywords      = {Broadcast,GPU,MPI,RDMA},
  mendeley-tags = {Broadcast,GPU,MPI,RDMA},
  pages         = {1--10},
  publisher     = {IEEE},
  title         = {{A high performance broadcast design with hardware multicast and GPUDirect RDMA for streaming applications on Infiniband clusters}},
  year          = {2014}
}
@article{Verbraeken2020,
  abstract        = {The demand for artificial intelligence has grown significantly over the last decade and this growth has been fueled by advances in machine learning techniques and the ability to leverage hardware acceleration. However, in order to increase the quality of predictions and render machine learning solutions feasible for more complex applications, a substantial amount of training data is required. Although small machine learning models can be trained with modest amounts of data, the input for training larger models such as neural networks grows exponentially with the number of parameters. Since the demand for processing training data has outpaced the increase in computation power of computing machinery, there is a need for distributing the machine learning workload across multiple machines, and turning the centralized into a distributed system. These distributed systems present new challenges, first and foremost the efficient parallelization of the training process and the creation of a coherent model. This article provides an extensive overview of the current state-of-the-art in the field by outlining the challenges and opportunities of distributed machine learning over conventional (centralized) machine learning, discussing the techniques used for distributed machine learning, and providing an overview of the systems that are available.},
  author          = {Verbraeken, Joost and Wolting, Matthijs and Katzy, Jonathan and Kloppenburg, Jeroen and Verbelen, Tim and Rellermeyer, Jan S.},
  doi             = {10.1145/3377454},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/ACM Computing Surveys/A Survey on Distributed Machine Learning - Verbraeken et al. - ACM Computing Surveys.pdf:pdf},
  issn            = {0360-0300},
  journal         = {ACM Computing Surveys},
  keywords        = {Distributed,Machine{\_}Learning,Survey},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Distributed,Machine{\_}Learning,Survey},
  number          = {2},
  pages           = {1--33},
  title           = {{A Survey on Distributed Machine Learning}},
  volume          = {53},
  year            = {2020}
}
@article{Wang2014,
  abstract        = {Designing high-performance and scalable applications on GPU clusters requires tackling several challenges. The key challenge is the separate host memory and device memory, which requires programmers to use multiple programming models, such as CUDA and MPI, to operate on data in different memory spaces. This challenge becomes more difficult to tackle when non-contiguous data in multidimensional structures is used by real-world applications. These challenges limit the programming productivity and the application performance. We propose the GPU-Aware MPI to support data communication from GPU to GPU using standard MPI. It unifies the separate memory spaces, and avoids explicit CPU-GPU data movement and CPU/GPU buffer management. It supports all MPI datatypes on device memory with two algorithms: a GPU datatype vectorization algorithm and a vector based GPU kernel data pack and unpack algorithm. A pipeline is designed to overlap the non-contiguous data packing and unpacking on GPUs, the data movement on the PCIe, and the RDMA data transfer on the network. We incorporate our design with the open-source MPI library MVAPICH2 and optimize a production application: the multiphase 3D LBM. Besides the increase of programming productivity, we observe up to 19.9 percent improvement in application-level performance on 64 GPUs of the Oakley supercomputer.},
  author          = {Wang, Hao and Potluri, Sreeram and Bureddy, Devendar and Rosales, Carlos and Panda, Dhabaleswar K.},
  doi             = {10.1109/TPDS.2013.222},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/IEEE Transactions on Parallel and Distributed Systems/GPU-aware MPI on RDMA-enabled clusters Design, implementation and evaluation - Wang et al. - IEEE Transactions on Parallel and Distribut.pdf:pdf},
  issn            = {15582183},
  journal         = {IEEE Transactions on Parallel and Distributed Systems},
  keywords        = {CUDA,GPU,GPUDirect{\_}RDMA,InfiniBand,Lattice Boltzmann method,MPI,RDMA},
  mendeley-groups = {MustKnow,UsedInComp1,UsedInComp2},
  mendeley-tags   = {CUDA,GPU,GPUDirect{\_}RDMA,InfiniBand,MPI},
  pages           = {2595--2605},
  title           = {{GPU-aware MPI on RDMA-enabled clusters: Design, implementation and evaluation}},
  year            = {2014}
}
@article{Wang2011,
  abstract        = {Data parallel architectures, such as General Purpose Graphics Units (GPGPUs) have seen a tremendous rise in their application for High End Computing. However, data movement in and out of GPGPUs remain the biggest hurdle to overall performance and programmer productivity. Applications executing on a cluster with GPUs have to manage datamovement using CUDA in addition toMPI, the de-facto parallel programming standard. Currently, data movement with CUDA and MPI libraries is not integrated and it is not as efficient as possible. In addition, MPI-2 one sided communication does not work for windows in GPU memory, as there is no way to remotely get or put data from GPU memory in a one-sided manner. In this paper, we propose a novel MPI design that integrates CUDA data movement transparently with MPI. The programmer is presented with one MPI interface that can communicate to and from GPUs. Data movement from GPU and network can now be overlapped. The proposed design is incorporated into the MVAPICH2 library. To the best of our knowledge, this is the first work of its kind to enable advanced MPI features and optimized pipelining in a widely used MPI library. We observe up to 45{\%} improvement in one-way latency. In addition, we show that collective communication performance can be improved significantly: 32{\%}, 37{\%} and 30{\%} improvement for Scatter, Gather and Allotall collective operations, respectively. Further, we enable MPI-2 one sided communication with GPUs.We observe up to 45{\%} improvement for Put and Get operations. {\textcopyright} Springer-Verlag 2011.},
  author          = {Wang, Hao and Potluri, Sreeram and Luo, Miao and Singh, Ashish Kumar and Sur, Sayantan and Panda, Dhabaleswar K.},
  doi             = {10.1007/s00450-011-0171-3},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2011/Computer Science - Research and Development/MVAPICH2-GPU Optimized GPU to GPU communication for InfiniBand clusters - Wang et al. - Computer Science - Research and Development.pdf:pdf},
  journal         = {Computer Science - Research and Development},
  keywords        = {CUDA,Clusters,GPGPU,GPU,InfiniBand,MPI},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {CUDA,GPU,InfiniBand,MPI},
  pages           = {257--266},
  title           = {{MVAPICH2-GPU: Optimized GPU to GPU communication for InfiniBand clusters}},
  year            = {2011}
}
@inproceedings{Wang2022,
  author        = {Wang, Hao and Wang, Haofeng and Wang, Sufang},
  booktitle     = {Proceedings of the International Conference on Electronics and Communication; Network and Computer Technology (ECNCT)},
  doi           = {10.1117/12.2628558},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the International Conference on Electronics and Communication Network and Computer Technology (ECNCT)/Multi-task scheduling framework for OpenCL programs on CPUs-GPUs heterogeneous platfor.pdf:pdf},
  keywords      = {GPU,OpenCL,Scheduling},
  mendeley-tags = {GPU,OpenCL,Scheduling},
  number        = {March},
  pages         = {31},
  title         = {{Multi-task scheduling framework for OpenCL programs on CPUs-GPUs heterogeneous platforms}},
  year          = {2022}
}
@article{Wang2022a,
  abstract        = {Processing large graphs with memory-limited GPU needs to resolve issues of host-GPU data transfer, which is a key performance bottleneck. Existing GPU-accelerated graph processing frameworks reduce the data transfers by managing the active subgraph transfer at runtime. Some frameworks adopt explicit transfer management approaches based on explicit memory copy with filter or compaction. In contrast, others adopt implicit transfer management approaches based on on-demand access with zero-copy or unified-memory. Having made intensive analysis, we find that as the active vertices evolve, the performance of the two approaches varies in different workloads. Due to heavy redundant data transfers, high CPU compaction overhead, or low bandwidth utilization, adopting a single approach often results in suboptimal performance. In this work, we propose a hybrid transfer management approach to take the merits of both the two approaches at runtime, with an objective to achieve the shortest execution time in each iteration. Based on the hybrid approach, we present HytGraph, a GPU-accelerated graph processing framework, which is empowered by a set of effective task scheduling optimizations to improve the performance. Our experimental results on real-world and synthesized graphs demonstrate that HyTGraph achieves up to 10.27X speedup over existing GPU-accelerated graph processing systems including Grus, Subway, and EMOGI.},
  archiveprefix   = {arXiv},
  arxivid         = {2208.14935},
  author          = {Wang, Qiange and Ai, Xin and Zhang, Yanfeng and Chen, Jing and Yu, Ge},
  eprint          = {2208.14935},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/arXiv/HyTGraph GPU-Accelerated Graph Processing with Hybrid Transfer Management - Wang et al. - arXiv.pdf:pdf},
  journal         = {arXiv},
  keywords        = {GPU},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU},
  pages           = {1--14},
  title           = {{HyTGraph: GPU-Accelerated Graph Processing with Hybrid Transfer Management}},
  year            = {2022}
}
@inproceedings{Wang2022c,
  abstract      = {Calculation of many-body correlation functions is one of the critical kernels utilized in many scientific computing areas, especially in Lattice Quantum Chromodynamics (Lattice QCD). It is formalized as a sum of a large number of contraction terms each of which can be represented by a graph consisting of vertices describing quarks inside a hadron node and edges designating quark propagations at specific time intervals. Due to its computation- and memory-intensive nature, real-world physics systems (e.g., multi-meson or multi-baryon systems) explored by Lattice QCD prefer to leverage multi-GPUs. Different from general graph processing, many-body correlation function calculations show two specific features: a large number of computation-/data-intensive kernels and frequently repeated appearances of original and intermediate data. The former results in expensive memory operations such as tensor movements and evictions. The latter offers data reuse opportunities to mitigate the data-intensive nature of many-body correlation function calculations. However, existing graph-based multi-GPU schedulers cannot capture these data-centric features, thus resulting in a sub-optimal performance for many-body correlation function calculations. To address this issue, this paper presents a multi-GPU scheduling framework, MICCO, to accelerate contractions for correlation functions particularly by taking the data dimension (e.g., data reuse and data eviction) into account. This work first performs a comprehensive study on the interplay of data reuse and load balance, and designs two new concepts: local reuse pattern and reuse bound to study the opportunity of achieving the optimal trade-off between them. Based on this study, MICCO proposes a heuristic scheduling algorithm and a machine-learning-based regression model to generate the optimal setting of reuse bounds. Specifically, MICCO is integrated into a real-world Lattice QCD system, Redstar, for the first time running on multiple GPUs. The evaluation demonstrates MICCO outperforms other state-of-art works, achieving up to 2.25× speedup in synthesized datasets, and 1.49× speedup in real-world correlation functions.},
  author        = {Wang, Qihan and Ren, Bin and Chen, Jie and Edwards, Robert G.},
  booktitle     = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi           = {10.1109/IPDPS53621.2022.00022},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/MICCO An Enhanced Multi-GPU Scheduling Framework for Many-Body Correlation Functions - Wang et al. - Proceeding.pdf:pdf},
  isbn          = {9781665481069},
  keywords      = {GPU,Multi{\_}GPU,Scheduling},
  mendeley-tags = {GPU,Multi{\_}GPU,Scheduling},
  pages         = {135--145},
  title         = {{MICCO: An Enhanced Multi-GPU Scheduling Framework for Many-Body Correlation Functions}},
  year          = {2022}
}
@article{Wang2022b,
  abstract        = {MPI communication optimization is a crucial stage to optimize high-performance applications. As a formal analysis of MPI communication, the communication performance models have made some achievements in improving the efficiency of collective algorithms and optimizing communication scheduling. However, previous models are difficult to model asynchronous concurrent communication and do not take into account numerous contention factors. In this paper, we present C-Lop, an incremental MPI performance model based on $\tau$-Lop. Firstly, C-Lop proposes a method for asynchronous modeling of concurrent communication. As the only model that considers concurrent transmission, $\tau$-Lop describes the cost of the all processes as a whole without distinguishing the cost of each process. Here, C-Lop uses the idea of asynchronous modeling that describe the cost of the system by averaging the communication cost per process. It can describe the communication cost for some systems with out-of-sync communication more accurately. Moreover, C-Lop introduces the parameter C to represent the contention, and considers the contention of concurrent transmissions on network-on-chip, data reuse, and contention of noncommunication processes to make a more accuracy estimation. Furthermore, parameter C can be customized to fit more application scenarios. In addition, we evaluate several common collective algorithms, a matrix multiplication algorithm (SUMMA), and two kinds of communication in a three-dimensional multi-grid application on the Tianhe-3 prototype, and results show that C-Lop outperforms the competition.},
  author          = {Wang, Ziheng and Chen, Heng and Cai, Weiling and Dong, Xiaoshe and Zhang, Xingjun},
  doi             = {10.1016/j.parco.2022.102925},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Parallel Computing/C-Lop Accurate contention-based modeling of MPI concurrent communication - Wang et al. - Parallel Computing.pdf:pdf},
  issn            = {01678191},
  journal         = {Parallel Computing},
  keywords        = {MPI,Message passing interface,Modeling,Multicore clusters,Parallel performance models,Performance analysis},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {MPI,Modeling},
  pages           = {1--13},
  title           = {{C-Lop: Accurate contention-based modeling of MPI concurrent communication}},
  year            = {2022}
}
@inproceedings{B2020,
  abstract      = {Overlap of communication with computation is a key optimization for high performance computing (HPC) applications. In this paper, we explore the usage of user-level threading to enable productive and efficient communi- cation overlap and pipelining. We extend OpenSHMEM with integrated user- level thread scheduling, enabling applications to leverage fine-grain thread- ing as an alternative to non-blocking communication. Our solution introduces communication-aware thread scheduling that utilizes the communication state of threads to minimize context switching overheads. We identify several pat- terns common to multi-threaded OpenSHMEM applications, leverage user-level threads to increase overlap of communication and computation, and explore the impact of different thread scheduling policies. Results indicate that user- level threading can enable blocking communication to meet the performance of highly-optimized, non-blocking, single-threaded codes with significantly lower application-level complexity. In one case, we observe a 28.7{\%} performance improvement for the Smith-Waterman DNA sequence alignment benchmark.},
  author        = {{Wasi-ur- Rahman}, Md. and Ozog, David and Dinan, James},
  booktitle     = {Proceedings of the IEEE International Conference on High Performance Computing (HiPC)},
  doi           = {10.1007/978-3-030-50743-5},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the IEEE International Conference on High Performance Computing (HiPC)/Simplifying Communication Overlap in OpenSHMEM Through Integrated User-Level Thread Scheduling - Wasi-ur- Rahman, Ozo.pdf:pdf},
  isbn          = {9783030507435},
  keywords      = {FP16,Half-precision,Low-precision,Mat,OpenSHMEM,Tensor cores,Tensor{\_}Core,accuracy,fp16,gemm,half-precision,linear algebra,low-precision,matrix multiplication,tensor cores},
  mendeley-tags = {OpenSHMEM,Tensor{\_}Core},
  pages         = {230--248},
  publisher     = {Springer International Publishing},
  title         = {{Simplifying Communication Overlap in OpenSHMEM Through Integrated User-Level Thread Scheduling}},
  volume        = {1},
  year          = {2020}
}
@article{Weingram2023,
  author        = {Weingram, Adam and Li, Yuke and Member, Student and Qi, Hao and Ng, Darren and Dai, Liuyao and Lu, Xiaoyi},
  doi           = {10.1007/s11390-023-2894-6},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/Journal of Computer Science and Technology/xCCL A Survey of Industry-Led Collective Communication Libraries for Deep Learning - Weingram et al. - Journal of Computer Science and.pdf:pdf},
  journal       = {Journal of Computer Science and Technology},
  keywords      = {Collectives,MPI,Survey,collective,deep learning,distributed training,gpudirect,rdma,remote direct memory access},
  mendeley-tags = {Collectives,MPI,Survey},
  pages         = {166--195},
  title         = {{xCCL : A Survey of Industry-Led Collective Communication Libraries for Deep Learning}},
  year          = {2023}
}
@inproceedings{Wende2012,
  abstract      = {General-purpose graphics processing units (GPUs) have been found to be viable solutions for large-scale numerical computations with an inherent potential for massive parallelism. In contrast, only few is known about using GPUs for small-scale computations. To have the GPU not be under-utilized for small problem sizes, a meaningful approach is to perform as many small-scale computations as possible in a concurrent manner. On NVIDIA Fermi GPUs, the concept of Concurrent Kernel Execution (CKE) allows for the execution of up to 16 GPU kernels on a single device. While using CKE in single-threaded CUDA programs is straightforward, for multi-threaded programs it might become a challenge to manage multiple host threads interacting with the GPU device, and in addition to have the CKE concept work properly. It can be observed that CKE performance breaks down when multiple host threads each invoke multiple GPU kernels in succession without synchronizing their actions. Since in real-world applications it is common that multiple host threads process their data independently, a mechanism is needed that helps avoiding CKE breakdown. We propose a producer-consumer principle approach to manage GPU kernel invocations from within parallel host regions by reordering the respective GPU kernels before actually invoking them. We are able to demonstrate significant performance improvements with this technique in a strong scaling simulation of a small molecule solvated within a nanodroplet. {\textcopyright} 2012 IEEE.},
  author        = {Wende, Florian and Cordes, Frank and Steinke, Thomas},
  booktitle     = {Symposium on Application Accelerators in High-Performance Computing (SAAHPC)},
  doi           = {10.1109/SAAHPC.2012.12},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2012/Symposium on Application Accelerators in High-Performance Computing (SAAHPC)/On improving the performance of multi-threaded CUDA applications with concurrent kernel execution by kernel reordering - Wende.pdf:pdf},
  isbn          = {9780769548388},
  issn          = {21665133},
  keywords      = {CUDA,Concurrent kernel execution,GP-GPU,GPU,Multi-threaded applications,Multithread},
  mendeley-tags = {CUDA,GPU,Multithread},
  pages         = {74--83},
  publisher     = {IEEE},
  title         = {{On improving the performance of multi-threaded CUDA applications with concurrent kernel execution by kernel reordering}},
  year          = {2012}
}
@techreport{Wende2014,
  abstract      = {Small-scale computations usually cannot fully utilize the com- pute capabilities of modern GPGPUs.With the Fermi GPU architecture Nvidia introduced the concurrent kernel execution feature allowing up to 16 GPU kernels to execute simultaneously on a shared GPU device for a better utilization of the respective resources. Insufficient scheduling ca- pabilities in this respect, however, can significantly reduce the theoretical concurrency level. With the Kepler GPU architecture Nvidia addresses this issue by introducing the Hyper-Q feature with 32 hardware managed work queues for concurrent kernel execution. We investigate the Hyper-Q feature within heterogeneous workloads with multiple concurrent host threads or processes offloading computations to the GPU each. By means of a synthetic benchmark kernel and a hybrid parallel CPU-GPU real-world application, we evaluate the performance obtained with Hyper-Q on GPU and compare it against a kernel reorder- ing mechanism introduced by the authors for the Fermi architecture. 1},
  author        = {Wende, Florian and Steinke, Thomas and Cordes, Frank},
  booktitle     = {ZIB-Rep},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/ZIB-Rep/Multi-threaded Kernel Offloading to GPGPU Using Hyper-Q on Kepler Architecture - Wende, Steinke, Cordes - ZIB-Rep.pdf:pdf},
  keywords      = {CUDA,GPU,Hyper{\_}Q,Multithread},
  mendeley-tags = {CUDA,GPU,Hyper{\_}Q,Multithread},
  number        = {June},
  title         = {{Multi-threaded Kernel Offloading to GPGPU Using Hyper-Q on Kepler Architecture}},
  volume        = {19},
  year          = {2014}
}
@article{Widener2016,
  abstract      = {Relaxed synchronization offers the potential for maintaining application scalability, by allowing many processes to make independent progress when some processes suffer delays. Yet the benefits of this approach for important parallel workloads have not been investigated in detail. In this paper, we use a validated simulation approach to explore the noise-mitigation effects of idealized nonblocking collectives, in workloads where these collectives are a major contributor to total execution time. Although nonblocking collectives are unlikely to provide significant noise mitigation to applications in the low operating system noise environments expected in next-generation high-performance computing systems, we show that they can potentially improve application runtime with respect to other noise types.},
  author        = {Widener, Patrick M. and Levy, Scott and Ferreira, Kurt B. and Hoefler, Torsten},
  doi           = {10.1177/1094342015611952},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/The International Journal of High Performance Computing Applications/On noise and the performance benefit of nonblocking collectives - Widener et al. - The International Journal of High Performance Compu.pdf:pdf},
  issn          = {17412846},
  journal       = {The International Journal of High Performance Computing Applications},
  keywords      = {Checkpoint,Collectives,HPC,MPI,checkpointing,collectives,nonblocking,resilience,simulation},
  mendeley-tags = {Checkpoint,Collectives,MPI},
  number        = {1},
  pages         = {121--133},
  title         = {{On noise and the performance benefit of nonblocking collectives}},
  volume        = {30},
  year          = {2016}
}
@inproceedings{Wilkins2022,
  abstract        = {MPI collective communication is an omnipresent communication model for high-performance computing (HPC) systems. The performance of a collective operation depends strongly on the algorithm used to implement it. MPI libraries use inaccurate heuristics to select these algorithms, causing applications to suffer unnecessary slowdowns. Machine learning (ML)-based autotuners are a promising alternative. ML autotuners can intelligently select algorithms for individual jobs, resulting in near-optimal performance. However, these approaches currently spend more time training than they save by accelerating applications, rendering them impractical. We make the case that ML-based collective algorithm selection autotuners can be made practical and accelerate production applications on large-scale supercomputers. We identify multiple impracticalities in the existing work, such as inefficient training point selection and ignoring non-power-of-two feature values. We address these issues through variance-based point selection and model testing alongside topology-aware benchmark paral-lelization. Our approach minimizes training time by eliminating unnecessary training points and maximizing machine utilization. We incorporate our improvements in a prototype active learning system, ACCLAiM (Advancing Collective Communication (L) Autotuning using Machine Learning). We show that each of ACCLAiM's advancements significantly reduces training time compared with the best existing machine learning approach. Then we apply ACCLAiM on a leadership-class supercomputer and demonstrate the conditions where ACCLAiM can accelerate HPC applications, proving the advantage of ML autotuners in a production setting for the first time.},
  author          = {Wilkins, Michael and Guo, Yanfei and Thakur, Rajeev and Dinda, Peter and Hardavellas, Nikos},
  booktitle       = {Proceedings of IEEE International Conference on Cluster Computing, CLUSTER},
  doi             = {10.1109/CLUSTER51413.2022.00030},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of IEEE International Conference on Cluster Computing, CLUSTER/ACCLAiM Advancing the Practicality of MPI Collective Communication Autotuning Using Machine Learning - Wilkins et al. - Proceedi.pdf:pdf},
  isbn            = {9781665498562},
  issn            = {15525244},
  keywords        = {Auto{\_}Tune,Collectives,MPI,autotuning machine learning,collective communication},
  mendeley-groups = {Auto-Tuning},
  mendeley-tags   = {Auto{\_}Tune,Collectives,MPI},
  pages           = {161--171},
  title           = {{ACCLAiM: Advancing the Practicality of MPI Collective Communication Autotuning Using Machine Learning}},
  year            = {2022}
}
@inproceedings{Wilkins2021,
  abstract        = {According to recent performance analyses, MPI collective operations make up a quarter of the execution time on production systems. Machine learning (ML) autotuners use supervised learning to select collective algorithms, significantly improving collective performance. However, we observe two barriers preventing their adoption over the default heuristic-based autotuners. First, a user may find it difficult to compare autotuners because we lack a methodology to quantify their performance. We call this the performance quantification challenge. Second, to obtain the advertised performance, ML model training requires benchmark data from a vast majority of the feature space. Collecting such data regularly on large scale systems consumes far too much time and resources, and this will only get worse with exascale systems. We refer to this as the training data collection challenge. To address these challenges, we contribute (1) a performance evaluation framework to compare and improve collective au-Totuner designs and (2) the Feature scaling, Active learning, Converge, Tune hyperparameters (FACT) approach, a three-part methodology to minimize the training data collection time (and thus maximize practicality at larger scale) without sacrificing accuracy. In the methodology, we first preprocess feature and output values based on domain knowledge. Then, we use active learning to iteratively collect only necessary training data points. Lastly, we perform hyperparameter tuning to further improve model accuracy without any additional data. On a production scale system, our methodology produces a model of equal accuracy using 6.88x less training data collection time.},
  author          = {Wilkins, Michael and Guo, Yanfei and Thakur, Rajeev and Hardavellas, Nikos and Dinda, Peter and Si, Min},
  booktitle       = {Proceedings of the International Workshop on Exascale MPI (ExaMPI)},
  doi             = {10.1109/ExaMPI54564.2021.00010},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the International Workshop on Exascale MPI (ExaMPI)/A FACT-based Approach Making Machine Learning Collective Autotuning Feasible on Exascale Systems - Wilkins et al. - Proceedings of the I.pdf:pdf},
  isbn            = {9781665411080},
  keywords        = {Auto{\_}Tune,Collectives,MPI,collective communication,machine learning},
  mendeley-groups = {Auto-Tuning},
  mendeley-tags   = {Auto{\_}Tune,Collectives,MPI},
  pages           = {36--45},
  publisher       = {Institute of Electrical and Electronics Engineers Inc.},
  title           = {{A FACT-based Approach: Making Machine Learning Collective Autotuning Feasible on Exascale Systems}},
  year            = {2021}
}
@article{Witte2022,
  abstract      = {Solving partial differential equations with deep learning makes it possible to reduce simulation times by multiple orders of magnitude and unlock scientific methods that typically rely on large numbers of sequential simulations, such as optimization and uncertainty quantification. Two of the largest challenges of adopting scientific AI for industrial problem settings is that training datasets must be simulated in advance and that neural networks for solving large-scale PDEs exceed the memory capabilities of current GPUs. We introduce a distributed programming API in the Julia language for simulating training data in parallel on the cloud and without requiring users to manage the underlying HPC infrastructure. In addition, we show that model-parallel deep learning based on domain decomposition allows us to scale neural networks for solving PDEs to commercial-scale problem settings and achieve above 90{\%} parallel efficiency. Combining our cloud API for training data generation and model-parallel deep learning, we train large-scale neural networks for solving the 3D Navier-Stokes equation and simulating 3D CO2 flow in porous media. For the CO2 example, we simulate a training dataset based on a commercial carbon capture and storage (CCS) project and train a neural network for CO2 flow simulation on a 3D grid with over 2 million cells that is 5 orders of magnitudes faster than a conventional numerical simulator and 3,200 times cheaper.},
  archiveprefix = {arXiv},
  arxivid       = {2211.12709},
  author        = {Witte, Philipp A. and Hewett, Russell J. and Saurabh, Kumar and Sojoodi, AmirHossein and Chandra, Ranveer},
  eprint        = {2211.12709},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/arXiv/SciAI4Industry -- Solving PDEs for industry-scale problems with deep learning - Witte et al. - arXiv.pdf:pdf},
  journal       = {arXiv},
  keywords      = {Deep{\_}Learning},
  mendeley-tags = {Deep{\_}Learning},
  pages         = {1--11},
  title         = {{SciAI4Industry -- Solving PDEs for industry-scale problems with deep learning}},
  year          = {2022}
}
@article{Won2023,
  abstract      = {Collective communications are an indispensable part of distributed training. Running a topology-aware collective algorithm is crucial for optimizing communication performance by minimizing congestion. Today such algorithms only exist for a small set of simple topologies, limiting the topologies employed in training clusters and handling irregular topologies due to network failures. In this paper, we propose TACOS, an automated topology-aware collective synthesizer for arbitrary input network topologies. TACOS synthesized 3.73x faster All-Reduce algorithm over baselines, and synthesized collective algorithms for 512-NPU system in just 6.1 minutes.},
  archiveprefix = {arXiv},
  arxivid       = {2304.05301},
  author        = {Won, William and Elavazhagan, Midhilesh and Srinivasan, Sudarshan and Durg, Ajaya and Gupta, Swati and Krishna, Tushar},
  eprint        = {2304.05301},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/arXiv/TACOS Topology-Aware Collective Algorithm Synthesizer for Distributed Training - Won et al. - arXiv.pdf:pdf},
  journal       = {arXiv},
  keywords      = {Collectives,MPI,Topology{\_}Aware},
  mendeley-tags = {Collectives,MPI,Topology{\_}Aware},
  pages         = {1--12},
  title         = {{TACOS: Topology-Aware Collective Algorithm Synthesizer for Distributed Training}},
  url           = {http://arxiv.org/abs/2304.05301},
  year          = {2023}
}
@inproceedings{Wu2021,
  author    = {Wu, Hao and Jin, Jiangming and Zhai, Jidong and Gong, Yifan and Liu, Wei},
  booktitle = {Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)},
  doi       = {10.1109/cluster48925.2021.00029},
  file      = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the IEEE International Conference on Cluster Computing (CLUSTER)/Accelerating GPU Message Communication for Autonomous Navigation Systems - Wu et al. - Proceedings of the IEEE Internationa.pdf:pdf},
  isbn      = {9781728196664},
  pages     = {181--191},
  publisher = {IEEE},
  title     = {{Accelerating GPU Message Communication for Autonomous Navigation Systems}},
  year      = {2021}
}
@article{Wu2005,
  abstract      = {We describe a generic programming model to design collective communications on SMP clusters. The programming model utilizes shared memory for collective communications and overlapping inter-node/intra-node communications, both of which are normally platform specific approaches. Several collective communications are designed based on this model and tested on three SMP clusters of different configurations. The results show that the developed collective communications can, with proper tuning, provide significant performance improvements over existing generic implementations. For example, when broadcasting an 8MB message our implementations outperform the vendor's MPI{\_}Bcast by 35{\%} on an IBM SP system, 51{\%} on a G4 cluster, and 63{\%} on an Intel cluster, the latter two using MPICH's MPI{\_}Bcast. With all-gather operations using 8MB messages, our implementation outperform the vendor's MPI{\_}Allgather by 75{\%} on the IBM SP, 60{\%} on the Intel cluster, and 48{\%} on the G4 cluster. {\textcopyright} 2005 IEEE.},
  author        = {Wu, Meng Shiou and Kendall, Ricky A. and Wright, Kyle},
  doi           = {10.1109/ICPP.2005.56},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2005/Proceedings of the International Conference on Parallel Processing (ICPP)/Optimizing collective communications on SMP clusters - Wu, Kendall, Wright - Proceedings of the International Conference on Paral.pdf:pdf},
  isbn          = {0769523803},
  issn          = {01903918},
  journal       = {Proceedings of the International Conference on Parallel Processing (ICPP)},
  keywords      = {Collectives,MPI},
  mendeley-tags = {Collectives,MPI},
  pages         = {399--407},
  title         = {{Optimizing collective communications on SMP clusters}},
  volume        = {2005},
  year          = {2005}
}
@inproceedings{Wu2016,
  abstract        = {Due to better parallel density and power efficiency, GPUs have become more popular for use in scientific applications. Many of these applications are based on the ubiquitous Message Passing Interface (MPI) programming paradigm, and take advantage of non-contiguous memory layouts to exchange data between processes. However, support for efficient non-contiguous data movements for GPU-resident data is still in its infancy, imposing a negative impact on the over-all application performance. To address this shortcoming, we present a solution where we take advantage of the inherent parallelism in the datatype packing and unpacking operations. We developed a close integration between Open MPI's stack-based datatype engine, NVIDIA's Unified Memory Architecture and GPUDirect capabilities. In this design the datatype packing and unpacking operations are offloaded onto the GPU and handled by specialized GPU kernels, while the CPU remains the driver for data movements between nodes. By incorporating our design into the Open MPI library we have shown significantly better performance for non-contiguous GPU-resident data transfers on both shared and distributed memory machines.},
  author          = {Wu, Wei and Bosilca, George and VandeVaart, Rolf and Jeaugey, Sylvain and Dongarra, Jack},
  booktitle       = {Proceedings of the ACM International Symposium on High-Performance Parallel and Distributed Computing (HPDC)},
  doi             = {10.1145/2907294.2907317},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2016/Proceedings of the ACM International Symposium on High-Performance Parallel and Distributed Computing (HPDC)/GPU-aware non-contiguous data movement in open MPI - Wu et al. - Proceedings of the ACM Intern.pdf:pdf},
  isbn            = {9781450343145},
  keywords        = {Datatype,GPU,Hybrid architecture,MPI,Non-contiguous data},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Datatype,GPU,MPI},
  pages           = {231--242},
  title           = {{GPU-aware non-contiguous data movement in open MPI}},
  year            = {2016}
}
@phdthesis{Xu2022,
  author          = {Xu, Wenjing},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Unknown/Parallel Computing Framework and GPU Performance Modeling - Xu - Unknown.pdf:pdf},
  keywords        = {GPU,Modeling,Thesis},
  mendeley-groups = {Theses},
  mendeley-tags   = {GPU,Modeling,Thesis},
  pages           = {1--123},
  school          = {Lousiana Tech University},
  title           = {{Parallel Computing Framework and GPU Performance Modeling}},
  year            = {2022}
}
@inproceedings{Yang2023,
  author        = {Yang, Zhenhua and Pan, Qingfeng and Xu, Chen},
  booktitle     = {Proceedings of Database Systems for Advanced Applications},
  doi           = {10.1007/978-3-031-30637-2},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/Proceedings of Database Systems for Advanced Applications/Fine-Grained Tuple Transfer for Pipelined Query Execution on CPU-GPU Coprocessor - Yang, Pan, Xu - Proceedings of Database Systems for A.pdf:pdf},
  isbn          = {9783031306372},
  keywords      = {GPU,GPU Database,Pipelined Execution,Tuple Transfer,gpu database},
  mendeley-tags = {GPU},
  pages         = {1--16},
  publisher     = {Springer Nature Switzerland},
  title         = {{Fine-Grained Tuple Transfer for Pipelined Query Execution on CPU-GPU Coprocessor}},
  url           = {http://dx.doi.org/10.1007/978-3-031-30637-2{\_}2},
  year          = {2023}
}
@phdthesis{YehiaArafa2021,
  author          = {{Yehia Arafa}},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Unknown/Performance Modeling and Prediction of Contemporary GPU Architectures - Yehia Arafa - Unknown.pdf:pdf},
  keywords        = {GPU,Modeling,Thesis},
  mendeley-groups = {MustKnow,Theses},
  mendeley-tags   = {GPU,Modeling,Thesis},
  pages           = {1--133},
  school          = {New Mexico State University},
  title           = {{Performance Modeling and Prediction of Contemporary GPU Architectures}},
  year            = {2021}
}
@inproceedings{Young2018,
  abstract        = {Historically, improvement in GPU performance has been tightly coupled with transistor scaling. As Moore's Law slows down, performance of single GPUs may ultimately plateau. To continue GPU performance scaling, multiple GPUs can be connected using system-level interconnects. However, limited inter-GPU interconnect bandwidth (e.g., 64GB/s) can hurt multi-GPU performance when there are frequent remote GPU memory accesses. Traditional GPUs rely on page migration to service the memory accesses from local memory instead. Page migration fails when the page is simultaneously shared between multiple GPUs in the system. As such, recent proposals enhance the software runtime system to replicate read-only shared pages in local memory. Unfortunately, such practice fails when there are frequent remote memory accesses to read-write shared pages. To address this problem, recent proposals cache remote shared data in the GPU last-level-cache (LLC). Unfortunately, remote data caching also fails when the shared-data working-set exceeds the available GPU LLC size. This paper conducts a combined performance analysis of state-of-The-Art software and hardware mechanisms to improve NUMA performance of multi-GPU systems. Our evaluations on a 4-node multi-GPU system reveal that the combination of work scheduling, page placement, page migration, page replication, and caching remote data still incurs a 47{\%} slowdown relative to an ideal NUMA-GPU system. This is because the shared memory footprint tends to be significantly larger than the GPU LLC size and can not be replicated by software because the shared footprint has read-write property. Thus, we show that existing NUMA-Aware software solutions require hardware support to address the NUMA bandwidth bottleneck. We propose Caching Remote Data in Video Memory (CARVE), a hardware mechanism that stores recently accessed remote shared data in a dedicated region of the GPU memory. CARVE outperforms state-of-The-Art NUMA mechanisms and is within 6{\%} the performance of an ideal NUMA-GPU system. A design space analysis on supporting cache coherence is also investigated. Overall, we show that dedicating only 3{\%} of GPU memory eliminates NUMA bandwidth bottlenecks while incurring negligible performance overheads due to the reduced GPU memory capacity.},
  author          = {Young, Vinson and Jaleel, Aamer and Bolotin, Evgeny and Ebrahimi, Eiman and Nellans, David and Villa, Oreste},
  booktitle       = {Proceedings of the International Symposium on Microarchitecture (MICRO)},
  doi             = {10.1109/MICRO.2018.00035},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2018/Proceedings of the International Symposium on Microarchitecture (MICRO)/Combining hwsw mechanisms to improve numa performance of multi-GPU systems - Young et al. - Proceedings of the International Sympos.pdf:pdf},
  isbn            = {9781538662403},
  issn            = {10724451},
  keywords        = {Coherence,DRAM-Cache,GPU,HBM,Memory,Multi-GPU,Multi{\_}GPU,NUMA,Page-Migration,Page-Replication},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,Multi{\_}GPU,NUMA},
  pages           = {339--351},
  publisher       = {IEEE},
  title           = {{Combining hw/sw mechanisms to improve numa performance of multi-GPU systems}},
  year            = {2018}
}
@article{Younge2017,
  abstract        = {Containerization, or OS-level virtualization has taken root within the computing industry. However, container utilization and its impact on performance and functionality within High Performance Computing (HPC) is still relatively undefined. This paper investigates the use of containers with advanced supercomputing and HPC system software. With this, we define a model for parallel MPI application DevOps and deployment using containers to enhance development effort and provide container portability from laptop to clouds or supercomputers. In this endeavor, we extend the use of Sin- gularity containers to a Cray XC-series supercomputer. We use the HPCG and IMB benchmarks to investigate potential points of overhead and scalability with containers on a Cray XC30 testbed system. Furthermore, we also deploy the same containers with Docker on Amazon's Elastic Compute Cloud (EC2), and compare against our Cray supercomputer testbed. Our results indicate that Singularity containers operate at native performance when dynamically linking Cray's MPI libraries on a Cray supercomputer testbed, and that while Amazon EC2 may be useful for initial DevOps and testing, scaling HPC applications better fits supercomputing resources like a Cray.},
  author          = {Younge, Andrew J. and Pedretti, Kevin and Grant, Ryan E. and Brightwell, Ron},
  doi             = {10.1109/CloudCom.2017.40},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2017/Proceedings of the International Conference on Cloud Computing Technology and Science, CloudCom/A Tale of Two Systems Using Containers to Deploy HPC Applications on Supercomputers and Clouds - Younge et.pdf:pdf},
  isbn            = {9781538606926},
  issn            = {23302186},
  journal         = {Proceedings of the International Conference on Cloud Computing Technology and Science, CloudCom},
  keywords        = {Cloud computing,Clouds,Containers,Devops,Docker,Ec2,High performance computing,Hpc,Kvm,Singularity,Virtual cluster,Virtualization},
  mendeley-groups = {ELEC-878},
  pages           = {74--81},
  title           = {{A Tale of Two Systems: Using Containers to Deploy HPC Applications on Supercomputers and Clouds}},
  volume          = {2017-Decem},
  year            = {2017}
}
@article{Yu2020,
  abstract      = {Heterogeneous computing is increasingly being used in a diversity of computing systems, ranging from HPC to the real-time embedded domain, to cope with the performance requirements. Due to the variety of accelerators, e.g., FPGAs, GPUs, the use of high-level parallel programming models is desirable to exploit the performance capabilities of them, while maintaining an adequate productivity level. In that regard, OpenMP is a well-known high-level programming model that incorporates powerful task and accelerator models capable of efficiently exploiting structured and unstructured parallelism in heterogeneous computing. This paper presents a novel compiler transformation technique that automatically transforms OpenMP code into CUDA graphs, combining the benefits of programmability of a high-level programming model such as OpenMP, with the performance benefits of a low-level programming model such as CUDA. Evaluations have been performed on two NVIDIA GPUs from the HPC and embedded domains, i.e., the V100 and the Jetson AGX respectively.},
  author        = {Yu, Chenle and Royuela, Sara and Qui{\~{n}}ones, Eduardo},
  doi           = {10.1145/3378678.3391881},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the International Workshop on Software and Compilers for Embedded Systems (SCOPES)/OpenMP to CUDA graphs A compiler-based transformation to enhance the programmability of NVIDIA devices -.pdf:pdf},
  isbn          = {9781450371315},
  journal       = {Proceedings of the International Workshop on Software and Compilers for Embedded Systems (SCOPES)},
  keywords      = {CUDA graphs,CUDAGraph,Compiler,GPU,OpenMP,compiler optimization,programmability},
  mendeley-tags = {CUDAGraph,Compiler,GPU,OpenMP},
  number        = {1},
  pages         = {42--47},
  title         = {{OpenMP to CUDA graphs: A compiler-based transformation to enhance the programmability of NVIDIA devices}},
  year          = {2020}
}
@inproceedings{Zahran2021,
  author        = {Zahran, Mohamed},
  booktitle     = {Proceedings of the International Computer Engineering Conference (ICENCO)},
  doi           = {10.1109/ICENCO49852.2021.9698918},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the International Computer Engineering Conference (ICENCO)/The Future of High-Performance Computing - Zahran - Proceedings of the International Computer Engineering Conference (ICENCO).pdf:pdf},
  isbn          = {9781728164489},
  keywords      = {CUDA,Exascale,GPU,Survey,heterogeneous computing,high-performance computing,parallel programming,specialized chips},
  mendeley-tags = {CUDA,Exascale,GPU,Survey},
  pages         = {1--6},
  publisher     = {IEEE},
  title         = {{The Future of High-Performance Computing}},
  year          = {2021}
}
@inproceedings{Zambre2022,
  abstract        = {Hybrid MPI+threads programming is gaining prominence, but, in practice, applications perform slower with it compared to the MPI everywhere model. The most critical challenge to the parallel efficiency of MPI+threads applications is slow MPI{\_}THREAD{\_}MULTIPLE performance. MPI libraries have recently made significant strides on this front, but to exploit their capabilities, users must expose the communication parallelism in their MPI+threads applications. Recent studies show that MPI 4.0 provides users with new performance-oriented options to do so, but our evaluation of these new mechanisms shows that they pose several challenges. An alternative design is MPI Endpoints. In this paper, we present a comparison of the different designs from the perspective of MPI's end-users: domain scientists and application developers. We evaluate the mechanisms on metrics beyond performance such as usability, scope, and portability. Based on the lessons learned, we make a case for a future direction.},
  archiveprefix   = {arXiv},
  arxivid         = {2206.14285},
  author          = {Zambre, Rohit and Chandramowlishwaran, Aparna},
  booktitle       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  eprint          = {2206.14285},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Lessons Learned on MPIThreads Communication - Zambre, Chandramowlishwaran - Proceedings o.pdf:pdf},
  isbn            = {9781665454445},
  keywords        = {Index Terms-exascale MPI,MPI,MPI Endpoints,MPI THREAD MULTIPLE,MPI+OpenMP,MPI+threads,Multithreaded{\_}MPI,network parallelism,partitioned commu-nication},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {MPI,Multithreaded{\_}MPI},
  pages           = {1--16},
  title           = {{Lessons Learned on MPI+Threads Communication}},
  url             = {https://arxiv.org/abs/2206.14285v1},
  year            = {2022}
}
@inproceedings{Gniadecki2020,
  author        = {Zambre, Rohit and Chandramowliswharan, Aparna and Balaji, Pavan},
  booktitle     = {Proceedings of the International Conference on Supercomputing (ICS)},
  doi           = {10.1145/3392717.3392773},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the International Conference on Supercomputing (ICS)/How I learned to stop worrying about user-visible endpoints and love MPI - Zambre, Chandramowliswharan, Balaji - Proceedings of the Int.pdf:pdf},
  keywords      = {MPI,MPI Endpoints,MPI+OpenMP,MPI+threads,MPI{\_}THREAD{\_}MULTIPLE,Multithreaded{\_}MPI,acm reference format,exascale,exascale MPI,high-performance communication,mpi,mpi endpoints,mpi{\_}thread{\_}multiple,openmp,threads},
  mendeley-tags = {MPI,Multithreaded{\_}MPI},
  pages         = {1--13},
  title         = {{How I learned to stop worrying about user-visible endpoints and love MPI}},
  year          = {2020}
}
@article{Zambre2021,
  abstract      = {Supercomputing applications are increasingly adopting the MPI+threads programming model over the traditional MPI everywhere approach to better handle the disproportionate increase in the number of cores compared with other on-node resources. In practice, however, most applications observe a slower performance with MPI+threads primarily because of poor communication performance. Recent research efforts on MPI libraries address this bottleneck by mapping logically parallel communication, that is, operations that are not subject to MPI{\&}{\#}x0027;s ordering constraints to the underlying network parallelism. Domain scientists, however, typically do not expose such communication independence information because the existing MPI-3.1 standard{\&}{\#}x0027;s semantics can be limiting. Researchers had initially proposed user-visible endpoints to combat this issue, but such a solution requires intrusive changes to the standard (new APIs). The upcoming MPI-4.0 standard, on the other hand, allows applications to relax unneeded semantics and provides them with many opportunities to express logical communication parallelism. In this paper, we show how MPI+threads applications can achieve high performance with logically parallel communication. Through application case studies, we compare the capabilities of the new MPI-4.0 standard with those of the existing one and user-visible endpoints (upper bound). Logical communication parallelism can boost the overall performance of an application by over 2x.},
  author        = {Zambre, Rohit and Sahasrabudhe, Damodar and Zhou, Hui and Berzins, Martin and Chandramowlishwaran, Aparna and Balaji, Pavan},
  doi           = {10.1109/TPDS.2021.3075157},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/IEEE Transactions on Parallel and Distributed Systems/Logically Parallel Communication for Fast MPIThreads Applications - Zambre et al. - IEEE Transactions on Parallel and Distributed System.pdf:pdf},
  journal       = {IEEE Transactions on Parallel and Distributed Systems},
  keywords      = {Boilers,Legion,Libraries,MPI Endpoints,MPI THREAD MULTIPLE,MPI+OpenMP,MPI+threads,Multithread,Multithreaded{\_}MPI,Parallel processing,Programming,Semantics,Standards,Uintah,Upper bound,Wombat,exascale MPI,hypre},
  mendeley-tags = {Multithread,Multithreaded{\_}MPI},
  title         = {{Logically Parallel Communication for Fast MPI+Threads Applications}},
  year          = {2021}
}
@article{Zhang2021,
  abstract      = {PetscSF, the communication component of the Portable, Extensible Toolkit for Scientific Computation (PETSc), is designed to provide PETScs communication infrastructure suitable for exascale computers that utilize GPUs and other accelerators. PetscSF provides a simple application programming interface (API) for managing common communication patterns in scientific computations by using a star-forest graph representation. PetscSF supports several implementations based on MPI and NVSHMEM, whose selection is based on the characteristics of the application or the target architecture. An efficient and portable model for network and intra-node communication is essential for implementing large-scale applications. The Message Passing Interface, which has been the de facto standard for distributed memory systems, has developed into a large complex API that does not yet provide high performance on the emerging heterogeneous CPU-GPU-based exascale systems. In this paper, we discuss the design of PetscSF, how it can overcome some difficulties of working directly with MPI on GPUs, and we demonstrate its performance, scalability, and novel features.},
  author        = {Zhang, Junchao and Brown, Jed and Balay, Satish and Faibussowitsch, Jacob and Knepley, Matthew and Marin, Oana and Mills, Richard Tran and Munson, Todd and Smith, Barry F. and Zampini, Stefano},
  doi           = {10.1109/TPDS.2021.3084070},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/IEEE Transactions on Parallel and Distributed Systems/The PetscSF Scalable Communication Layer - Zhang et al. - IEEE Transactions on Parallel and Distributed Systems.pdf:pdf},
  issn          = {15582183},
  journal       = {IEEE Transactions on Parallel and Distributed Systems},
  keywords      = {Arrays,Communication,Electronics packaging,Forestry,GPU,Graphics processing units,Libraries,MPI,PETSc,Programming,Scalability,extreme-scale},
  mendeley-tags = {GPU,MPI},
  pages         = {1--12},
  title         = {{The PetscSF Scalable Communication Layer}},
  year          = {2021}
}
@article{Zhang2023,
  abstract      = {Communication scheduling has been shown to be effective in accelerating distributed training, which enables all-reduce communications to be overlapped with backpropagation computations. This has been commonly adopted in popular distributed deep learning frameworks. However, there exist two fundamental problems: (1) excessive startup latency proportional to the number of workers for each all-reduce operation; (2) it only achieves sub-optimal training performance due to the dependency and synchronization requirement of the feed-forward computation in the next iteration. We propose a novel scheduling algorithm, DeAR, that decouples the all-reduce primitive into two continuous operations, which overlaps with both backpropagation and feed-forward computations without extra communications. We further design a practical tensor fusion algorithm to improve the training performance. Experimental results with five popular models show that DeAR achieves up to 83{\%} and 15{\%} training speedup over the state-of-the-art solutions on a 64-GPU cluster with 10Gb/s Ethernet and 100Gb/s InfiniBand interconnects, respectively.},
  archiveprefix = {arXiv},
  arxivid       = {2302.12445},
  author        = {Zhang, Lin and Shi, Shaohuai and Chu, Xiaowen and Wang, Wei and Li, Bo and Liu, Chengjian},
  eprint        = {2302.12445},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/arXiv/Decoupling the All-Reduce Primitive for Accelerating Distributed Deep Learning - Zhang et al. - arXiv.pdf:pdf},
  journal       = {arXiv},
  keywords      = {Collectives,Deep{\_}Learning,MPI},
  mendeley-tags = {Collectives,Deep{\_}Learning,MPI},
  pages         = {1--12},
  title         = {{Decoupling the All-Reduce Primitive for Accelerating Distributed Deep Learning}},
  url           = {http://arxiv.org/abs/2302.12445},
  year          = {2023}
}
@inproceedings{Zhang2020,
  abstract        = {GPUs are playing an increasingly important role in general-purpose computing. Many algorithms require synchronizations at different levels of granularity in a single GPU. Additionally, the emergence of dense GPU nodes also calls for multi-GPU synchronization. Nvidia's latest CUDA provides a variety of synchronization methods. Until now, there is no full understanding of the characteristics of those synchronization methods. This work explores important undocumented features and provides an in-depth analysis of the performance considerations and pitfalls of the state-of-art synchronization methods for Nvidia GPUs. The provided analysis would be useful when making design choices for applications, libraries, and frameworks running on single and/or multi-GPU environments. We provide a case study of the commonly used reduction operator to illustrate how the knowledge gained in our analysis can be useful. We also describe our micro-benchmarks and measurement methods.},
  author          = {Zhang, Lingqi and Wahib, Mohamed and Zhang, Haoyu and Matsuoka, Satoshi},
  booktitle       = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi             = {10.1109/IPDPS47924.2020.00057},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/A Study of Single and Multi-device Synchronization Methods in Nvidia GPUs - Zhang et al. - Proceedings of the I.pdf:pdf},
  isbn            = {9781728168760},
  keywords        = {CUDA Barrier,GPU,GPUs,Multi{\_}GPU,Synchronization},
  mendeley-groups = {MustKnow,UsedInComp2},
  mendeley-tags   = {GPU,Multi{\_}GPU},
  pages           = {483--493},
  title           = {{A Study of Single and Multi-device Synchronization Methods in Nvidia GPUs}},
  year            = {2020}
}
@article{Zhao2021,
  abstract        = {The ability to support multitasking becomes more and more important in the development of graphic processing unit (GPU). GPU multitasking methods are classified into three types: temporal multitasking, spatial multitasking, and simultaneous multitasking (SMK). This paper first introduces the features of some commercial GPU architectures to support multitasking and the common metrics used for evaluating the performance of GPU multitasking methods, and then reviews the GPU multitasking methods supported by hardware architecture (i.e., hardware GPU multitasking methods). The main problems of each type of hardware GPU multitasking methods to be solved are illustrated. Meanwhile, the key idea of each previous hardware GPU multitasking method is introduced. In addition, the characteristics of hardware GPU multitasking methods belonging to the same type are compared. This paper also gives some valuable suggestions for the future research. An enhanced GPU simulator is needed to bridge the gap between academia and industry. In addition, it is promising to expand the research space with machine learning technologies, advanced GPU architectural innovations, 3D stacked memory, etc. Because most previous GPU multitasking methods are based on NVIDIA GPUs, this paper focuses on NVIDIA GPU architecture, and uses NVIDIAs terminology. To our knowledge, this paper is the first survey about hardware GPU multitasking methods. We believe that our survey can help the readers gain insights into the research field of hardware GPU multitasking methods.},
  author          = {Zhao, Chen and Gao, Wu and Nie, Feiping and Zhou, Huiyang},
  doi             = {10.1109/TPDS.2021.3115630},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/IEEE Transactions on Parallel and Distributed Systems/A Survey of GPU Multitasking Methods Supported by Hardware Architecture - Zhao et al. - IEEE Transactions on Parallel and Distributed Sy.pdf:pdf},
  issn            = {15582183},
  journal         = {IEEE Transactions on Parallel and Distributed Systems},
  keywords        = {Computer architecture,GPU,GPU multitasking,Graphics processing units,Hardware,Kernel,Multitasking,Registers,Survey,Task analysis,hardware architecture,simultaneous multitasking (SMK),spatial multitasking,survey,temporal multitasking},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,Survey},
  pages           = {1451--1463},
  title           = {{A Survey of GPU Multitasking Methods Supported by Hardware Architecture}},
  year            = {2021}
}
@inproceedings{Zhao2020,
  abstract        = {Communication plays an important role in MPI applications, and reduce operations are heavily used part of MPI. In this paper, we propose a k-nomial tree topology and a hierarchy tree topology to optimize the Reduce operation in MPI. The k-nomial tree can effectively decrease the communication steps and is suitable for lots of processes. Compared with the binomial tree algorithm in small and medium size messages, the Reduce operation performed by the k-nomial tree can improve communication performance by 46{\%}. Hierarchy trees can dynamically group processes at run time to take advantage of high bandwidth to communicate as much as possible within nodes. The test results show that compared with the binomial tree algorithm, the performance of the hierarchy tree algorithm is stable. For Reduce operation, we can get a 30{\%} performance improvement.},
  author          = {Zhao, Tianhai and Wang, Yunlan and Wang, Xu},
  booktitle       = {Proceedings of the High Performance Computing and Cluster Technologies Conference (HPCCT)},
  doi             = {10.1145/3409501.3409510},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2020/Proceedings of the High Performance Computing and Cluster Technologies Conference (HPCCT)/Optimized Reduce Communication Performance with the Tree Topology - Zhao, Wang, Wang - Proceedings of the High Pe.pdf:pdf},
  isbn            = {9781450375603},
  issn            = {21531633},
  keywords        = {Collectives,MPI,MPI{\_}Reduce,hierarchy,k-nomial,optimization,tree topology},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Collectives,MPI},
  pages           = {165--171},
  title           = {{Optimized Reduce Communication Performance with the Tree Topology}},
  year            = {2020}
}
@inproceedings{Zhao2023,
  author        = {Zhao, Yuxuan and Sun, Qi and He, Zhuolun},
  booktitle     = {Associatoin for the Advancement of Artificial Intelligence (AAAI)},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2023/Associatoin for the Advancement of Artificial Intelligence (AAAI)/AutoGraph Optimizing DNN Computation Graph for Parallel GPU Kernel Execution - Zhao, Sun, He - Associatoin for the Advancement of Artif.pdf:pdf},
  keywords      = {CUDA{\_}Graphs,GPU},
  mendeley-tags = {CUDA{\_}Graphs,GPU},
  pages         = {1--9},
  title         = {{AutoGraph : Optimizing DNN Computation Graph for Parallel GPU Kernel Execution}},
  year          = {2023}
}
@inproceedings{Zheng2019,
  abstract        = {MPI libraries are widely used in applications of high performance computing. Yet, effective tuning of MPI colletives on large parallel systems is an outstanding challenge. This process often follows a trial-and-error approach and requires expert insights into the subtle interactions between software and the underlying hardware. This paper presents an empirical approach to choose and switch MPI communication algorithms at runtime to optimize the application performance. We achieve this by first modeling offline, through microbenchmarks, to find how the runtime parameters with different message sizes affect the choice of MPI communication algorithms. We then apply the knowledge to automatically optimize new unseen MPI programs. We evaluate our approach by applying it to NPB and HPCC benchmarks on a 384-node computer cluster of the Tianhe-2 supercomputer. Experimental results show that our approach achieves, on average, 22.7{\%} (up to 40.7{\%}) improvement over the default setting.},
  author          = {Zheng, Wenxu and Fang, Jianbin and Juan, Chen and Wu, Feihao and Pan, Xiaodong and Wang, Hao and Sun, Xiaole and Yuan, Yuan and Xie, Min and Huang, Chun and Tang, Tao and Wang, Zheng},
  booktitle       = {Proceedings of the IEEE International Conference on High Performance Computing and Communications (HPCC)},
  doi             = {10.1109/HPCC/SmartCity/DSS.2019.00101},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the IEEE International Conference on High Performance Computing and Communications (HPCC)/Auto-tuning MPI collective operations on large-scale parallel systems - Zheng et al. - Proceedings.pdf:pdf},
  isbn            = {9781728120584},
  keywords        = {Auto{\_}Tune,Collectives,MPI,auto-tuning,collective communication},
  mendeley-groups = {UsedInComp2},
  mendeley-tags   = {Auto{\_}Tune,Collectives,MPI},
  pages           = {670--677},
  publisher       = {IEEE},
  title           = {{Auto-tuning MPI collective operations on large-scale parallel systems}},
  year            = {2019}
}
@article{Zhong2022,
  abstract      = {The modern CPU's design, including the deep memory hierarchies and SIMD/vectorization capability have a more significant impact on algorithms' efficiency than the modest frequency increase observed recently. The current introduction of wide vector instruction set extensions (AVX and SVE) motivated vectorization to become a critical software component to increase efficiency and close the gap to peak performance. In this paper, we investigate the impact of the vectorization of MPI reduction operations. We propose an implementation of predefined MPI reduction operations using vector intrinsics (AVX and SVE) to improve the time-to-solution of the predefined MPI reduction operations. The evaluation of the resulting software stack under different scenarios demonstrates that the approach is not only efficient but also generalizable to many vector architectures. Experiments conducted on varied architectures (Intel Xeon Gold, AMD Zen 2, and Arm A64FX), show that the proposed vector extension optimized reduction operations significantly reduce completion time for collective communication reductions. With these optimizations, we achieve higher memory bandwidth and an increased efficiency for local computations, which directly benefit the overall cost of collective reductions and applications based on them.},
  author        = {Zhong, Dong and Cao, Qinglei and Bosilca, George and Dongarra, Jack},
  doi           = {10.1016/j.parco.2021.102871},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Parallel Computing/Using long vector extensions for MPI reductions - Zhong et al. - Parallel Computing.pdf:pdf},
  issn          = {01678191},
  journal       = {Parallel Computing},
  keywords      = {Instruction level parallelism,Intel AVX2/AVX-512,Long vector extension,MPI,MPI reduction operation,Scalable Vector Extension (SVE),Single instruction multiple data,Vector,Vector operation,long vector extension},
  mendeley-tags = {MPI,Vector},
  pages         = {1--11},
  title         = {{Using long vector extensions for MPI reductions}},
  url           = {https://doi.org/10.1016/j.parco.2021.102871},
  year          = {2022}
}
@inproceedings{Zhou2019,
  abstract        = {The advent of multi-/many-core processors in clusters advocates hybrid parallel programming, which combines Message Passing Interface (MPI) for inter-node parallelism with a shared memory model for on-node parallelism. Compared to the traditional hybrid approach of MPI plus OpenMP, a new, but promising hybrid approach of MPI plus MPI-3 shared-memory extensions (MPI+MPI) is gaining attraction. We describe an algorithmic approach for collective operations (with allgather and broadcast as concrete examples) in the context of hybrid MPI+MPI, so as to minimize memory consumption and memory copies. With this approach, only one memory copy is maintained and shared by on-node processes. This allows the removal of unnecessary on-node copies of replicated data that are required between MPI processes when the collectives are invoked in the context of pure MPI. We compare our approach of collectives for hybrid MPI+MPI and the traditional one for pure MPI, and also have a discussion on the synchronization that is required to guarantee data integrity. The performance of our approach has been validated on a Cray XC40 system (Cray MPI) and NEC cluster (Open MPI), showing that it achieves comparable or better performance for allgather operations. We have further validated our approach with a standard computational kernel, namely distributed matrix multiplication, and a Bayesian Probabilistic Matrix Factorization code.},
  author          = {Zhou, Huan and Gracia, Jos{\'{e}} and Schneider, Ralf},
  booktitle       = {Proceedings of the International Conference on Parallel Processing (ICPP)},
  doi             = {10.1145/3339186.3339199},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2019/Proceedings of the International Conference on Parallel Processing (ICPP)/MPI collectives for multi-core clusters Optimized performance of the hybrid MPIMPI parallel codes - Zhou, Gracia, Schneider - Pro.pdf:pdf},
  isbn            = {9781450371964},
  keywords        = {Collective communication,Collectives,Hybrid programming,Hybrid{\_}MPI,MPI,MPI shared memory model,Shared{\_}Memory},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {Collectives,Hybrid{\_}MPI,Shared{\_}Memory},
  pages           = {1--10},
  title           = {{MPI collectives for multi-core clusters: Optimized performance of the hybrid MPI+MPI parallel codes}},
  year            = {2019}
}
@inproceedings{Zhou2015,
  abstract      = {The efficiency and scalability of MPI collective operations, in particular the broadcast operation, plays an integral part in high performance computing applications. MPICH, as one of the contemporary widely-used MPI software stacks, implements the broadcast operation based on point-to-point operation. Depending on the parameters, such as message size and process count, the library chooses to use different algorithms, as for instance binomial dissemination, recursive-doubling exchange or ring all-to-all broadcast (all-gather). However, the existing broadcast design in latest release of MPICH does not provide good performance for large messages (lmsg) or medium messages with non-power-of-two process counts (mmsg-npof2) due to the inner suboptimal ring all gather algorithm. In this paper, based on the native broadcast design in MPICH, we propose a tuned broadcast approach with bandwidth-saving in mind catering to the case of lmsg and mmsg-npof2. Several comparisons of the native and tuned broadcast designs are made for different data sizes and program sizes on Cray XC40 cluster. The results show that the performance of the tuned broadcast design can get improved by a range from 2{\%} to 54{\%} for lmsg and mmsg-npof2 in terms of user-level testing.},
  author        = {Zhou, Huan and Marjanovic, Vladimir and Niethammer, Christoph and Gracia, Jose},
  booktitle     = {Proceedings of the International Conference on Parallel Processing Workshops},
  doi           = {10.1109/ICPPW.2015.20},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2015/Proceedings of the International Conference on Parallel Processing Workshops/A Bandwidth-Saving Optimization for MPI Broadcast Collective Operation - Zhou et al. - Proceedings of the International Confer.pdf:pdf},
  isbn          = {9781467375894},
  issn          = {15302016},
  keywords      = {Bandwidth-saving,Broadcast,Collectives,MPI,MPICH},
  mendeley-tags = {Broadcast,Collectives,MPI},
  pages         = {111--118},
  title         = {{A Bandwidth-Saving Optimization for MPI Broadcast Collective Operation}},
  volume        = {2015-Janua},
  year          = {2015}
}
@inproceedings{Zhou2022a,
  abstract        = {The hybrid MPI+X programming paradigm, where X refers to threads or GPUs, has gained prominence in the high-performance computing arena. This corresponds to a trend of system architectures growing more heterogeneous. The current MPI standard only specifies the compatibility levels between MPI and threading runtimes. No MPI concept or interface exists for applications to pass thread context or GPU stream context to MPI implementations explicitly. This lack has made performance optimization complicated in some cases and impossible in other cases. We propose a new concept in MPI, called MPIX stream, to represent the general serial execution context that exists in X runtimes. MPIX streams can be directly mapped to threads or GPU execution streams. Passing thread context into MPI allows implementations to precisely map the execution contexts to network endpoints. Passing GPU execution context into MPI allows implementations to directly operate on GPU streams, lowering the CPU/GPU synchronization cost.},
  author          = {Zhou, Hui and Raffenetti, Ken and Guo, Yanfei and Thakur, Rajeev},
  booktitle       = {Proceedings of the European MPI Users' Group Meeting (EuroMPI)},
  doi             = {10.1145/3555819.3555820},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the European MPI Users' Group Meeting (EuroMPI)/MPIX Stream An Explicit Solution to Hybrid MPIX Programming - Zhou et al. - Proceedings of the European MPI Users' Group Meeting (EuroMP.pdf:pdf},
  isbn            = {9781450397995},
  keywords        = {GPU,GPU Stream,MPI,MPI+GPUs,MPI+Threads,MPI+X,MPIX Stream,Network Endpoints},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {GPU,MPI},
  pages           = {1--10},
  title           = {{MPIX Stream: An Explicit Solution to Hybrid MPI+X Programming}},
  year            = {2022}
}
@inproceedings{Zhou2022,
  author        = {Zhou, Jia and Tu, Jun and Ren, Donglin},
  booktitle     = {Proceedings of the International Conference on Big Data Analytics (ICBDA)},
  doi           = {10.1109/ICBDA55095.2022.9760359},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Proceedings of the International Conference on Big Data Analytics (ICBDA)/An Asynchronous Distributed Training Algorithm Based on Gossip - Zhou, Tu, Ren - Proceedings of the International Conference on B.pdf:pdf},
  isbn          = {9781665479387},
  keywords      = {Deep{\_}Learning,Distributed,Gossip,asynchronous,b ackground and r,distributed decentralization,elated w ork,gossip,ii},
  mendeley-tags = {Deep{\_}Learning,Distributed,Gossip},
  pages         = {1--4},
  publisher     = {IEEE},
  title         = {{An Asynchronous Distributed Training Algorithm Based on Gossip}},
  year          = {2022}
}
@article{Zhou2022b,
  abstract        = {Containers improve the efficiency in application deployment and thus have been widely utilised on Cloud and lately in High Performance Computing (HPC) environments. Containers encapsulate complex programs with their dependencies in isolated environments making applications more compatible and portable. Often HPC systems have higher security levels compared to Cloud systems, which restrict users{\&}{\#}x0027; ability to customise environments. Therefore, containers on HPC need to include a heavy package of libraries making their size relatively large. These libraries usually are specifically optimised for the hardware, which compromises portability of containers. {\textless}italic{\textgreater}Per contra{\textless}/italic{\textgreater}, a Cloud container has smaller volume and is more portable. Furthermore, containers would benefit from orchestrators that facilitate deployment and management of containers at a large scale. Cloud systems in practice usually incorporate sophisticated container orchestration mechanisms as opposed to HPC systems. Nevertheless, some solutions to enable container orchestration on HPC systems have been proposed in state of the art. This paper gives a survey and taxonomy of efforts in both containerisation and its orchestration strategies on HPC systems. It highlights differences thereof between Cloud and HPC. Lastly, challenges are discussed and the potentials for research and engineering are envisioned.},
  author          = {Zhou, Naweiluo and Zhou, Huan and Hoppe, Dennis},
  doi             = {10.1109/TSE.2022.3229221},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/IEEE Transactions on Software Engineering/Containerisation for High Performance Computing Systems Survey and Prospects - Zhou, Zhou, Hoppe - IEEE Transactions on Software Enginee.pdf:pdf},
  issn            = {19393520},
  journal         = {IEEE Transactions on Software Engineering},
  keywords        = {AI,Cloud,Cloud Computing,Cloud computing,Container,Containers,Engines,HPC,Hardware,Job Scheduling,Kernel,Orchestration,Resource Management,Security,Survey,Virtual machine monitors},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Cloud,Containers,Survey},
  pages           = {1--20},
  title           = {{Containerisation for High Performance Computing Systems: Survey and Prospects}},
  year            = {2022}
}
@inproceedings{Zhou2021,
  abstract        = {While the memory bandwidth of accelerators such as GPU has significantly improved over the last decade, the commodity networks such as Ethernet and InfiniBand are lagging in terms of raw throughput creating. Although there are significant research efforts on improving the large message data transfers for GPU-resident data, the inter-node communication remains the major performance bottleneck due to the data explosion created by the emerging High-Performance Computing (HPC) applications. On the other hand, the recent developments in GPU-based compression algorithms exemplify the potential of using high-performance message compression techniques to reduce the volume of data transferred thereby reducing the load on an already overloaded inter-node communication fabric. The existing GPU-based compression schemes are not designed for 'on-the-fly' execution and lead to severe performance degradation when integrated into the communication libraries. In this paper, we take up this challenge and redesign the MVAPICH2 MPI library to enable high-performance, on-the-fly message compression for modern, dense GPU clusters. We also enhance existing implementations of lossless and lossy compression algorithms, MPC and ZFP, to provide high-performance, on-the-fly message compression and decompression. We demonstrate that our proposed designs can offer significant benefits at the microbenchmark and application-levels. The proposed design is able to provide up to 19{\%} and 37{\%} improvement in the GPU computing flops of AWP-ODC with the enhanced MPCOPT and ZFP-OPT schemes, respectively. Moreover, we gain up to 1.56x improvement in Dask throughput. To the best of our knowledge, this is the first work that leverages the GPU-based compression techniques to significantly improve the GPU communication performance for various MPI primitives, MPI-based data science, and HPC applications.},
  author          = {Zhou, Q. and Chu, C. and Kumar, N. S. and Kousha, P. and Ghazimirsaeed, S. M. and Subramoni, H. and Panda, D. K.},
  booktitle       = {Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  doi             = {10.1109/IPDPS49936.2021.00053},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2021/Proceedings of the IEEE International Parallel and Distributed Processing Symposium (IPDPS)/Designing high-performance MPI libraries with on-the-fly compression for modern GPU Clusters - Zhou et al. - Pr.pdf:pdf},
  isbn            = {9781665440660},
  keywords        = {Compression,Dask,GPU,GPU-Aware MPI,HPC,MPI},
  mendeley-groups = {MustKnow},
  mendeley-tags   = {Compression,GPU,MPI},
  pages           = {1--10},
  publisher       = {IEEE},
  title           = {{Designing high-performance MPI libraries with on-the-fly compression for modern GPU Clusters}},
  year            = {2021}
}
@article{Zhou2022c,
  abstract      = {As more High-Performance Computing (HPC) and Deep Learning (DL) applications are adapting to scale using GPUs, the communication of GPU-resident data is becoming vital to end-to-end application performance. Among the available MPI operations in such applications, All-to-All is one of the most communication-intensive operations that becomes the bottleneck of efficiently scaling applications to larger GPU systems. Over the last decade, most research has focused on the optimization of large GPU-resident data transfers. However, for state-of-the-art GPU-Aware MPI libraries, MPI{\_}Alltoall communication for large GPU-resident data still suffers from poor performance due to the throughput limitation of commodity networks. However, the development of GPU-based compression algorithms with high throughput can reduce the volume of data transferred. The recent research of point-to-point-based online compression with these compression algorithms has shown potential on modern GPU clusters. In this paper, we redesign an MPI library to enable efficient collective-level online compression with an optimized host-staging scheme for All-to-All communication. We demonstrate that the proposed design achieves benefits at both microbenchmark and application levels. At the microbenchmark level, the proposed design can reduce the All-to-All communication latency by up to 87{\%}. For PSDNS, a traditional HPC application, our proposed design can reduce the All-to-All communication latency and total runtime by up to 29.2{\%} and 21.8{\%}, respectively, while ensuring data validation and not affecting the application convergence time. For Microsoft's DeepSpeed, a DL optimization library, the proposed design reduces the MPI{\_}Alltoall runtime by up to 26.4{\%} compared to a state-of-the-art MPI library with point-to-point compression while ensuring data validation. To the best of our knowledge, this is the first work that leverages online GPU-based compression techniques to significantly accelerate MPI{\_}Alltoall communication for HPC and DL applications.},
  author        = {Zhou, Qinghua and Kousha, Pouya and Anthony, Quentin and {Shafie Khorassani}, Kawthar and Shafi, Aamir and Subramoni, Hari and Panda, Dhabaleswar K.},
  doi           = {10.1007/978-3-031-07312-0_1},
  file          = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2022/Lecture Notes in Computer Science/Accelerating MPI All-to-All Communication with Online Compression on Modern GPU Clusters - Zhou et al. - Lecture Notes in Computer Scien.pdf:pdf},
  isbn          = {9783031073113},
  issn          = {16113349},
  journal       = {Lecture Notes in Computer Science},
  keywords      = {All-to-All,All{\_}to{\_}All,Collectives,Compression,DL,GPU,GPU-Aware MPI,HPC,MPI},
  mendeley-tags = {All{\_}to{\_}All,Collectives,Compression,GPU,MPI},
  pages         = {1--23},
  publisher     = {Springer International Publishing},
  title         = {{Accelerating MPI All-to-All Communication with Online Compression on Modern GPU Clusters}},
  year          = {2022}
}
@article{Zounmevo2014,
  abstract        = {The Message Passing Interface (MPI) message queues have been shown to grow proportionately to the job size for many applications. With such a behaviour and knowing that message queues are used very frequently, ensuring fast queue operations at large scales is of paramount importance in the current and the upcoming exascale computing eras. Scalability, however, is two-fold. With the growing processor core density per node, and the expected smaller memory density per core at larger scales, a queue mechanism that is blind on memory requirements poses another scalability issue even if it solves the speed of operation problem. In this work we propose a multidimensional queue management mechanism whose operation time and memory overhead grow sub-linearly with the job size. We show why a novel approach is justified in spite of the existence of well-known and fast data structures such as binary search trees. We compare our proposal with a linked list-based approach which is not scalable in terms of speed of operation, and with an array-based method which is not scalable in terms of memory consumption. Our proposed multidimensional approach yields queue operation time speedups that translate to up to 4-fold execution time improvement over the linked list design for the applications studied in this work. It also shows a consistent lower memory footprint compared to the array-based design. Finally, compared to the linked list-based queue, our proposed design yields cache miss rate improvements which are on average on par with the array-based design. {\textcopyright} 2013 Elsevier B.V. All rights reserved.},
  author          = {Zounmevo, Judicael A. and Afsahi, Ahmad},
  doi             = {10.1016/j.future.2013.07.003},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Future Generation Computer Systems/A fast and resource-conscious MPI message queue mechanism for large-scale jobs - Zounmevo, Afsahi - Future Generation Computer Systems.pdf:pdf},
  issn            = {0167739X},
  journal         = {Future Generation Computer Systems},
  keywords        = {Exascale,MPI,Message queues,Message{\_}Matching,Multidimensional searches,Scalability},
  mendeley-groups = {UsedInComp1},
  mendeley-tags   = {Exascale,MPI,Message{\_}Matching},
  number          = {1},
  pages           = {265--290},
  title           = {{A fast and resource-conscious MPI message queue mechanism for large-scale jobs}},
  year            = {2014}
}
@inproceedings{Zounmevo2014a,
  abstract        = {The synchronization model of the MPI one-sided communication paradigm can lead to serialization and latency propagation. For instance, a process can propagate non-RMA communication-related latencies to remote peers waiting in their respective epoch-closing routines in matching epochs. In this work, we discuss six latency issues that were documented for MPI-2.0 and show how they evolved in MPI-3.0. Then, we propose entirely nonblocking RMA synchronizations that allow processes to avoid waiting even in epoch-closing routines. The proposal provides contention avoidance in communication patterns that require back to back RMA epochs. It also fixes the latency propagation issues. Moreover, it allows the MPI progress engine to orchestrate aggressive schedulings to cut down the overall completion time of sets of epochs without introducing memory consistency hazards. Our test results show noticeable performance improvements for a lower-upper matrix decomposition as well as an application pattern that performs massive atomic updates.},
  author          = {Zounmevo, Judicael A. and Zhao, Xin and Balaji, Pavan and Gropp, William and Afsahi, Ahmad},
  booktitle       = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)},
  doi             = {10.1109/SC.2014.44},
  file            = {:C$\backslash$:/Users/amirs/Documents/Mendeley Desktop/2014/Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis (SC)/Nonblocking Epochs in MPI One-Sided Communication - Zounmevo et al. - Proceedings of the.pdf:pdf},
  isbn            = {9781479955008},
  issn            = {21674337},
  keywords        = {MPI,Nonblocking,RMA,latency propagation,nonblocking synchronizations,one-sided},
  mendeley-groups = {ByPPRL},
  mendeley-tags   = {MPI,Nonblocking,RMA},
  pages           = {475--486},
  title           = {{Nonblocking Epochs in MPI One-Sided Communication}},
  year            = {2014}
}

@inproceedings{shamis2015ucx,
  title        = {UCX: an open source framework for HPC network APIs and beyond},
  author       = {Shamis, Pavel and Venkata, Manjunath Gorentla and Lopez, M Graham and Baker, Matthew B and Hernandez, Oscar and Itigin, Yossi and Dubman, Mike and Shainer, Gilad and Graham, Richard L and Liss, Liran and others},
  booktitle    = {2015 IEEE 23rd Annual Symposium on High-Performance Interconnects},
  pages        = {40--43},
  year         = {2015},
  organization = {IEEE}
}